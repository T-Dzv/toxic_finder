{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10318333,"sourceType":"datasetVersion","datasetId":6388194}],"dockerImageVersionId":30822,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Завантаження даних (може відрізнятись в залежності від оточення в якому ви працюєте)\n\nimport pandas as pd\n\n# Шлях до файлу (вкажіть ваш власний шлях до файлу)\nfile_path = '/kaggle/input/data-prep/train_data.csv'\n\n# Завантаження даних\ndata = pd.read_csv(file_path)\n\n# Перевірка перших кількох рядків\nprint(data.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T10:57:18.272474Z","iopub.execute_input":"2024-12-28T10:57:18.272817Z","iopub.status.idle":"2024-12-28T10:57:23.538419Z","shell.execute_reply.started":"2024-12-28T10:57:18.272777Z","shell.execute_reply":"2024-12-28T10:57:23.537163Z"}},"outputs":[{"name":"stdout","text":"                 id                               cleaned_comment_text  \\\n0  0000997932d777bf  Explanation Why the edits made under my userna...   \n1  000103f0d9cfb60f  Daww He matches this background colour Im seem...   \n2  000113f07ec002fd  Hey man Im really not trying to edit war Its j...   \n3  0001b41b1c6bb37e  More I cant make any real suggestions on impro...   \n4  0001d958c54c6e35  You sir are my hero Any chance you remember wh...   \n\n                                           input_ids  \\\n0  [101, 7526, 2339, 1996, 10086, 2015, 2081, 210...   \n1  [101, 4830, 2860, 2860, 2002, 3503, 2023, 4281...   \n2  [101, 4931, 2158, 10047, 2428, 2025, 2667, 200...   \n3  [101, 2062, 1045, 2064, 2102, 2191, 2151, 2613...   \n4  [101, 2017, 2909, 2024, 2026, 5394, 2151, 3382...   \n\n                                     attention_masks  toxic  severe_toxic  \\\n0  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...      0             0   \n1  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...      0             0   \n2  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...      0             0   \n3  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...      0             0   \n4  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...      0             0   \n\n   obscene  threat  insult  identity_hate  \n0        0       0       0              0  \n1        0       0       0              0  \n2        0       0       0              0  \n3        0       0       0              0  \n4        0       0       0              0  \n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# виводимо загальну інформацію про вибірку\ndata.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T10:57:26.676524Z","iopub.execute_input":"2024-12-28T10:57:26.676890Z","iopub.status.idle":"2024-12-28T10:57:26.755357Z","shell.execute_reply.started":"2024-12-28T10:57:26.676852Z","shell.execute_reply":"2024-12-28T10:57:26.754307Z"}},"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 159571 entries, 0 to 159570\nData columns (total 10 columns):\n #   Column                Non-Null Count   Dtype \n---  ------                --------------   ----- \n 0   id                    159571 non-null  object\n 1   cleaned_comment_text  159571 non-null  object\n 2   input_ids             159571 non-null  object\n 3   attention_masks       159571 non-null  object\n 4   toxic                 159571 non-null  int64 \n 5   severe_toxic          159571 non-null  int64 \n 6   obscene               159571 non-null  int64 \n 7   threat                159571 non-null  int64 \n 8   insult                159571 non-null  int64 \n 9   identity_hate         159571 non-null  int64 \ndtypes: int64(6), object(4)\nmemory usage: 12.2+ MB\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# перевіряємо унікальні значення для кожного класу\n\n# Підрахунок кількості позитивних прикладів для кожного класу\nclass_distribution = data[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']].sum()\nprint(\"Кількість позитивних прикладів для кожного класу:\\n\", class_distribution)\n\n# Загальна кількість прикладів\ntotal_samples = len(data)\n\n# Відсоткове співвідношення по кожному класу\nclass_percentage = (class_distribution / total_samples) * 100\nprint(\"\\nВідсоткове співвідношення класів:\\n\", class_percentage)\n\n# Підрахунок нетоксичних прикладів\nnon_toxic_count = (data[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']].sum(axis=1) == 0).sum()\nnon_toxic_percentage = (non_toxic_count / total_samples) * 100\n\n# Виведення нетоксичних прикладів\nprint(f\"\\nКількість нетоксичних прикладів: {non_toxic_count}\")\nprint(f\"Відсоток нетоксичних прикладів: {non_toxic_percentage:.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T10:57:29.262570Z","iopub.execute_input":"2024-12-28T10:57:29.263002Z","iopub.status.idle":"2024-12-28T10:57:29.305654Z","shell.execute_reply.started":"2024-12-28T10:57:29.262961Z","shell.execute_reply":"2024-12-28T10:57:29.304517Z"}},"outputs":[{"name":"stdout","text":"Кількість позитивних прикладів для кожного класу:\n toxic            15294\nsevere_toxic      1595\nobscene           8449\nthreat             478\ninsult            7877\nidentity_hate     1405\ndtype: int64\n\nВідсоткове співвідношення класів:\n toxic            9.584448\nsevere_toxic     0.999555\nobscene          5.294822\nthreat           0.299553\ninsult           4.936361\nidentity_hate    0.880486\ndtype: float64\n\nКількість нетоксичних прикладів: 143346\nВідсоток нетоксичних прикладів: 89.83%\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"**Створення та підготовка міні-датасету для тестового моделювання**\n\nЯкщо ви вирішили не створювати міні вибірку і працювати одразу із повним файлом, пропустіть цей блок","metadata":{}},{"cell_type":"code","source":"# Створюємо копію даних для міні-вибірки\ndata_copy = data.copy()\n\n# Створення колонки label_combination\ndata_copy['label_combination'] = data_copy[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']].apply(\n    lambda row: '-'.join(row.astype(str)), axis=1\n)\n\n# Видалення рідкісних комбінацій міток у копії\nlabel_counts = data_copy['label_combination'].value_counts()\ndata_copy = data_copy[data_copy['label_combination'].isin(label_counts[label_counts > 1].index)].copy()\n\n# Видалення тимчасової колонки\ndata_copy.drop(columns=['label_combination'], inplace=True)\n\n# Виділення міні-вибірки (10% даних)\nfrom sklearn.model_selection import train_test_split\n\ndata_sample, _ = train_test_split(\n    data_copy,\n    test_size=0.9,  # 10% в міні-вибірку\n    stratify=data_copy[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']],\n    random_state=42\n)\n\nprint(f\"Розмір міні-вибірки: {len(data_sample)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T10:57:34.645531Z","iopub.execute_input":"2024-12-28T10:57:34.645976Z","iopub.status.idle":"2024-12-28T10:57:44.685828Z","shell.execute_reply.started":"2024-12-28T10:57:34.645939Z","shell.execute_reply":"2024-12-28T10:57:44.684811Z"}},"outputs":[{"name":"stdout","text":"Розмір міні-вибірки: 15956\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# Розмір вибірки все же завеликий для тестових цілей, сменшуємо ще\n# Зменшуємо розмір вибірки до 10% без втрати рідкісних класів\nsmaller_sample_size = int(len(data_sample) * 0.1)\n\n# Вибірка випадкових рядків без порушення пропорцій\ndata_sample = data_sample.sample(n=smaller_sample_size, random_state=42)\n\nprint(f\"Кількість прикладів у новій міні-вибірці: {len(data_sample)}\")\n\n# Перевіряємо, чи збережені рідкісні класи\nclass_distribution = data_sample[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']].sum()\nprint(\"Розподіл класів у зменшеній вибірці:\\n\", class_distribution)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T10:57:52.055397Z","iopub.execute_input":"2024-12-28T10:57:52.056075Z","iopub.status.idle":"2024-12-28T10:57:52.069657Z","shell.execute_reply.started":"2024-12-28T10:57:52.056022Z","shell.execute_reply":"2024-12-28T10:57:52.068456Z"}},"outputs":[{"name":"stdout","text":"Кількість прикладів у новій міні-вибірці: 1595\nРозподіл класів у зменшеній вибірці:\n toxic            153\nsevere_toxic      21\nobscene           96\nthreat             8\ninsult            80\nidentity_hate     16\ndtype: int64\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"import tensorflow as tf\n\n# Перетворення input_ids та attention_masks у списки для міні-вибірки\nmini_input_ids = tf.convert_to_tensor(data_sample['input_ids'].apply(eval).tolist())\nmini_attention_masks = tf.convert_to_tensor(data_sample['attention_masks'].apply(eval).tolist())\n\n# Перетворення labels у тензор для міні-вибірки\nmini_labels = tf.convert_to_tensor(data_sample[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']].values)\n\n# Перевірка формату міні-вибірки\nprint(f\"mini_input_ids shape: {mini_input_ids.shape}\")\nprint(f\"mini_attention_masks shape: {mini_attention_masks.shape}\")\nprint(f\"mini_labels shape: {mini_labels.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T10:57:56.793443Z","iopub.execute_input":"2024-12-28T10:57:56.793862Z","iopub.status.idle":"2024-12-28T10:58:06.821267Z","shell.execute_reply.started":"2024-12-28T10:57:56.793820Z","shell.execute_reply":"2024-12-28T10:58:06.820295Z"}},"outputs":[{"name":"stdout","text":"mini_input_ids shape: (1595, 128)\nmini_attention_masks shape: (1595, 128)\nmini_labels shape: (1595, 6)\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# Створюємо tf.data.Dataset для міні-вибірки\nmini_dataset = tf.data.Dataset.from_tensor_slices(({\n    'input_ids': mini_input_ids,\n    'attention_mask': mini_attention_masks\n}, mini_labels))\n\n# Перевірка кількості прикладів у міні-вибірці\nprint(f\"Кількість прикладів у mini_dataset: {len(mini_dataset)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T10:58:15.553720Z","iopub.execute_input":"2024-12-28T10:58:15.554549Z","iopub.status.idle":"2024-12-28T10:58:15.568841Z","shell.execute_reply.started":"2024-12-28T10:58:15.554507Z","shell.execute_reply":"2024-12-28T10:58:15.567620Z"}},"outputs":[{"name":"stdout","text":"Кількість прикладів у mini_dataset: 1595\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# Перевірка структури mini_dataset\nfor X, Y in mini_dataset.take(1):  # Перевіряємо структуру\n    print(f\"X (input_ids): {X['input_ids'].shape}\")\n    print(f\"X (attention_mask): {X['attention_mask'].shape}\")\n    print(f\"Y (labels): {Y.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T10:58:25.397100Z","iopub.execute_input":"2024-12-28T10:58:25.397563Z","iopub.status.idle":"2024-12-28T10:58:25.454065Z","shell.execute_reply.started":"2024-12-28T10:58:25.397530Z","shell.execute_reply":"2024-12-28T10:58:25.452803Z"}},"outputs":[{"name":"stdout","text":"X (input_ids): (128,)\nX (attention_mask): (128,)\nY (labels): (6,)\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"'''\nрозбиття вибірки на тренувальну і валідаційну.\nОскільки на цьому етапі ми виконуємо тестову побудову моделі і її точність нам не важлива, \nрозділимо вибірку \"грубо\", ігноруючи диспропорції класів. При роботі із повною вибіркою у\nнаступних частинах коду цей підхід не припустимий та має бути змінений.\n'''\n# Розподіл mini_dataset на тренувальну та валідаційну вибірки\nvalidation_split = 0.2  # 20% для валідації\ntotal_size = len(mini_dataset)\nval_size = int(total_size * validation_split)\n\n# Використовуємо take() і skip() для поділу\nmini_val_dataset = mini_dataset.take(val_size)\nmini_train_dataset = mini_dataset.skip(val_size)\n\n# Перевірка розмірів\nprint(f\"Тренувальна вибірка: {len(mini_train_dataset)} прикладів\")\nprint(f\"Валідаційна вибірка: {len(mini_val_dataset)} прикладів\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T10:58:29.106489Z","iopub.execute_input":"2024-12-28T10:58:29.106946Z","iopub.status.idle":"2024-12-28T10:58:29.122429Z","shell.execute_reply.started":"2024-12-28T10:58:29.106909Z","shell.execute_reply":"2024-12-28T10:58:29.121239Z"}},"outputs":[{"name":"stdout","text":"Тренувальна вибірка: 1276 прикладів\nВалідаційна вибірка: 319 прикладів\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"# Мінімальний тест, щоб переконатись, що модель приймає оброблені дані\nfrom transformers import TFBertModel\n\n# Завантажуємо предобучену модель BERT\nbert_model = TFBertModel.from_pretrained(\"bert-base-uncased\")\n\n# Передаємо батч з розміром 1 у модель\nfor batch in mini_train_dataset.take(1):  # Беремо перший батч\n    mini_inputs, mini_labels = batch\n    mini_input_ids = tf.expand_dims(mini_inputs['input_ids'], axis=0)  # Додаємо розмір батчу\n    mini_attention_mask = tf.expand_dims(mini_inputs['attention_mask'], axis=0)  # Додаємо розмір батчу\n\n    # Передаємо дані у модель\n    outputs = bert_model(input_ids=mini_input_ids, attention_mask=mini_attention_mask)\n    print(\"Модель успішно прийняла дані!\")\n    print(f\"Вихідний shape: {outputs.last_hidden_state.shape}\")\n    break","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T10:58:32.403047Z","iopub.execute_input":"2024-12-28T10:58:32.403525Z","iopub.status.idle":"2024-12-28T10:58:45.284357Z","shell.execute_reply.started":"2024-12-28T10:58:32.403486Z","shell.execute_reply":"2024-12-28T10:58:45.283399Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f7e3fe0d236049759425385365025fcc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"50627b4eb0684525b97311747dd630a5"}},"metadata":{}},{"name":"stderr","text":"Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias']\n- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\nAll the weights of TFBertModel were initialized from the PyTorch model.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n","output_type":"stream"},{"name":"stdout","text":"Модель успішно прийняла дані!\nВихідний shape: (1, 128, 768)\n","output_type":"stream"}],"execution_count":10},{"cell_type":"markdown","source":"**Створення та підготовка повного датасету**","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# Створюємо копію даних для розділення\ndata_copy = data.copy()\n\n# Створення колонки label_combination\ndata_copy['label_combination'] = data_copy[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']].apply(\n    lambda row: '-'.join(row.astype(str)), axis=1\n)\n\n# Видалення рідкісних комбінацій міток у копії\nlabel_counts = data_copy['label_combination'].value_counts()\ndata_copy = data_copy[data_copy['label_combination'].isin(label_counts[label_counts > 1].index)].copy()\n\n# Видалення тимчасової колонки\ndata_copy.drop(columns=['label_combination'], inplace=True)\n\n# Розділення на тренувальну і валідаційну вибірки\ntrain_data, val_data = train_test_split(\n    data_copy,\n    test_size=0.2,  # 20% для валідації\n    stratify=data_copy[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']],\n    random_state=42\n)\n\n# Перевірка розмірів\nprint(f\"Тренувальна вибірка: {len(train_data)} прикладів\")\nprint(f\"Валідаційна вибірка: {len(val_data)} прикладів\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T11:21:50.340680Z","iopub.execute_input":"2024-12-28T11:21:50.341045Z","iopub.status.idle":"2024-12-28T11:22:00.051164Z","shell.execute_reply.started":"2024-12-28T11:21:50.341011Z","shell.execute_reply":"2024-12-28T11:22:00.049310Z"}},"outputs":[{"name":"stdout","text":"Тренувальна вибірка: 127655 прикладів\nВалідаційна вибірка: 31914 прикладів\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"# перевіряємо унікальні значення для кожного класу для тренувальної вибірки\n\n# Підрахунок кількості позитивних прикладів для кожного класу\nclass_distribution = train_data[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']].sum()\nprint(\"Кількість позитивних прикладів для кожного класу:\\n\", class_distribution)\n\n# Загальна кількість прикладів\ntotal_samples = len(train_data)\n\n# Відсоткове співвідношення по кожному класу\nclass_percentage = (class_distribution / total_samples) * 100\nprint(\"\\nВідсоткове співвідношення класів:\\n\", class_percentage)\n\n# Підрахунок нетоксичних прикладів\nnon_toxic_count = (train_data[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']].sum(axis=1) == 0).sum()\nnon_toxic_percentage = (non_toxic_count / total_samples) * 100\n\n# Виведення нетоксичних прикладів\nprint(f\"\\nКількість нетоксичних прикладів: {non_toxic_count}\")\nprint(f\"Відсоток нетоксичних прикладів: {non_toxic_percentage:.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T11:23:10.035941Z","iopub.execute_input":"2024-12-28T11:23:10.036341Z","iopub.status.idle":"2024-12-28T11:23:10.070791Z","shell.execute_reply.started":"2024-12-28T11:23:10.036309Z","shell.execute_reply":"2024-12-28T11:23:10.069408Z"}},"outputs":[{"name":"stdout","text":"Кількість позитивних прикладів для кожного класу:\n toxic            12233\nsevere_toxic      1274\nobscene           6759\nthreat             382\ninsult            6300\nidentity_hate     1122\ndtype: int64\n\nВідсоткове співвідношення класів:\n toxic            9.582860\nsevere_toxic     0.998002\nobscene          5.294740\nthreat           0.299244\ninsult           4.935177\nidentity_hate    0.878931\ndtype: float64\n\nКількість нетоксичних прикладів: 114677\nВідсоток нетоксичних прикладів: 89.83%\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"# перевіряємо унікальні значення для кожного класу для валідаційної вибірки\n\n# Підрахунок кількості позитивних прикладів для кожного класу\nclass_distribution = val_data[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']].sum()\nprint(\"Кількість позитивних прикладів для кожного класу:\\n\", class_distribution)\n\n# Загальна кількість прикладів\ntotal_samples = len(val_data)\n\n# Відсоткове співвідношення по кожному класу\nclass_percentage = (class_distribution / total_samples) * 100\nprint(\"\\nВідсоткове співвідношення класів:\\n\", class_percentage)\n\n# Підрахунок нетоксичних прикладів\nnon_toxic_count = (val_data[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']].sum(axis=1) == 0).sum()\nnon_toxic_percentage = (non_toxic_count / total_samples) * 100\n\n# Виведення нетоксичних прикладів\nprint(f\"\\nКількість нетоксичних прикладів: {non_toxic_count}\")\nprint(f\"Відсоток нетоксичних прикладів: {non_toxic_percentage:.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T11:24:07.787382Z","iopub.execute_input":"2024-12-28T11:24:07.787813Z","iopub.status.idle":"2024-12-28T11:24:07.811435Z","shell.execute_reply.started":"2024-12-28T11:24:07.787780Z","shell.execute_reply":"2024-12-28T11:24:07.809867Z"}},"outputs":[{"name":"stdout","text":"Кількість позитивних прикладів для кожного класу:\n toxic            3059\nsevere_toxic      319\nobscene          1690\nthreat             94\ninsult           1576\nidentity_hate     282\ndtype: int64\n\nВідсоткове співвідношення класів:\n toxic            9.585135\nsevere_toxic     0.999561\nobscene          5.295482\nthreat           0.294542\ninsult           4.938272\nidentity_hate    0.883625\ndtype: float64\n\nКількість нетоксичних прикладів: 28669\nВідсоток нетоксичних прикладів: 89.83%\n","output_type":"stream"}],"execution_count":17},{"cell_type":"markdown","source":"Вибірка розподілена рівномірно з врахуванням пропорцій класів.","metadata":{}},{"cell_type":"code","source":"# Перетворення тренувальної вибірки\n\nimport tensorflow as tf\n\n# Перетворення input_ids та attention_masks у списки\ninput_ids = tf.convert_to_tensor(train_data['input_ids'].apply(eval).tolist())\nattention_masks = tf.convert_to_tensor(train_data['attention_masks'].apply(eval).tolist())\n\n# Перетворення labels у тензор\nlabels = tf.convert_to_tensor(train_data[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']].values)\n\n# Перевірка формату\nprint(f\"input_ids shape: {input_ids.shape}\")\nprint(f\"attention_masks shape: {attention_masks.shape}\")\nprint(f\"labels shape: {labels.shape}\")\n\n# Створюємо tf.data.Dataset\ntrain_dataset = tf.data.Dataset.from_tensor_slices(({\n    'input_ids': input_ids,\n    'attention_mask': attention_masks\n}, labels))\n\n# Перевірка кількості прикладів\nprint(f\"Кількість прикладів у dataset: {len(train_dataset)}\")\n\n# Перевірка структури train_dataset\nfor X, Y in train_dataset.take(1):  # Перевіряємо структуру\n    print(f\"X (input_ids): {X['input_ids'].shape}\")\n    print(f\"X (attention_mask): {X['attention_mask'].shape}\")\n    print(f\"Y (labels): {Y.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T11:30:40.961010Z","iopub.execute_input":"2024-12-28T11:30:40.961451Z","iopub.status.idle":"2024-12-28T11:31:33.513099Z","shell.execute_reply.started":"2024-12-28T11:30:40.961416Z","shell.execute_reply":"2024-12-28T11:31:33.511819Z"}},"outputs":[{"name":"stdout","text":"input_ids shape: (127655, 128)\nattention_masks shape: (127655, 128)\nlabels shape: (127655, 6)\nКількість прикладів у dataset: 127655\nX (input_ids): (128,)\nX (attention_mask): (128,)\nY (labels): (6,)\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"# Перетворення валідаціної вибірки\n\n# Перетворення input_ids та attention_masks у списки для валідаційної вибірки\nval_input_ids = tf.convert_to_tensor(val_data['input_ids'].apply(eval).tolist())\nval_attention_masks = tf.convert_to_tensor(val_data['attention_masks'].apply(eval).tolist())\n\n# Перетворення labels у тензор для валідаційної вибірки\nval_labels = tf.convert_to_tensor(val_data[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']].values)\n\n# Перевірка формату\nprint(f\"val_input_ids shape: {val_input_ids.shape}\")\nprint(f\"val_attention_masks shape: {val_attention_masks.shape}\")\nprint(f\"val_labels shape: {val_labels.shape}\")\n\n# Створюємо tf.data.Dataset для валідаційної вибірки\nval_dataset = tf.data.Dataset.from_tensor_slices(({\n    'input_ids': val_input_ids,\n    'attention_mask': val_attention_masks\n}, val_labels))\n\n# Перевірка кількості прикладів\nprint(f\"Кількість прикладів у val_dataset: {len(val_dataset)}\")\n\n# Перевірка структури val_dataset\nfor X, Y in val_dataset.take(1):  # Перевіряємо структуру\n    print(f\"X (val_input_ids): {X['input_ids'].shape}\")\n    print(f\"X (val_attention_mask): {X['attention_mask'].shape}\")\n    print(f\"Y (val_labels): {Y.shape}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T11:33:36.877672Z","iopub.execute_input":"2024-12-28T11:33:36.878107Z","iopub.status.idle":"2024-12-28T11:33:49.742662Z","shell.execute_reply.started":"2024-12-28T11:33:36.878064Z","shell.execute_reply":"2024-12-28T11:33:49.741409Z"}},"outputs":[{"name":"stdout","text":"val_input_ids shape: (31914, 128)\nval_attention_masks shape: (31914, 128)\nval_labels shape: (31914, 6)\nКількість прикладів у val_dataset: 31914\nX (val_input_ids): (128,)\nX (val_attention_mask): (128,)\nY (val_labels): (6,)\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"# Мінімальний тест, щоб переконатись, що модель приймає оброблені дані\nfrom transformers import TFBertModel\n\n# Завантажуємо предобучену модель BERT\nbert_model = TFBertModel.from_pretrained(\"bert-base-uncased\")\n\n# Передаємо батч з розміром 1 у модель\nfor batch in train_dataset.take(1):  # Беремо перший батч\n    inputs, labels = batch\n    input_ids = tf.expand_dims(inputs['input_ids'], axis=0)  # Додаємо розмір батчу\n    attention_mask = tf.expand_dims(inputs['attention_mask'], axis=0)  # Додаємо розмір батчу\n\n    # Передаємо дані у модель\n    outputs = bert_model(input_ids=input_ids, attention_mask=attention_mask)\n    print(\"Модель успішно прийняла дані!\")\n    print(f\"Вихідний shape: {outputs.last_hidden_state.shape}\")\n    break","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T11:37:34.957489Z","iopub.execute_input":"2024-12-28T11:37:34.957886Z","iopub.status.idle":"2024-12-28T11:37:39.045859Z","shell.execute_reply.started":"2024-12-28T11:37:34.957845Z","shell.execute_reply":"2024-12-28T11:37:39.044812Z"}},"outputs":[{"name":"stderr","text":"Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias']\n- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\nAll the weights of TFBertModel were initialized from the PyTorch model.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n","output_type":"stream"},{"name":"stdout","text":"Модель успішно прийняла дані!\nВихідний shape: (1, 128, 768)\n","output_type":"stream"}],"execution_count":21},{"cell_type":"markdown","source":"**Примітка**\n\nдані підготовлені для роботи із моделлю БЕРТ. Але через конфлікти бібліотек PyTorch / Tensorflow можливо доведеться в коді зі створення та навчання моделі виконувати додаткові перетворення. \nУ власному коді для вирішення кофліктів я використовувала створений кастомний клас даних. Він наданий нижче для прикладу. У вашому коді можливо ви вирішите конфлікти іншими шляхами.","metadata":{}},{"cell_type":"code","source":"from transformers import TFBertModel\nfrom tensorflow.keras.layers import Input, Layer\nfrom tensorflow.keras.models import Model\nimport tensorflow as tf\n\n# Кастомний шар для інтеграції з BERT\nclass BertLayer(Layer):\n    def __init__(self, pretrained_model_name=\"bert-base-uncased\", trainable=False, **kwargs):\n        super(BertLayer, self).__init__(**kwargs)\n        # Завантажуємо попередньо навчений BERT\n        self.bert = TFBertModel.from_pretrained(pretrained_model_name)\n        self.bert.trainable = trainable  # Заморожуємо або розморожуємо шари залежно від параметра trainable\n\n    def call(self, inputs):\n        # Вхідні дані: input_ids та attention_mask\n        input_ids, attention_mask = inputs\n        # Передаємо дані через BERT\n        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n        return outputs.last_hidden_state  # Повертаємо тільки last_hidden_state","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T11:40:54.197695Z","iopub.execute_input":"2024-12-28T11:40:54.198131Z","iopub.status.idle":"2024-12-28T11:40:54.247420Z","shell.execute_reply.started":"2024-12-28T11:40:54.198098Z","shell.execute_reply":"2024-12-28T11:40:54.246300Z"}},"outputs":[],"execution_count":22}]}