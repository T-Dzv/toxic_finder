{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10361110,"sourceType":"datasetVersion","datasetId":6416892},{"sourceId":10364862,"sourceType":"datasetVersion","datasetId":6419638}],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Перевірка підключення GPU\nimport tensorflow as tf\nprint(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T07:11:51.216258Z","iopub.execute_input":"2025-01-04T07:11:51.216688Z","iopub.status.idle":"2025-01-04T07:12:01.298925Z","shell.execute_reply.started":"2025-01-04T07:11:51.216651Z","shell.execute_reply":"2025-01-04T07:12:01.297935Z"}},"outputs":[{"name":"stdout","text":"Num GPUs Available:  2\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.optimizers import Adam, Nadam\nfrom tensorflow.keras.layers import Input, Dense, Layer, Dropout, GlobalAveragePooling1D\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.metrics import Precision, Recall\n\n\nfrom transformers import TFBertForSequenceClassification, TFBertModel\n\nimport numpy as np\nimport pandas as pd\nfrom sklearn.metrics import classification_report, multilabel_confusion_matrix\nfrom sklearn.model_selection import train_test_split","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T07:12:01.300080Z","iopub.execute_input":"2025-01-04T07:12:01.300752Z","iopub.status.idle":"2025-01-04T07:12:07.007196Z","shell.execute_reply.started":"2025-01-04T07:12:01.300725Z","shell.execute_reply":"2025-01-04T07:12:07.006504Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"**Підготовка кастомних класів і функцій**","metadata":{}},{"cell_type":"markdown","source":"Даний блок необхідно копіювати при завантажені моделей","metadata":{}},{"cell_type":"code","source":"# Кастомний шар для інтеграції з BERT\nclass BertLayer(Layer):\n    def __init__(self, pretrained_model_name=\"bert-base-uncased\", trainable=False, **kwargs):\n        super(BertLayer, self).__init__(**kwargs)\n        # Завантажуємо попередньо навчений BERT\n        self.bert = TFBertModel.from_pretrained(pretrained_model_name)\n        self.bert.trainable = trainable  # Заморожуємо або розморожуємо шари залежно від параметра trainable\n\n    def call(self, inputs):\n        # Вхідні дані: input_ids та attention_mask\n        input_ids, attention_mask = inputs\n        # Передаємо дані через BERT\n        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n        return outputs.last_hidden_state  # Повертаємо тільки last_hidden_state","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T07:12:07.008796Z","iopub.execute_input":"2025-01-04T07:12:07.009361Z","iopub.status.idle":"2025-01-04T07:12:07.013965Z","shell.execute_reply.started":"2025-01-04T07:12:07.009336Z","shell.execute_reply":"2025-01-04T07:12:07.013267Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"'''\nу якості метрики обрано Ф-1 у зв'язку із незбалансованістю класів. \nПідготуємо функцію для неї\n'''\n\nimport tensorflow as tf\nfrom tensorflow.keras import backend as K\n\ndef f1_metric(y_true, y_pred):\n    # Преобразуем в бинарный формат для каждого класса\n    y_true = K.cast(y_true, 'int32')\n    y_pred = K.cast(K.greater_equal(y_pred, 0.5), 'int32')\n\n    # Вычисляем точность (precision) и полноту (recall)\n    true_positive = K.sum(K.cast(y_true * y_pred, 'float32'))\n    false_positive = K.sum(K.cast((1 - y_true) * y_pred, 'float32'))\n    false_negative = K.sum(K.cast(y_true * (1 - y_pred), 'float32'))\n\n    precision = true_positive / (true_positive + false_positive + K.epsilon())\n    recall = true_positive / (true_positive + false_negative + K.epsilon())\n\n    # F1-score = 2 * (precision * recall) / (precision + recall)\n    f1 = 2 * (precision * recall) / (precision + recall + K.epsilon())\n    \n    return f1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T07:12:07.014966Z","iopub.execute_input":"2025-01-04T07:12:07.015242Z","iopub.status.idle":"2025-01-04T07:12:07.032513Z","shell.execute_reply.started":"2025-01-04T07:12:07.015221Z","shell.execute_reply":"2025-01-04T07:12:07.031659Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"'''\nпідготовка вагів для функції врат щоб врахувати незбалансованість вибірки\n'''\n# Підрахунок ваг для кожного класу\nclass_counts = {\n    0: 15294,  # toxic\n    1: 1595,   # severe_toxic\n    2: 8449,   # obscene\n    3: 478,    # threat\n    4: 7877,   # insult\n    5: 1405    # identity_hate\n}\n\n# Загальна кількість прикладів у вибірці\ntotal_samples = 159571\n\n# Вага для кожного класу буде пропорційною оберненому співвідношенню його частоти\nclass_weights = {}\nfor label, count in class_counts.items():\n    # Вага класу розраховується як обернене відношення загальної кількості прикладів\n    class_weights[label] = total_samples / count\n\n# Нормалізація ваг класів, щоб їх сума була рівна 1\nclass_weights = {k: v / sum(class_weights.values()) for k, v in class_weights.items()}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T07:12:07.033176Z","iopub.execute_input":"2025-01-04T07:12:07.033358Z","iopub.status.idle":"2025-01-04T07:12:07.053191Z","shell.execute_reply.started":"2025-01-04T07:12:07.033342Z","shell.execute_reply":"2025-01-04T07:12:07.052536Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import backend as K\n\ndef weighted_f1_loss(y_true, y_pred, class_weights):\n    \"\"\"\n    Кастомна функція втрат для оптимізації макро F1-міри з урахуванням ваг класів.\n    \n    Args:\n        y_true: tf.Tensor, істинні мітки (розмірність [batch_size, num_classes]).\n        y_pred: tf.Tensor, передбачення моделі (розмірність [batch_size, num_classes]).\n        class_weights: dict, ваги класів (ключі - індекси класів, значення - ваги).\n\n    Returns:\n        tf.Tensor, значення функції втрат.\n    \"\"\"\n    # Застосовуємо сигмоїду до передбачень, якщо вони ще не пройшли через активацію\n    y_pred = K.sigmoid(y_pred)\n\n    # Перетворення ваг класів у тензор\n    class_weight_tensor = tf.constant([class_weights[i] for i in range(len(class_weights))], dtype=tf.float32)\n\n    # Обчислення TP, FP, FN\n    true_positives = K.sum(y_true * y_pred, axis=0)\n    predicted_positives = K.sum(y_pred, axis=0)\n    actual_positives = K.sum(y_true, axis=0)\n\n    # Обчислення Precision та Recall для кожного класу\n    precision = true_positives / (predicted_positives + K.epsilon())\n    recall = true_positives / (actual_positives + K.epsilon())\n\n    # Обчислення F1 для кожного класу\n    f1_per_class = 2 * (precision * recall) / (precision + recall + K.epsilon())\n\n    # Застосування ваг класів\n    weighted_f1 = f1_per_class * class_weight_tensor\n\n    # Середнє значення макро F1\n    macro_f1 = K.mean(weighted_f1)\n\n    # Повернення від'ємного значення F1 як функції втрат (для мінімізації)\n    return 1 - macro_f1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T07:12:07.053970Z","iopub.execute_input":"2025-01-04T07:12:07.054250Z","iopub.status.idle":"2025-01-04T07:12:07.072695Z","shell.execute_reply.started":"2025-01-04T07:12:07.054223Z","shell.execute_reply":"2025-01-04T07:12:07.072143Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"**Загальна підготовка даних**","metadata":{}},{"cell_type":"code","source":"data_path = '/kaggle/input/detaset/train_data.csv'\ndf = pd.read_csv(data_path)\n\n# список категорій:\nLABEL_COLUMNS = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n\n# Конвертація токенізованих даних з рядків у масиви\nfor column in ['input_ids', 'attention_masks']:\n    df[column] = df[column].apply(eval).apply(np.array)\n\n# Виділяємо токенізовані вектори та мітки\ninput_ids = np.stack(df['input_ids'].values)\nattention_mask = np.stack(df['attention_masks'].values)\nlabels = np.array(df[LABEL_COLUMNS].values)\nlabels = labels.astype('float32')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T07:12:07.073537Z","iopub.execute_input":"2025-01-04T07:12:07.073746Z","iopub.status.idle":"2025-01-04T07:12:56.712772Z","shell.execute_reply.started":"2025-01-04T07:12:07.073727Z","shell.execute_reply":"2025-01-04T07:12:56.712021Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# Розділення на тренувальну та тестову вибірки (повний набір даних)\n\ntrain_input_ids, val_input_ids, train_attention_mask, val_attention_mask, train_labels, val_labels = train_test_split(\n    input_ids, attention_mask, labels, test_size=0.2, random_state=42\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T07:12:56.715166Z","iopub.execute_input":"2025-01-04T07:12:56.715433Z","iopub.status.idle":"2025-01-04T07:12:56.843631Z","shell.execute_reply.started":"2025-01-04T07:12:56.715414Z","shell.execute_reply":"2025-01-04T07:12:56.842922Z"}},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"**Бінарна модель**","metadata":{}},{"cell_type":"code","source":"# Генерація міток для бінарної моделі\nt_binary_labels = np.where(np.all(train_labels == 0, axis=1), 1, 0).astype('float32')\nv_binary_labels = np.where(np.all(val_labels == 0, axis=1), 1, 0).astype('float32')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T07:12:56.844999Z","iopub.execute_input":"2025-01-04T07:12:56.845215Z","iopub.status.idle":"2025-01-04T07:12:56.853710Z","shell.execute_reply.started":"2025-01-04T07:12:56.845197Z","shell.execute_reply":"2025-01-04T07:12:56.852911Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"# Балансування даних\n\nfrom imblearn.over_sampling import SMOTE\n\nt_features = np.hstack((train_input_ids, train_attention_mask))\n\nsmote = SMOTE(random_state=42)\nt_data_resampled, t_binary_labels_resampled = smote.fit_resample(t_features, t_binary_labels)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T07:12:56.854513Z","iopub.execute_input":"2025-01-04T07:12:56.854811Z","iopub.status.idle":"2025-01-04T07:13:01.833891Z","shell.execute_reply.started":"2025-01-04T07:12:56.854776Z","shell.execute_reply":"2025-01-04T07:13:01.832942Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"# До SMOTE\nprint(\"До обробки:\")\nprint(f\"Токсичні: {np.sum(t_binary_labels == 0)}\")\nprint(f\"Нетоксичні: {np.sum(t_binary_labels == 1)}\")\n\n# Після SMOTE\nprint(\"\\nПісля обробки:\")\nprint(f\"Токсичні: {np.sum(t_binary_labels_resampled == 0)}\")\nprint(f\"Нетоксичні: {np.sum(t_binary_labels_resampled == 1)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T07:13:01.835184Z","iopub.execute_input":"2025-01-04T07:13:01.835900Z","iopub.status.idle":"2025-01-04T07:13:01.843039Z","shell.execute_reply.started":"2025-01-04T07:13:01.835852Z","shell.execute_reply":"2025-01-04T07:13:01.842244Z"}},"outputs":[{"name":"stdout","text":"До обробки:\nТоксичні: 12981\nНетоксичні: 114675\n\nПісля обробки:\nТоксичні: 114675\nНетоксичні: 114675\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"# Зворотне перетворення на train_input_ids і t_attention_mask\n\n# Вихідні розміри train_input_ids и train_attention_mask\ninput_ids_size = train_input_ids.shape[1]\nattention_mask_size = train_attention_mask.shape[1]\n\n# Зворотній розподіл\nt_input_ids_resampled = t_data_resampled[:, :input_ids_size]\nt_attention_mask_resampled = t_data_resampled[:, input_ids_size:]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T07:13:01.843797Z","iopub.execute_input":"2025-01-04T07:13:01.844070Z","iopub.status.idle":"2025-01-04T07:13:01.856261Z","shell.execute_reply.started":"2025-01-04T07:13:01.844041Z","shell.execute_reply":"2025-01-04T07:13:01.855658Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"t_data = {\n    \"input_ids\": t_input_ids_resampled,\n    \"attention_mask\": t_attention_mask_resampled,\n}\n\nv_data = {\n    \"input_ids\": val_input_ids,\n    \"attention_mask\": val_attention_mask,\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T07:13:01.857093Z","iopub.execute_input":"2025-01-04T07:13:01.857377Z","iopub.status.idle":"2025-01-04T07:13:01.872596Z","shell.execute_reply.started":"2025-01-04T07:13:01.857351Z","shell.execute_reply":"2025-01-04T07:13:01.871932Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"# Модель для бінарної класифікації\n\n# Вхідні дані\ninput_ids = Input(shape=(128,), dtype=tf.int32, name=\"input_ids\")\nattention_mask = Input(shape=(128,), dtype=tf.int32, name=\"attention_mask\")\n\n# BERT шар\nbert_outputs = BertLayer(trainable=False)([input_ids, attention_mask])\n\n# Пулінг\npooled_output = GlobalAveragePooling1D()(bert_outputs)\n\n# бінарна класифікація\nbinary_dense = Dense(128, activation=\"swish\")(pooled_output)\nbinary_dropout = Dropout(0.3)(binary_dense)\nbinary_output = Dense(1, activation=\"sigmoid\", name=\"binary_output\")(binary_dropout)\n\n# Модель\nmodel_3_1 = Model(\n    inputs=[input_ids, attention_mask],\n    outputs=[binary_output]\n)\n\n# Компіляція моделі\nmodel_3_1.compile(\n    optimizer=Adam(learning_rate=1e-4),\n    loss=\"binary_crossentropy\",\n    metrics=[\"accuracy\"]\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T07:13:01.873352Z","iopub.execute_input":"2025-01-04T07:13:01.873601Z","iopub.status.idle":"2025-01-04T07:13:10.457459Z","shell.execute_reply.started":"2025-01-04T07:13:01.873569Z","shell.execute_reply":"2025-01-04T07:13:10.456780Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"118d2acbbe734b71b4bf49e856a4d93a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"96b7703957964a7d9364f67e9a1d8fde"}},"metadata":{}},{"name":"stderr","text":"Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight']\n- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\nAll the weights of TFBertModel were initialized from the PyTorch model.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"from tensorflow.keras.callbacks import EarlyStopping\n\nearly_stopping = EarlyStopping(\n    monitor='val_loss',        \n    patience=3,                \n    restore_best_weights=True  \n)\n\n# Навчання моделі\nhistory_3_1 = model_3_1.fit(\n    t_data,\n    t_binary_labels_resampled,\n    validation_data=(v_data, v_binary_labels),\n    epochs=5,  \n    batch_size=256,\n    callbacks=[early_stopping]  \n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T07:13:10.458303Z","iopub.execute_input":"2025-01-04T07:13:10.458578Z","iopub.status.idle":"2025-01-04T09:58:43.035013Z","shell.execute_reply.started":"2025-01-04T07:13:10.458555Z","shell.execute_reply":"2025-01-04T09:58:43.034087Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/5\n\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2011s\u001b[0m 2s/step - accuracy: 0.5405 - loss: 0.6923 - val_accuracy: 0.5193 - val_loss: 0.7024\nEpoch 2/5\n\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1979s\u001b[0m 2s/step - accuracy: 0.5582 - loss: 0.6841 - val_accuracy: 0.4711 - val_loss: 0.7021\nEpoch 3/5\n\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1980s\u001b[0m 2s/step - accuracy: 0.5641 - loss: 0.6819 - val_accuracy: 0.5953 - val_loss: 0.6460\nEpoch 4/5\n\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1981s\u001b[0m 2s/step - accuracy: 0.5665 - loss: 0.6809 - val_accuracy: 0.5964 - val_loss: 0.6540\nEpoch 5/5\n\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1981s\u001b[0m 2s/step - accuracy: 0.5677 - loss: 0.6798 - val_accuracy: 0.6106 - val_loss: 0.6288\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"import json\n\n# Збереження історії навчання в JSON\nwith open('history_3_1.json', 'w') as json_file:\n    json.dump(history_3_1.history, json_file)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T09:58:43.036159Z","iopub.execute_input":"2025-01-04T09:58:43.036497Z","iopub.status.idle":"2025-01-04T09:58:43.040680Z","shell.execute_reply.started":"2025-01-04T09:58:43.036465Z","shell.execute_reply":"2025-01-04T09:58:43.040001Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"model_3_1.save(\"model_3_1.h5\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T09:58:43.041341Z","iopub.execute_input":"2025-01-04T09:58:43.041586Z","iopub.status.idle":"2025-01-04T09:58:43.095675Z","shell.execute_reply.started":"2025-01-04T09:58:43.041557Z","shell.execute_reply":"2025-01-04T09:58:43.095112Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"# Підготовка частини валідаціної вибірки для прогнозів \n_, test_input_ids, _, test_attention_mask, _, test_labels = train_test_split(\n    val_input_ids, val_attention_mask, val_labels, test_size=0.1, random_state=42\n)\n\ntest_binary_labels = np.where(np.all(test_labels == 0, axis=1), 1, 0).astype('float32')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T09:58:43.096419Z","iopub.execute_input":"2025-01-04T09:58:43.096685Z","iopub.status.idle":"2025-01-04T09:58:43.120261Z","shell.execute_reply.started":"2025-01-04T09:58:43.096659Z","shell.execute_reply":"2025-01-04T09:58:43.119566Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"# Отримання прогнозів для першої моделі\nbinary_predictions = model_3_1.predict(\n    {'input_ids': test_input_ids, 'attention_mask': test_attention_mask},\n    batch_size=64\n)\n\nbinary_predictions = (binary_predictions > 0.5).astype(int)  # Перетворення в 0 або 1\n\n# Розподіл прогнозів бінарної моделі\nunique, counts = np.unique(binary_predictions, return_counts=True)\nbinary_distribution = dict(zip(unique, counts))\n\nprint(\"Розподіл міток:\")\nprint(f\"Нетоксичні (1): {binary_distribution.get(1, 0)}\")\nprint(f\"Токсичні (0): {binary_distribution.get(0, 0)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T09:58:43.121058Z","iopub.execute_input":"2025-01-04T09:58:43.121318Z","iopub.status.idle":"2025-01-04T09:59:25.721641Z","shell.execute_reply.started":"2025-01-04T09:58:43.121297Z","shell.execute_reply":"2025-01-04T09:59:25.720840Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 716ms/step\nРозподіл міток:\nНетоксичні (1): 1956\nТоксичні (0): 1236\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"# Розподіл істинних міток\nunique, counts = np.unique(test_binary_labels, return_counts=True)\ntrue_distribution = dict(zip(unique, counts))\n\nprint(\"Розподіл істинних міток:\")\nprint(f\"Нетоксичні (1): {true_distribution.get(1, 0)}\")\nprint(f\"Токсичні (0): {true_distribution.get(0, 0)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T09:59:25.722389Z","iopub.execute_input":"2025-01-04T09:59:25.722747Z","iopub.status.idle":"2025-01-04T09:59:25.728695Z","shell.execute_reply.started":"2025-01-04T09:59:25.722722Z","shell.execute_reply":"2025-01-04T09:59:25.727775Z"}},"outputs":[{"name":"stdout","text":"Розподіл істинних міток:\nНетоксичні (1): 2879\nТоксичні (0): 313\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"# Оцінка моделі\nprint(\"\\nКласифікаційний звіт для бінарної моделі:\\n\")\nprint(classification_report(test_binary_labels, binary_predictions, target_names=[\n    \"non_toxic\", \"toxic\"\n]))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T09:59:25.729564Z","iopub.execute_input":"2025-01-04T09:59:25.729777Z","iopub.status.idle":"2025-01-04T09:59:25.753448Z","shell.execute_reply.started":"2025-01-04T09:59:25.729759Z","shell.execute_reply":"2025-01-04T09:59:25.752592Z"}},"outputs":[{"name":"stdout","text":"\nКласифікаційний звіт для бінарної моделі:\n\n              precision    recall  f1-score   support\n\n   non_toxic       0.13      0.51      0.21       313\n       toxic       0.92      0.63      0.75      2879\n\n    accuracy                           0.62      3192\n   macro avg       0.53      0.57      0.48      3192\nweighted avg       0.84      0.62      0.69      3192\n\n","output_type":"stream"}],"execution_count":21},{"cell_type":"markdown","source":"**Фінтюнінг бінарної моделі**","metadata":{}},{"cell_type":"code","source":"# Розморозка останніх 4-х шарів BERT\nfor layer in model_3_1.layers:\n    if isinstance(layer, BertLayer):  \n        for bert_layer in layer.bert.bert.encoder.layer[-4:]:  \n            bert_layer.trainable = True\n\nmodel_3_1.compile(\n    optimizer=Adam(learning_rate=1e-5),  # Низкий learning rate для фінтюнинга\n    loss=\"binary_crossentropy\",\n    metrics=[\"accuracy\"]\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T09:59:25.754215Z","iopub.execute_input":"2025-01-04T09:59:25.754503Z","iopub.status.idle":"2025-01-04T09:59:25.764885Z","shell.execute_reply.started":"2025-01-04T09:59:25.754482Z","shell.execute_reply":"2025-01-04T09:59:25.764196Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"# Финтюнинг\nhistory_3_1 = model_3_1.fit(\n    t_data,\n    t_binary_labels_resampled,\n    validation_data=(v_data, v_binary_labels),\n    epochs=3,               # Невелика кількість епох, оскільки БЕРТ має навчатись дуже швидко\n    batch_size=256\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T09:59:25.768864Z","iopub.execute_input":"2025-01-04T09:59:25.769085Z","iopub.status.idle":"2025-01-04T11:39:02.997171Z","shell.execute_reply.started":"2025-01-04T09:59:25.769065Z","shell.execute_reply":"2025-01-04T11:39:02.996429Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/3\n\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2016s\u001b[0m 2s/step - accuracy: 0.5727 - loss: 0.6776 - val_accuracy: 0.5466 - val_loss: 0.6649\nEpoch 2/3\n\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1980s\u001b[0m 2s/step - accuracy: 0.5734 - loss: 0.6768 - val_accuracy: 0.5135 - val_loss: 0.6744\nEpoch 3/3\n\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1980s\u001b[0m 2s/step - accuracy: 0.5773 - loss: 0.6763 - val_accuracy: 0.4795 - val_loss: 0.7042\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"# Збереження історії змін в JSON\nwith open('history_3_1_fin.json', 'w') as json_file:\n    json.dump(history_3_1.history, json_file)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T11:39:02.999126Z","iopub.execute_input":"2025-01-04T11:39:02.999359Z","iopub.status.idle":"2025-01-04T11:39:03.003530Z","shell.execute_reply.started":"2025-01-04T11:39:02.999339Z","shell.execute_reply":"2025-01-04T11:39:03.002831Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"model_3_1.save(\"model_3_1_fin.h5\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T11:39:03.004376Z","iopub.execute_input":"2025-01-04T11:39:03.004686Z","iopub.status.idle":"2025-01-04T11:39:03.038344Z","shell.execute_reply.started":"2025-01-04T11:39:03.004662Z","shell.execute_reply":"2025-01-04T11:39:03.037711Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"model_3_1.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T13:07:11.175493Z","iopub.execute_input":"2025-01-04T13:07:11.175841Z","iopub.status.idle":"2025-01-04T13:07:11.197535Z","shell.execute_reply.started":"2025-01-04T13:07:11.175817Z","shell.execute_reply":"2025-01-04T13:07:11.196747Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ input_ids (\u001b[38;5;33mInputLayer\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ -                      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ attention_mask            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ -                      │\n│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ bert_layer (\u001b[38;5;33mBertLayer\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m768\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ input_ids[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],       │\n│                           │                        │                │ attention_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ global_average_pooling1d  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ bert_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)  │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m98,432\u001b[0m │ global_average_poolin… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout (\u001b[38;5;33mDropout\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ binary_output (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m129\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ input_ids (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ attention_mask            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ bert_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BertLayer</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_ids[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       │\n│                           │                        │                │ attention_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ global_average_pooling1d  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ bert_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)  │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">98,432</span> │ global_average_poolin… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ binary_output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m295,685\u001b[0m (1.13 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">295,685</span> (1.13 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m98,561\u001b[0m (385.00 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">98,561</span> (385.00 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m197,124\u001b[0m (770.02 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">197,124</span> (770.02 KB)\n</pre>\n"},"metadata":{}}],"execution_count":56},{"cell_type":"code","source":"# Отримання прогнозів для першої моделі\nbinary_predictions = model_3_1.predict(\n    {'input_ids': test_input_ids, 'attention_mask': test_attention_mask},\n    batch_size=64\n)\n\nbinary_predictions = (binary_predictions > 0.5).astype(int)  # Перетворення в 0 або 1\n\n# Розподіл прогнозів бінарної моделі\nunique, counts = np.unique(binary_predictions, return_counts=True)\nbinary_distribution = dict(zip(unique, counts))\n\nprint(\"Розподіл міток:\")\nprint(f\"Нетоксичні (1): {binary_distribution.get(1, 0)}\")\nprint(f\"Токсичні (0): {binary_distribution.get(0, 0)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T11:39:03.039072Z","iopub.execute_input":"2025-01-04T11:39:03.039320Z","iopub.status.idle":"2025-01-04T11:39:42.301917Z","shell.execute_reply.started":"2025-01-04T11:39:03.039292Z","shell.execute_reply":"2025-01-04T11:39:42.300962Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 687ms/step\nРозподіл міток:\nНетоксичні (1): 1442\nТоксичні (0): 1750\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"# Оцінка моделі\nprint(\"\\nКласифікаційний звіт для бінарної моделі:\\n\")\nprint(classification_report(test_binary_labels, binary_predictions, target_names=[\n    \"non_toxic\", \"toxic\"\n]))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T11:39:42.302668Z","iopub.execute_input":"2025-01-04T11:39:42.302897Z","iopub.status.idle":"2025-01-04T11:39:42.316372Z","shell.execute_reply.started":"2025-01-04T11:39:42.302878Z","shell.execute_reply":"2025-01-04T11:39:42.315635Z"}},"outputs":[{"name":"stdout","text":"\nКласифікаційний звіт для бінарної моделі:\n\n              precision    recall  f1-score   support\n\n   non_toxic       0.13      0.72      0.22       313\n       toxic       0.94      0.47      0.63      2879\n\n    accuracy                           0.49      3192\n   macro avg       0.53      0.59      0.42      3192\nweighted avg       0.86      0.49      0.59      3192\n\n","output_type":"stream"}],"execution_count":27},{"cell_type":"markdown","source":"**Багатоміткова модель**","metadata":{}},{"cell_type":"markdown","source":"У якості основи для багатоміткової моделі буде взята модель №2 із даного проекту - https://github.com/T-Dzv/toxic_finder/blob/dzv-model-4/model-2.ipynb\n\nЦя модель хоч продемонструвала схильність до визначення більшості коментарів, як токсичних. Проте попри свої недоліки вона дійсно намагалась прогнозувати всі класи токсичності, навіть якщо її результати поки далекі від ідеальних. \n\nНавіть при поточних результатах модель дає не нульовий recall для всіх класів, у тому числі рідких, щого не вдалось добитись у інших спробах (перша частина модулю)\n\nВикористання цієї моделі в пайплайні разом із бінарною моделлю та із донавчанням (фінтюнінг на вибірці лише із токсичних коментарів) має потенціал. ","metadata":{}},{"cell_type":"code","source":"# виділення із вибірки лише токсичних коментарів\n\n# Видбірка токсичних коментарів\nt_toxic_indices = np.any(train_labels == 1, axis=1)\nv_toxic_indices = np.any(val_labels == 1, axis=1)\n\n# Вхідні дані лише для токсичних прикладів\nt_toxic_input_ids = train_input_ids[t_toxic_indices]\nt_toxic_attention_mask = train_attention_mask[t_toxic_indices]\nt_toxic_labels = train_labels[t_toxic_indices]\n\nv_toxic_input_ids = val_input_ids[v_toxic_indices]\nv_toxic_attention_mask = val_attention_mask[v_toxic_indices]\nv_toxic_labels = val_labels[v_toxic_indices]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T11:39:42.317487Z","iopub.execute_input":"2025-01-04T11:39:42.317785Z","iopub.status.idle":"2025-01-04T11:39:42.348633Z","shell.execute_reply.started":"2025-01-04T11:39:42.317756Z","shell.execute_reply":"2025-01-04T11:39:42.347902Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"# Завантаження попердньо навченої моделі\nfrom keras.models import load_model\n\nmodel_path = '/kaggle/input/pretrained/model.h5'\nmodel_3_2 = load_model(model_path, custom_objects={'BertLayer': BertLayer}, compile=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T12:00:14.125867Z","iopub.execute_input":"2025-01-04T12:00:14.126198Z","iopub.status.idle":"2025-01-04T12:00:17.095474Z","shell.execute_reply.started":"2025-01-04T12:00:14.126175Z","shell.execute_reply":"2025-01-04T12:00:17.094812Z"}},"outputs":[{"name":"stderr","text":"Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight']\n- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\nAll the weights of TFBertModel were initialized from the PyTorch model.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n","output_type":"stream"}],"execution_count":45},{"cell_type":"code","source":"model_3_2.compile(\n    optimizer=Nadam(learning_rate=1e-4),\n    loss=lambda y_true, y_pred: weighted_f1_loss(y_true, y_pred, class_weights),\n    metrics=[\"accuracy\", Precision(name=\"precision\"), Recall(name=\"recall\"), f1_metric]\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T12:03:16.478478Z","iopub.execute_input":"2025-01-04T12:03:16.478791Z","iopub.status.idle":"2025-01-04T12:03:16.490191Z","shell.execute_reply.started":"2025-01-04T12:03:16.478768Z","shell.execute_reply":"2025-01-04T12:03:16.489484Z"}},"outputs":[],"execution_count":46},{"cell_type":"markdown","source":"**Фінтюнінг багатоміткової моделі**","metadata":{}},{"cell_type":"code","source":"# Розморозка останніх 4-х шарів BERT\nfor layer in model_3_2.layers:\n    if isinstance(layer, BertLayer):  \n        for bert_layer in layer.bert.bert.encoder.layer[-4:]:  \n            bert_layer.trainable = True\n\nmodel_3_2.compile(\n    optimizer=Nadam(learning_rate=1e-4),\n    loss=lambda y_true, y_pred: weighted_f1_loss(y_true, y_pred, class_weights),\n    metrics=[\"accuracy\", Precision(name=\"precision\"), Recall(name=\"recall\"), f1_metric]\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T12:03:20.592841Z","iopub.execute_input":"2025-01-04T12:03:20.593141Z","iopub.status.idle":"2025-01-04T12:03:20.606257Z","shell.execute_reply.started":"2025-01-04T12:03:20.593117Z","shell.execute_reply":"2025-01-04T12:03:20.605507Z"}},"outputs":[],"execution_count":47},{"cell_type":"code","source":"# Навчання моделі\nhistory_3_2 = model_3_2.fit(\n    {\n        'input_ids': t_toxic_input_ids,\n        'attention_mask': t_toxic_attention_mask\n    },\n    t_toxic_labels,\n    validation_data=(\n        {\n            'input_ids': v_toxic_input_ids,\n            'attention_mask': v_toxic_attention_mask\n        },\n        v_toxic_labels),\n    epochs=3, \n    batch_size=256\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T12:03:26.044888Z","iopub.execute_input":"2025-01-04T12:03:26.045213Z","iopub.status.idle":"2025-01-04T12:10:10.680603Z","shell.execute_reply.started":"2025-01-04T12:03:26.045186Z","shell.execute_reply":"2025-01-04T12:10:10.679705Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/3\n\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 3s/step - accuracy: 0.5929 - f1_metric: 0.5669 - loss: 0.9759 - precision: 0.4286 - recall: 0.8409 - val_accuracy: 0.2605 - val_f1_metric: 0.5651 - val_loss: 0.9770 - val_precision: 0.3965 - val_recall: 0.9819\nEpoch 2/3\n\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 2s/step - accuracy: 0.2394 - f1_metric: 0.5659 - loss: 0.9762 - precision: 0.3981 - recall: 0.9787 - val_accuracy: 0.1554 - val_f1_metric: 0.5634 - val_loss: 0.9770 - val_precision: 0.3944 - val_recall: 0.9839\nEpoch 3/3\n\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 2s/step - accuracy: 0.1628 - f1_metric: 0.5630 - loss: 0.9760 - precision: 0.3944 - recall: 0.9838 - val_accuracy: 0.1329 - val_f1_metric: 0.5585 - val_loss: 0.9770 - val_precision: 0.3891 - val_recall: 0.9878\n","output_type":"stream"}],"execution_count":48},{"cell_type":"code","source":"# Збереження історії змін в JSON\nwith open('history_3_2_fin.json', 'w') as json_file:\n    json.dump(history_3_2.history, json_file)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T12:10:55.460925Z","iopub.execute_input":"2025-01-04T12:10:55.461272Z","iopub.status.idle":"2025-01-04T12:10:55.465531Z","shell.execute_reply.started":"2025-01-04T12:10:55.461244Z","shell.execute_reply":"2025-01-04T12:10:55.464858Z"}},"outputs":[],"execution_count":49},{"cell_type":"code","source":"model_3_2.save(\"model_3_2_fin.h5\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T12:10:58.375221Z","iopub.execute_input":"2025-01-04T12:10:58.375525Z","iopub.status.idle":"2025-01-04T12:10:58.400314Z","shell.execute_reply.started":"2025-01-04T12:10:58.375502Z","shell.execute_reply":"2025-01-04T12:10:58.399379Z"}},"outputs":[],"execution_count":50},{"cell_type":"code","source":"# Прогнози мультиміткової моделі на валідаціних даних\nmul_model_predictions = model_3_2.predict(\n    {'input_ids': v_toxic_input_ids, 'attention_mask': v_toxic_attention_mask},\n    batch_size=64\n)\n\n# Перетворюємо прогнози на бінарні мітки\nmultilabel_predictions = (mul_model_predictions > 0.5).astype(int)\n# Сумуємо значення для кожної мітки\ntoxic_label_counts = multilabel_predictions.sum(axis=0)\n\n# Мітки токсичності\nlabels = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n\nprint(\"\\nРозподіл міток багатоміткової моделі:\")\nfor i, label in enumerate(labels):\n    print(f\"{label}: {toxic_label_counts[i]}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T12:11:08.850739Z","iopub.execute_input":"2025-01-04T12:11:08.851024Z","iopub.status.idle":"2025-01-04T12:11:47.544304Z","shell.execute_reply.started":"2025-01-04T12:11:08.851001Z","shell.execute_reply":"2025-01-04T12:11:47.543576Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 660ms/step\n\nРозподіл міток багатоміткової моделі:\ntoxic: 3244\nsevere_toxic: 2263\nobscene: 3244\nthreat: 2720\ninsult: 3244\nidentity_hate: 3244\n","output_type":"stream"}],"execution_count":51},{"cell_type":"code","source":"# Оцінка моделі\nprint(\"\\nКласифікаційний звіт для другого підходу моделі:\\n\")\nprint(classification_report(v_toxic_labels, multilabel_predictions, target_names=[\n    \"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"\n]))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T12:12:05.258078Z","iopub.execute_input":"2025-01-04T12:12:05.258369Z","iopub.status.idle":"2025-01-04T12:12:05.277555Z","shell.execute_reply.started":"2025-01-04T12:12:05.258346Z","shell.execute_reply":"2025-01-04T12:12:05.276637Z"}},"outputs":[{"name":"stdout","text":"\nКласифікаційний звіт для другого підходу моделі:\n\n               precision    recall  f1-score   support\n\n        toxic       0.94      1.00      0.97      3056\n severe_toxic       0.11      0.77      0.19       321\n      obscene       0.53      1.00      0.69      1715\n       threat       0.02      0.85      0.05        74\n       insult       0.50      1.00      0.66      1614\nidentity_hate       0.09      1.00      0.17       294\n\n    micro avg       0.39      0.99      0.56      7074\n    macro avg       0.37      0.94      0.45      7074\n weighted avg       0.66      0.99      0.75      7074\n  samples avg       0.39      0.99      0.53      7074\n\n","output_type":"stream"}],"execution_count":52},{"cell_type":"markdown","source":"Після фінтюнингу на лише токсичних коментарях модель стала схольною призначати мітку 1 майже всім класам. Спробуємо альтернативно виконати фінтюнинг передавши на навчання повну вибірку даних, включаючи нетоксичні коментарі. ","metadata":{}},{"cell_type":"code","source":"# Завантаження попердньо навченої моделі\nfrom keras.models import load_model\n\nmodel_path = '/kaggle/input/pretrained/model.h5'\nmodel_3_3 = load_model(model_path, custom_objects={'BertLayer': BertLayer}, compile=False)\n\nmodel_3_3.compile(\n    optimizer=Nadam(learning_rate=1e-4),\n    loss=lambda y_true, y_pred: weighted_f1_loss(y_true, y_pred, class_weights),\n    metrics=[\"accuracy\", Precision(name=\"precision\"), Recall(name=\"recall\"), f1_metric]\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T12:14:59.730446Z","iopub.execute_input":"2025-01-04T12:14:59.730785Z","iopub.status.idle":"2025-01-04T12:15:03.659445Z","shell.execute_reply.started":"2025-01-04T12:14:59.730762Z","shell.execute_reply":"2025-01-04T12:15:03.658581Z"}},"outputs":[{"name":"stderr","text":"Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight']\n- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\nAll the weights of TFBertModel were initialized from the PyTorch model.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n","output_type":"stream"}],"execution_count":53},{"cell_type":"code","source":"# Розморозка останніх 4-х шарів BERT\nfor layer in model_3_3.layers:\n    if isinstance(layer, BertLayer):  \n        for bert_layer in layer.bert.bert.encoder.layer[-4:]:  \n            bert_layer.trainable = True\n\nmodel_3_3.compile(\n    optimizer=Nadam(learning_rate=1e-5),\n    loss=lambda y_true, y_pred: weighted_f1_loss(y_true, y_pred, class_weights),\n    metrics=[\"accuracy\", Precision(name=\"precision\"), Recall(name=\"recall\"), f1_metric]\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T12:15:11.201153Z","iopub.execute_input":"2025-01-04T12:15:11.201462Z","iopub.status.idle":"2025-01-04T12:15:11.215164Z","shell.execute_reply.started":"2025-01-04T12:15:11.201436Z","shell.execute_reply":"2025-01-04T12:15:11.214385Z"}},"outputs":[],"execution_count":54},{"cell_type":"code","source":"# Навчання моделі\nhistory_3_3 = model_3_3.fit(\n    {\n        'input_ids': train_input_ids,\n        'attention_mask': train_attention_mask\n    },\n    train_labels,\n    validation_data=(\n        {\n            'input_ids': v_toxic_input_ids,\n            'attention_mask': v_toxic_attention_mask\n        },\n        v_toxic_labels),\n    epochs=3, \n    batch_size=256\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T12:15:16.163209Z","iopub.execute_input":"2025-01-04T12:15:16.163549Z","iopub.status.idle":"2025-01-04T13:05:26.479666Z","shell.execute_reply.started":"2025-01-04T12:15:16.163522Z","shell.execute_reply":"2025-01-04T13:05:26.478926Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/3\n\u001b[1m499/499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1031s\u001b[0m 2s/step - accuracy: 0.7662 - f1_metric: 0.0964 - loss: 0.9967 - precision: 0.0519 - recall: 0.7188 - val_accuracy: 0.6939 - val_f1_metric: 0.5393 - val_loss: 0.9775 - val_precision: 0.4420 - val_recall: 0.6930\nEpoch 2/3\n\u001b[1m499/499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m989s\u001b[0m 2s/step - accuracy: 0.6958 - f1_metric: 0.0947 - loss: 0.9967 - precision: 0.0510 - recall: 0.6899 - val_accuracy: 0.6893 - val_f1_metric: 0.5372 - val_loss: 0.9775 - val_precision: 0.4433 - val_recall: 0.6835\nEpoch 3/3\n\u001b[1m499/499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m989s\u001b[0m 2s/step - accuracy: 0.6646 - f1_metric: 0.0939 - loss: 0.9968 - precision: 0.0506 - recall: 0.6685 - val_accuracy: 0.5968 - val_f1_metric: 0.5254 - val_loss: 0.9775 - val_precision: 0.4310 - val_recall: 0.6746\n","output_type":"stream"}],"execution_count":55},{"cell_type":"code","source":"# Збереження історії змін в JSON\nwith open('history_3_3_fin.json', 'w') as json_file:\n    json.dump(history_3_3.history, json_file)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T13:13:54.488282Z","iopub.execute_input":"2025-01-04T13:13:54.488647Z","iopub.status.idle":"2025-01-04T13:13:54.493179Z","shell.execute_reply.started":"2025-01-04T13:13:54.488618Z","shell.execute_reply":"2025-01-04T13:13:54.492345Z"}},"outputs":[],"execution_count":58},{"cell_type":"code","source":"model_3_3.save(\"model_3_3_fin.h5\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T13:13:57.267068Z","iopub.execute_input":"2025-01-04T13:13:57.267353Z","iopub.status.idle":"2025-01-04T13:13:57.290977Z","shell.execute_reply.started":"2025-01-04T13:13:57.267331Z","shell.execute_reply":"2025-01-04T13:13:57.290300Z"}},"outputs":[],"execution_count":59},{"cell_type":"code","source":"# Прогнози мультиміткової моделі на валідаціних даних\nmul_model_predictions = model_3_3.predict(\n    {'input_ids': v_toxic_input_ids, 'attention_mask': v_toxic_attention_mask},\n    batch_size=64\n)\n\n# Перетворюємо прогнози на бінарні мітки\nmultilabel_predictions = (mul_model_predictions > 0.5).astype(int)\n# Сумуємо значення для кожної мітки\ntoxic_label_counts = multilabel_predictions.sum(axis=0)\n\n# Мітки токсичності\nlabels = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n\nprint(\"\\nРозподіл міток багатоміткової моделі:\")\nfor i, label in enumerate(labels):\n    print(f\"{label}: {toxic_label_counts[i]}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T13:14:06.109565Z","iopub.execute_input":"2025-01-04T13:14:06.109906Z","iopub.status.idle":"2025-01-04T13:14:43.086892Z","shell.execute_reply.started":"2025-01-04T13:14:06.109875Z","shell.execute_reply":"2025-01-04T13:14:43.085875Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 623ms/step\n\nРозподіл міток багатоміткової моделі:\ntoxic: 2462\nsevere_toxic: 1461\nobscene: 1979\nthreat: 1863\ninsult: 1981\nidentity_hate: 1326\n","output_type":"stream"}],"execution_count":61},{"cell_type":"code","source":"# Оцінка моделі\nprint(\"\\nКласифікаційний звіт для другого підходу моделі:\\n\")\nprint(classification_report(v_toxic_labels, multilabel_predictions, target_names=[\n    \"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"\n]))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T13:15:53.019869Z","iopub.execute_input":"2025-01-04T13:15:53.020215Z","iopub.status.idle":"2025-01-04T13:15:53.044412Z","shell.execute_reply.started":"2025-01-04T13:15:53.020184Z","shell.execute_reply":"2025-01-04T13:15:53.043515Z"}},"outputs":[{"name":"stdout","text":"\nКласифікаційний звіт для другого підходу моделі:\n\n               precision    recall  f1-score   support\n\n        toxic       0.95      0.77      0.85      3056\n severe_toxic       0.12      0.54      0.19       321\n      obscene       0.54      0.63      0.58      1715\n       threat       0.02      0.53      0.04        74\n       insult       0.51      0.63      0.57      1614\nidentity_hate       0.09      0.43      0.15       294\n\n    micro avg       0.43      0.67      0.53      7074\n    macro avg       0.37      0.59      0.40      7074\n weighted avg       0.67      0.67      0.65      7074\n  samples avg       0.40      0.68      0.44      7074\n\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"}],"execution_count":62},{"cell_type":"markdown","source":"У другій версії моделі також прослідковується надмірне віднесення прикладів до класів токсичності (модель схильна ставити мітки 1 для більшості класів). Проте у цьому випадку принаймні модель не ставить мітки классу взагалі всім прикладам і у пайплайні з бінарною моделлю має видавати більш релеватні результати. ","metadata":{}},{"cell_type":"markdown","source":"**Побудова загального пайплайну прогнозів**","metadata":{}},{"cell_type":"code","source":"# Додання класу нетоксичних коментарів до міток тестової вибірки (всі нулі)\nall_zeros_class = np.all(test_labels == 0, axis=1).astype(int)  \ny_test_expanded = np.hstack((test_labels, all_zeros_class.reshape(-1, 1)))  ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T13:22:40.704894Z","iopub.execute_input":"2025-01-04T13:22:40.705206Z","iopub.status.idle":"2025-01-04T13:22:40.709978Z","shell.execute_reply.started":"2025-01-04T13:22:40.705183Z","shell.execute_reply":"2025-01-04T13:22:40.709148Z"}},"outputs":[],"execution_count":63},{"cell_type":"code","source":"# Отримання прогнозів для першої моделі\nbinary_predictions = model_3_1.predict(\n    {'input_ids': test_input_ids, 'attention_mask': test_attention_mask},\n    batch_size=64\n)\nbinary_predictions = (binary_predictions > 0.5).astype(int)  # Перетворення в 0 або 1\n\nfinal_predictions = []\n# Проходимо по кожному прикладу даних\nfor i in range(len(test_input_ids)):\n    binary_prediction = binary_predictions[i].item()  # Прогноз бінарної моделі для поточного приклада\n\n    if binary_prediction == 1:\n        # Якщо коментар не токсичний, формуємо фінальний вектор\n        final_predictions.append([0, 0, 0, 0, 0, 0, 1])  # Всі нулі + 1 на останьому індексі\n    else:\n        # Якщо коментар токсичний, формуємо прогноз мультимітковою моделлю\n        toxic_input_ids = test_input_ids[i].reshape(1, -1)  # Приклад в форматі (1, 128)\n        toxic_attention_mask = test_attention_mask[i].reshape(1, -1)\n\n        # Прогноз мультимітковою моделлю\n        multilabel_prediction = model_3_3.predict(\n            {'input_ids': toxic_input_ids, 'attention_mask': toxic_attention_mask},\n            batch_size=1,\n            verbose=0 \n        )\n\n        # Перетворення прогнозів\n        multilabel_result = (multilabel_prediction > 0.5).astype(int).flatten().tolist()\n        multilabel_result.append(0)  # Дадаємо 0 в останній індекс \n\n        # Додаємо результат у фінальні прогнози\n        final_predictions.append(multilabel_result)\n\n# Перетворення фінальних прогнозів в numpy-масив\nfinal_predictions = np.array(final_predictions)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T13:27:05.121019Z","iopub.execute_input":"2025-01-04T13:27:05.121329Z","iopub.status.idle":"2025-01-04T13:29:26.586033Z","shell.execute_reply.started":"2025-01-04T13:27:05.121306Z","shell.execute_reply":"2025-01-04T13:29:26.585096Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 524ms/step\n","output_type":"stream"}],"execution_count":65},{"cell_type":"code","source":"# Оцінка моделі\nprint(\"\\nКласифікаційний звіт для другого підходу моделі:\\n\")\nprint(classification_report(y_test_expanded, final_predictions, target_names=[\n    \"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\", \"non_toxic\"\n]))\n\n# Побудова багатоміткової матриці помилок\nconf_matrices = multilabel_confusion_matrix(y_test_expanded, final_predictions)\n\n# Приклад виводу (наприклад для \"toxic\")\nprint(\"Confusion matrix for 'toxic':\")\nprint(conf_matrices[0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T13:31:18.920133Z","iopub.execute_input":"2025-01-04T13:31:18.920461Z","iopub.status.idle":"2025-01-04T13:31:18.942047Z","shell.execute_reply.started":"2025-01-04T13:31:18.920436Z","shell.execute_reply":"2025-01-04T13:31:18.941241Z"}},"outputs":[{"name":"stdout","text":"\nКласифікаційний звіт для другого підходу моделі:\n\n               precision    recall  f1-score   support\n\n        toxic       0.13      0.69      0.22       304\n severe_toxic       0.02      0.51      0.03        35\n      obscene       0.07      0.61      0.13       173\n       threat       0.00      0.50      0.00         4\n       insult       0.07      0.62      0.13       168\nidentity_hate       0.01      0.32      0.02        28\n    non_toxic       0.94      0.47      0.63      2879\n\n    micro avg       0.19      0.50      0.28      3591\n    macro avg       0.18      0.53      0.17      3591\n weighted avg       0.77      0.50      0.53      3591\n  samples avg       0.46      0.49      0.46      3591\n\nConfusion matrix for 'toxic':\n[[1444 1444]\n [  93  211]]\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"}],"execution_count":66}]}