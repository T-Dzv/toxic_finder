{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10361110,"sourceType":"datasetVersion","datasetId":6416892}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Перевірка підключення GPU\nimport tensorflow as tf\nprint(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.optimizers import Adam, Nadam\nfrom tensorflow.keras.layers import Input, Dense, Layer, Dropout, GlobalAveragePooling1D\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.metrics import Precision, Recall\n\n\nfrom transformers import TFBertForSequenceClassification, TFBertModel\n\nimport numpy as np\nimport pandas as pd\nfrom sklearn.metrics import classification_report, multilabel_confusion_matrix\nfrom sklearn.model_selection import train_test_split","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Підготовка кастомних класів і функцій**","metadata":{}},{"cell_type":"markdown","source":"Даний блок необхідно копіювати при завантажені моделей","metadata":{}},{"cell_type":"code","source":"# Кастомний шар для інтеграції з BERT\nclass BertLayer(Layer):\n    def __init__(self, pretrained_model_name=\"bert-base-uncased\", trainable=False, **kwargs):\n        super(BertLayer, self).__init__(**kwargs)\n        # Завантажуємо попередньо навчений BERT\n        self.bert = TFBertModel.from_pretrained(pretrained_model_name)\n        self.bert.trainable = trainable  # Заморожуємо або розморожуємо шари залежно від параметра trainable\n\n    def call(self, inputs):\n        # Вхідні дані: input_ids та attention_mask\n        input_ids, attention_mask = inputs\n        # Передаємо дані через BERT\n        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n        return outputs.last_hidden_state  # Повертаємо тільки last_hidden_state","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"'''\nу якості метрики обрано Ф-1 у зв'язку із незбалансованістю класів. \nПідготуємо функцію для неї\n'''\n\nimport tensorflow as tf\nfrom tensorflow.keras import backend as K\n\ndef f1_metric(y_true, y_pred):\n    # Преобразуем в бинарный формат для каждого класса\n    y_true = K.cast(y_true, 'int32')\n    y_pred = K.cast(K.greater_equal(y_pred, 0.5), 'int32')\n\n    # Вычисляем точность (precision) и полноту (recall)\n    true_positive = K.sum(K.cast(y_true * y_pred, 'float32'))\n    false_positive = K.sum(K.cast((1 - y_true) * y_pred, 'float32'))\n    false_negative = K.sum(K.cast(y_true * (1 - y_pred), 'float32'))\n\n    precision = true_positive / (true_positive + false_positive + K.epsilon())\n    recall = true_positive / (true_positive + false_negative + K.epsilon())\n\n    # F1-score = 2 * (precision * recall) / (precision + recall)\n    f1 = 2 * (precision * recall) / (precision + recall + K.epsilon())\n    \n    return f1","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"'''\nпідготовка вагів для функції врат щоб врахувати незбалансованість вибірки\n'''\n# Підрахунок ваг для кожного класу\nclass_counts = {\n    0: 15294,  # toxic\n    1: 1595,   # severe_toxic\n    2: 8449,   # obscene\n    3: 478,    # threat\n    4: 7877,   # insult\n    5: 1405    # identity_hate\n}\n\n# Загальна кількість прикладів у вибірці\ntotal_samples = 159571\n\n# Вага для кожного класу буде пропорційною оберненому співвідношенню його частоти\nclass_weights = {}\nfor label, count in class_counts.items():\n    # Вага класу розраховується як обернене відношення загальної кількості прикладів\n    class_weights[label] = total_samples / count\n\n# Нормалізація ваг класів, щоб їх сума була рівна 1\nclass_weights = {k: v / sum(class_weights.values()) for k, v in class_weights.items()}","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import backend as K\n\ndef weighted_f1_loss(y_true, y_pred, class_weights):\n    \"\"\"\n    Кастомна функція втрат для оптимізації макро F1-міри з урахуванням ваг класів.\n    \n    Args:\n        y_true: tf.Tensor, істинні мітки (розмірність [batch_size, num_classes]).\n        y_pred: tf.Tensor, передбачення моделі (розмірність [batch_size, num_classes]).\n        class_weights: dict, ваги класів (ключі - індекси класів, значення - ваги).\n\n    Returns:\n        tf.Tensor, значення функції втрат.\n    \"\"\"\n    # Застосовуємо сигмоїду до передбачень, якщо вони ще не пройшли через активацію\n    y_pred = K.sigmoid(y_pred)\n\n    # Перетворення ваг класів у тензор\n    class_weight_tensor = tf.constant([class_weights[i] for i in range(len(class_weights))], dtype=tf.float32)\n\n    # Обчислення TP, FP, FN\n    true_positives = K.sum(y_true * y_pred, axis=0)\n    predicted_positives = K.sum(y_pred, axis=0)\n    actual_positives = K.sum(y_true, axis=0)\n\n    # Обчислення Precision та Recall для кожного класу\n    precision = true_positives / (predicted_positives + K.epsilon())\n    recall = true_positives / (actual_positives + K.epsilon())\n\n    # Обчислення F1 для кожного класу\n    f1_per_class = 2 * (precision * recall) / (precision + recall + K.epsilon())\n\n    # Застосування ваг класів\n    weighted_f1 = f1_per_class * class_weight_tensor\n\n    # Середнє значення макро F1\n    macro_f1 = K.mean(weighted_f1)\n\n    # Повернення від'ємного значення F1 як функції втрат (для мінімізації)\n    return 1 - macro_f1","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Загальна підготовка даних**","metadata":{}},{"cell_type":"code","source":"data_path = '/kaggle/input/dataset/train_data.csv'\ndf = pd.read_csv(data_path)\n\n# список категорій:\nLABEL_COLUMNS = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n\n# Конвертація токенізованих даних з рядків у масиви\nfor column in ['input_ids', 'attention_masks']:\n    df[column] = df[column].apply(eval).apply(np.array)\n\n# Виділяємо токенізовані вектори та мітки\ninput_ids = np.stack(df['input_ids'].values)\nattention_mask = np.stack(df['attention_masks'].values)\nlabels = np.array(df[LABEL_COLUMNS].values)\nlabels = labels.astype('float32')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Розділення на тренувальну та тестову вибірки (повний набір даних)\n\ntrain_input_ids, val_input_ids, train_attention_mask, val_attention_mask, train_labels, val_labels = train_test_split(\n    input_ids, attention_mask, labels, test_size=0.2, random_state=42\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Бінарна модель**","metadata":{}},{"cell_type":"code","source":"# Генерація міток для бінарної моделі\nt_binary_labels = np.where(np.all(train_labels == 0, axis=1), 1, 0).astype('float32')\nv_binary_labels = np.where(np.all(val_labels == 0, axis=1), 1, 0).astype('float32')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Балансування даних\n\nfrom imblearn.over_sampling import SMOTE\n\nt_features = np.hstack((train_input_ids, train_attention_mask))\n\nsmote = SMOTE(random_state=42)\nt_data_resampled, t_binary_labels_resampled = smote.fit_resample(t_features, t_binary_labels)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# До SMOTE\nprint(\"До обробки:\")\nprint(f\"Токсичні: {np.sum(t_binary_labels == 0)}\")\nprint(f\"Нетоксичні: {np.sum(t_binary_labels == 1)}\")\n\n# Після SMOTE\nprint(\"\\nПісля обробки:\")\nprint(f\"Токсичні: {np.sum(t_binary_labels_resampled == 0)}\")\nprint(f\"Нетоксичні: {np.sum(t_binary_labels_resampled == 1)}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Зворотне перетворення на train_input_ids і t_attention_mask\n\n# Вихідні розміри train_input_ids и train_attention_mask\ninput_ids_size = train_input_ids.shape[1]\nattention_mask_size = train_attention_mask.shape[1]\n\n# Зворотній розподіл\nt_input_ids_resampled = t_data_resampled[:, :input_ids_size]\nt_attention_mask_resampled = t_data_resampled[:, input_ids_size:]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"t_data = {\n    \"input_ids\": t_input_ids_resampled,\n    \"attention_mask\": t_attention_mask_resampled,\n}\n\nv_data = {\n    \"input_ids\": val_input_ids,\n    \"attention_mask\": val_attention_mask,\n}","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Модель для бінарної класифікації\n\n# Вхідні дані\ninput_ids = Input(shape=(128,), dtype=tf.int32, name=\"input_ids\")\nattention_mask = Input(shape=(128,), dtype=tf.int32, name=\"attention_mask\")\n\n# BERT шар\nbert_outputs = BertLayer(trainable=False)([input_ids, attention_mask])\n\n# Пулінг\npooled_output = GlobalAveragePooling1D()(bert_outputs)\n\n# бінарна класифікація\nbinary_dense = Dense(128, activation=\"swish\")(pooled_output)\nbinary_dropout = Dropout(0.3)(binary_dense)\nbinary_output = Dense(1, activation=\"sigmoid\", name=\"binary_output\")(binary_dropout)\n\n# Модель\nmodel_3_1 = Model(\n    inputs=[input_ids, attention_mask],\n    outputs=[binary_output]\n)\n\n# Компіляція моделі\nmodel_3_1.compile(\n    optimizer=Adam(learning_rate=1e-4),\n    loss=\"binary_crossentropy\",\n    metrics=[\"accuracy\"]\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tensorflow.keras.callbacks import EarlyStopping\n\nearly_stopping = EarlyStopping(\n    monitor='val_loss',        \n    patience=3,                \n    restore_best_weights=True  \n)\n\n# Навчання моделі\nhistory_3_1 = model_3_1.fit(\n    t_data,\n    t_binary_labels_resampled,\n    validation_data=(v_data, v_binary_labels),\n    epochs=10,  \n    batch_size=128,\n    callbacks=[early_stopping]  \n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import json\n\n# Збереження історії навчання в JSON\nwith open('history_3_1.json', 'w') as json_file:\n    json.dump(history_3_1.history, json_file)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model_3_1.save(\"model_3_1.h5\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Підготовка частини валідаціної вибірки для прогнозів \n_, test_input_ids, _, test_attention_mask, _, test_labels = train_test_split(\n    val_input_ids, val_attention_mask, val_labels, test_size=0.1, random_state=42\n)\n\ntest_binary_labels = np.where(np.all(test_labels == 0, axis=1), 1, 0).astype('float32')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Отримання прогнозів для першої моделі\nbinary_predictions = model_3_1.predict(\n    {'input_ids': test_input_ids, 'attention_mask': test_attention_mask},\n    batch_size=64\n)\n\nbinary_predictions = (binary_predictions > 0.5).astype(int)  # Перетворення в 0 або 1\n\n# Розподіл прогнозів бінарної моделі\nunique, counts = np.unique(binary_predictions, return_counts=True)\nbinary_distribution = dict(zip(unique, counts))\n\nprint(\"Розподіл міток:\")\nprint(f\"Нетоксичні (1): {binary_distribution.get(1, 0)}\")\nprint(f\"Токсичні (0): {binary_distribution.get(0, 0)}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Розподіл істинних міток\nunique, counts = np.unique(test_binary_labels, return_counts=True)\ntrue_distribution = dict(zip(unique, counts))\n\nprint(\"Розподіл істинних міток:\")\nprint(f\"Нетоксичні (1): {true_distribution.get(1, 0)}\")\nprint(f\"Токсичні (0): {true_distribution.get(0, 0)}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Оцінка моделі\nprint(\"\\nКласифікаційний звіт для бінарної моделі:\\n\")\nprint(classification_report(test_binary_labels, binary_predictions, target_names=[\n    \"non_toxic\", \"toxic\"\n]))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Фінтюнінг бінарної моделі**","metadata":{}},{"cell_type":"code","source":"# Розморозка останніх 4-х шарів BERT\nfor layer in model_3_1.layers:\n    if isinstance(layer, BertLayer):  \n        for bert_layer in layer.bert.bert.encoder.layer[-4:]:  \n            bert_layer.trainable = True\n\nmodel_3_1.compile(\n    optimizer=Adam(learning_rate=1e-5),  # Низкий learning rate для фінтюнинга\n    loss=\"binary_crossentropy\",\n    metrics=[\"accuracy\"]\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Финтюнинг\nhistory_3_1 = model_3_1.fit(\n    t_data,\n    t_binary_labels_resampled,\n    validation_data=(v_data, v_binary_labels),\n    epochs=3,               # Невелика кількість епох, оскільки БЕРТ має навчатись дуже швидко\n    batch_size=128\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Збереження історії змін в JSON\nwith open('history_3_1_fin.json', 'w') as json_file:\n    json.dump(history_3_1.history, json_file)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model_3_1.save(\"model_3_1_fin.h5\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Отримання прогнозів для першої моделі\nbinary_predictions = model_3_1.predict(\n    {'input_ids': test_input_ids, 'attention_mask': test_attention_mask},\n    batch_size=64\n)\n\nbinary_predictions = (binary_predictions > 0.5).astype(int)  # Перетворення в 0 або 1\n\n# Розподіл прогнозів бінарної моделі\nunique, counts = np.unique(binary_predictions, return_counts=True)\nbinary_distribution = dict(zip(unique, counts))\n\nprint(\"Розподіл міток:\")\nprint(f\"Нетоксичні (1): {binary_distribution.get(1, 0)}\")\nprint(f\"Токсичні (0): {binary_distribution.get(0, 0)}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Оцінка моделі\nprint(\"\\nКласифікаційний звіт для бінарної моделі:\\n\")\nprint(classification_report(test_binary_labels, binary_predictions, target_names=[\n    \"non_toxic\", \"toxic\"\n]))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Багатоміткова модель**","metadata":{}},{"cell_type":"markdown","source":"У якості основи для багатоміткової моделі буде взята модель №2 із даного проекту - https://github.com/T-Dzv/toxic_finder/blob/dzv-model-4/model-2.ipynb\n\nЦя модель хоч продемонструвала схильність до визначення більшості коментарів, як токсичних. Проте попри свої недоліки вона дійсно намагалась прогнозувати всі класи токсичності, навіть якщо її результати поки далекі від ідеальних. \n\nНавіть при поточних результатах модель дає не нульовий recall для всіх класів, у тому числі рідких, щого не вдалось добитись у інших спробах (перша частина модулю)\n\nВикористання цієї моделі в пайплайні разом із бінарною моделлю та із донавчанням (фінтюнінг на вибірці лише із токсичних коментарів) має потенціал. ","metadata":{}},{"cell_type":"code","source":"# виділення із вибірки лише токсичних коментарів\n\n# Видбірка токсичних коментарів\nt_toxic_indices = np.any(train_labels == 1, axis=1)\nv_toxic_indices = np.any(val_labels == 1, axis=1)\n\n# Вхідні дані лише для токсичних прикладів\nt_toxic_input_ids = train_input_ids[t_toxic_indices]\nt_toxic_attention_mask = train_attention_mask[t_toxic_indices]\nt_toxic_labels = train_labels[t_toxic_indices]\n\nv_toxic_input_ids = val_input_ids[v_toxic_indices]\nv_toxic_attention_mask = val_attention_mask[v_toxic_indices]\nv_toxic_labels = val_labels[v_toxic_indices]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Завантаження попердньо навченої моделі\nfrom keras.models import load_model\n\nmodel_path = '/kaggle/input/pretrained/model.h5'\nmodel_3_2 = load_model(model_path, custom_objects={'BertLayer': BertLayer}, compile=False)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model_3_2.compile(\n    optimizer=Nadam(learning_rate=1e-4),\n    loss=lambda y_true, y_pred: weighted_f1_loss(y_true, y_pred, class_weights),\n    metrics=[\"accuracy\", Precision(name=\"precision\"), Recall(name=\"recall\"), f1_metric]\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Фінтюнінг багатоміткової моделі**","metadata":{}},{"cell_type":"code","source":"# Розморозка останніх 4-х шарів BERT\nfor layer in model_3_1.layers:\n    if isinstance(layer, BertLayer):  \n        for bert_layer in layer.bert.bert.encoder.layer[-4:]:  \n            bert_layer.trainable = True\n\nmodel_3_2.compile(\n    optimizer=Nadam(learning_rate=1e-4),\n    loss=lambda y_true, y_pred: weighted_f1_loss(y_true, y_pred, class_weights),\n    metrics=[\"accuracy\", Precision(name=\"precision\"), Recall(name=\"recall\"), f1_metric]\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Навчання моделі\nhistory_3_2 = model_3_2.fit(\n    {\n        'input_ids': t_toxic_input_ids,\n        'attention_mask': t_toxic_attention_mask\n    },\n    t_toxic_labels,\n    validation_data=(\n        {\n            'input_ids': v_toxic_input_ids,\n            'attention_mask': v_toxic_attention_mask\n        },\n        v_toxic_labels),\n    epochs=3, \n    batch_size=128\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Збереження історії змін в JSON\nwith open('history_3_2_fin.json', 'w') as json_file:\n    json.dump(history_3_2.history, json_file)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model_3_2.save(\"model_3_2_fin.h5\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Прогнози мультиміткової моделі на валідаціних даних\nmultilabel_predictions = model_3_2.predict(\n    {'input_ids': v_toxic_input_ids, 'attention_mask': v_toxic_attention_mask},\n    batch_size=64\n)\n\n# Перетворюємо прогнози на бінарні мітки\nmultilabel_predictions = (multilabel_predictions > 0.5).astype(int)\n# Сумуємо значення для кожної мітки\ntoxic_label_counts = multilabel_predictions.sum(axis=0)\n\n# Мітки токсичності\nlabels = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n\nprint(\"\\nРозподіл міток багатоміткової моделі:\")\nfor i, label in enumerate(labels):\n    print(f\"{label}: {toxic_label_counts[i]}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Істиний розподіл міток\ntrue_label_counts = v_toxic_labels.sum(axis=0)\n\nprint(\"\\nРозподіл істиних міток:\")\nfor i, label in enumerate(labels):\n    print(f\"{label}: {true_label_counts[i]}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Оцінка моделі\nprint(\"\\nКласифікаційний звіт для другого підходу моделі:\\n\")\nprint(classification_report(v_toxic_labels, multilabel_predictions, target_names=[\n    \"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"\n]))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Побудова загального пайплайну прогнозів**","metadata":{}},{"cell_type":"code","source":"# Додання класу нетоксичних коментарів до міток тестової вибірки (всі нулі)\nall_zeros_class = np.all(test_labels == 0, axis=1).astype(int)  \ny_test_expanded = np.hstack((test_labels, all_zeros_class.reshape(-1, 1)))  \n\n# Отримання прогнозів для першої моделі\nbinary_predictions = model_3_1.predict(\n    {'input_ids': test_input_ids, 'attention_mask': test_attention_mask},\n    batch_size=64\n)\nbinary_predictions = (binary_output > 0.5).astype(int)  # Перетворення в 0 або 1\n\nfinal_predictions = []\n# Проходимо по кодному прикладу даних\nfor i in range(len(test_input_ids)):\n    binary_prediction = binary_predictions[i]  # Прогноз бінарної моделі для поточного приклада\n\n    if binary_prediction == 1:\n        # Якщо коментар не токсичний, формуємо фінальний вектор\n        final_predictions.append([0, 0, 0, 0, 0, 0, 1])  # Всі нулі + 1 на останьому індексі\n    else:\n        # Якщо коментар токсичний, формуємо прогноз мультимітковою моделлю\n        toxic_input_ids = test_input_ids[i].reshape(1, -1)  # Приклад в форматі (1, 128)\n        toxic_attention_mask = test_attention_mask[i].reshape(1, -1)\n\n        # Прогноз мультимітковою моделлю\n        multilabel_prediction = model_3_2.predict(\n            {'input_ids': toxic_input_ids, 'attention_mask': toxic_attention_mask},\n            batch_size=1\n        )\n\n        # Перетворення прогнозів\n        multilabel_result = (multilabel_prediction > 0.5).astype(int).flatten().tolist()\n        multilabel_result.append(0)  # Дадаємо 0 в останній індекс \n\n        # Додаємо результат у фінальні прогнози\n        final_predictions.append(multilabel_result)\n\n# Перетворення фінальних прогнозів в numpy-масив\nfinal_predictions = np.array(final_predictions)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Оцінка моделі\nprint(\"\\nКласифікаційний звіт для другого підходу моделі:\\n\")\nprint(classification_report(y_test_expanded, final_predictions, target_names=[\n    \"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\", \"non_toxic\"\n]))\n\n# Побудова багатоміткової матриці помилок\nconf_matrices = multilabel_confusion_matrix(y_test_expanded, final_predictions)\n\n# Приклад виводу (наприклад для \"toxic\")\nprint(\"Confusion matrix for 'toxic':\")\nprint(conf_matrices[0])","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}