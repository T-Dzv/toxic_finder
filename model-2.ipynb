{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10310286,"sourceType":"datasetVersion","datasetId":6382453}],"dockerImageVersionId":30822,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Розробка моделі, здатної ідентифікувати та класифікувати різні рівні токсичності в коментарях, використовуючи можливості BERT (Bidirectional Encoder Representations from Transformers) для аналізу тексту.\n\nВ цьому модулі ми виконаємо:\n* завантаження попередньо підготовленого датасету\n* за необхідності додаткове перетворення формату даних для передачі у модель\n* виділення із датасету невиличкої тестової вибірки для тестової побудови та навчання моделі з метою економії обчислювальних даних\n* побудову передначеної моделі на основі моделі BERT та підбір її гіперпараметрів.\n* feature extraction\n* fine tuning\n* перевірка чи корректно модель виконує прогнози\n* виконання навчання моделі із вибраною архітектурою на повній тестовій вибірці\n* фінальні валідаційні тести\n\nДаний модуль виконано на kaggle.com. Для відтворення у іншому оточенні може вимагатись адаптація коду. ","metadata":{}},{"cell_type":"markdown","source":"**Частина 1.**\n\nЗавантаження, виділення міні-вибірки для тестової побудови моделі, підготовка даних до передачі у модель","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\n# Шлях до файлу\nfile_path = '/kaggle/input/train-data/train_data.csv'\n\n# Завантаження даних\ndata = pd.read_csv(file_path)\n\n# Перевірка перших кількох рядків\nprint(data.head())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T13:29:05.534867Z","iopub.execute_input":"2024-12-28T13:29:05.535182Z","iopub.status.idle":"2024-12-28T13:29:07.951765Z","shell.execute_reply.started":"2024-12-28T13:29:05.535160Z","shell.execute_reply":"2024-12-28T13:29:07.950837Z"}},"outputs":[{"name":"stdout","text":"                 id                               cleaned_comment_text  \\\n0  0000997932d777bf  Explanation Why the edits made under my userna...   \n1  000103f0d9cfb60f  Daww He matches this background colour Im seem...   \n2  000113f07ec002fd  Hey man Im really not trying to edit war Its j...   \n3  0001b41b1c6bb37e  More I cant make any real suggestions on impro...   \n4  0001d958c54c6e35  You sir are my hero Any chance you remember wh...   \n\n                                           input_ids  \\\n0  [101, 7526, 2339, 1996, 10086, 2015, 2081, 210...   \n1  [101, 4830, 2860, 2860, 2002, 3503, 2023, 4281...   \n2  [101, 4931, 2158, 10047, 2428, 2025, 2667, 200...   \n3  [101, 2062, 1045, 2064, 2102, 2191, 2151, 2613...   \n4  [101, 2017, 2909, 2024, 2026, 5394, 2151, 3382...   \n\n                                     attention_masks  toxic  severe_toxic  \\\n0  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...      0             0   \n1  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...      0             0   \n2  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...      0             0   \n3  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...      0             0   \n4  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...      0             0   \n\n   obscene  threat  insult  identity_hate  \n0        0       0       0              0  \n1        0       0       0              0  \n2        0       0       0              0  \n3        0       0       0              0  \n4        0       0       0              0  \n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"# виводимо загальну інформацію про вибірку\ndata.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T13:29:13.326448Z","iopub.execute_input":"2024-12-28T13:29:13.326775Z","iopub.status.idle":"2024-12-28T13:29:13.384134Z","shell.execute_reply.started":"2024-12-28T13:29:13.326751Z","shell.execute_reply":"2024-12-28T13:29:13.383218Z"}},"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 159571 entries, 0 to 159570\nData columns (total 10 columns):\n #   Column                Non-Null Count   Dtype \n---  ------                --------------   ----- \n 0   id                    159571 non-null  object\n 1   cleaned_comment_text  159571 non-null  object\n 2   input_ids             159571 non-null  object\n 3   attention_masks       159571 non-null  object\n 4   toxic                 159571 non-null  int64 \n 5   severe_toxic          159571 non-null  int64 \n 6   obscene               159571 non-null  int64 \n 7   threat                159571 non-null  int64 \n 8   insult                159571 non-null  int64 \n 9   identity_hate         159571 non-null  int64 \ndtypes: int64(6), object(4)\nmemory usage: 12.2+ MB\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"# перевіряємо унікальні значення для кожного класу\n\n# Підрахунок кількості позитивних прикладів для кожного класу\nclass_distribution = data[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']].sum()\nprint(\"Кількість позитивних прикладів для кожного класу:\\n\", class_distribution)\n\n# Загальна кількість прикладів\ntotal_samples = len(data)\n\n# Відсоткове співвідношення по кожному класу\nclass_percentage = (class_distribution / total_samples) * 100\nprint(\"\\nВідсоткове співвідношення класів:\\n\", class_percentage)\n\n# Підрахунок нетоксичних прикладів\nnon_toxic_count = (data[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']].sum(axis=1) == 0).sum()\nnon_toxic_percentage = (non_toxic_count / total_samples) * 100\n\n# Виведення нетоксичних прикладів\nprint(f\"\\nКількість нетоксичних прикладів: {non_toxic_count}\")\nprint(f\"Відсоток нетоксичних прикладів: {non_toxic_percentage:.2f}%\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T13:29:16.641483Z","iopub.execute_input":"2024-12-28T13:29:16.641802Z","iopub.status.idle":"2024-12-28T13:29:16.673289Z","shell.execute_reply.started":"2024-12-28T13:29:16.641776Z","shell.execute_reply":"2024-12-28T13:29:16.672592Z"}},"outputs":[{"name":"stdout","text":"Кількість позитивних прикладів для кожного класу:\n toxic            15294\nsevere_toxic      1595\nobscene           8449\nthreat             478\ninsult            7877\nidentity_hate     1405\ndtype: int64\n\nВідсоткове співвідношення класів:\n toxic            9.584448\nsevere_toxic     0.999555\nobscene          5.294822\nthreat           0.299553\ninsult           4.936361\nidentity_hate    0.880486\ndtype: float64\n\nКількість нетоксичних прикладів: 143346\nВідсоток нетоксичних прикладів: 89.83%\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"# Створюємо копію даних для міні-вибірки\ndata_copy = data.copy()\n\n# Створення колонки label_combination\ndata_copy['label_combination'] = data_copy[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']].apply(\n    lambda row: '-'.join(row.astype(str)), axis=1\n)\n\n# Видалення рідкісних комбінацій міток у копії\nlabel_counts = data_copy['label_combination'].value_counts()\ndata_copy = data_copy[data_copy['label_combination'].isin(label_counts[label_counts > 1].index)].copy()\n\n# Видалення тимчасової колонки\ndata_copy.drop(columns=['label_combination'], inplace=True)\n\n# Виділення міні-вибірки (10% даних)\nfrom sklearn.model_selection import train_test_split\n\ndata_sample, _ = train_test_split(\n    data_copy,\n    test_size=0.9,  # 10% в міні-вибірку\n    stratify=data_copy[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']],\n    random_state=42\n)\n\nprint(f\"Розмір міні-вибірки: {len(data_sample)}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T18:38:17.240520Z","iopub.execute_input":"2024-12-28T18:38:17.240810Z","iopub.status.idle":"2024-12-28T18:38:25.024321Z","shell.execute_reply.started":"2024-12-28T18:38:17.240788Z","shell.execute_reply":"2024-12-28T18:38:25.023428Z"}},"outputs":[{"name":"stdout","text":"Розмір міні-вибірки: 15956\n","output_type":"stream"}],"execution_count":65},{"cell_type":"code","source":"# Розмір вибірки все же завеликий для тестових цілей, сменшуємо ще\n# Зменшуємо розмір вибірки до 10% без втрати рідкісних класів\nsmaller_sample_size = int(len(data_sample) * 0.1)\n\n# Вибірка випадкових рядків без порушення пропорцій\ndata_sample = data_sample.sample(n=smaller_sample_size, random_state=42)\n\nprint(f\"Кількість прикладів у новій міні-вибірці: {len(data_sample)}\")\n\n# Перевіряємо, чи збережені рідкісні класи\nclass_distribution = data_sample[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']].sum()\nprint(\"Розподіл класів у зменшеній вибірці:\\n\", class_distribution)\n\n# Підрахунок нетоксичних прикладів\nnon_toxic_count = (data_sample[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']].sum(axis=1) == 0).sum()\n\n# Виведення нетоксичних прикладів\nprint(f\"\\nКількість нетоксичних прикладів: {non_toxic_count}\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T18:38:27.675573Z","iopub.execute_input":"2024-12-28T18:38:27.675902Z","iopub.status.idle":"2024-12-28T18:38:27.688908Z","shell.execute_reply.started":"2024-12-28T18:38:27.675875Z","shell.execute_reply":"2024-12-28T18:38:27.688059Z"}},"outputs":[{"name":"stdout","text":"Кількість прикладів у новій міні-вибірці: 1595\nРозподіл класів у зменшеній вибірці:\n toxic            153\nsevere_toxic      21\nobscene           96\nthreat             8\ninsult            80\nidentity_hate     16\ndtype: int64\n\nКількість нетоксичних прикладів: 1437\n","output_type":"stream"}],"execution_count":66},{"cell_type":"code","source":"import tensorflow as tf\n\n# Перетворення input_ids та attention_masks у списки для міні-вибірки\nmini_input_ids = tf.convert_to_tensor(data_sample['input_ids'].apply(eval).tolist())\nmini_attention_masks = tf.convert_to_tensor(data_sample['attention_masks'].apply(eval).tolist())\n\n# Перетворення labels у тензор для міні-вибірки\nmini_labels = tf.convert_to_tensor(data_sample[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']].values)\n\n# Перевірка формату міні-вибірки\nprint(f\"mini_input_ids shape: {mini_input_ids.shape}\")\nprint(f\"mini_attention_masks shape: {mini_attention_masks.shape}\")\nprint(f\"mini_labels shape: {mini_labels.shape}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T13:29:36.201454Z","iopub.execute_input":"2024-12-28T13:29:36.201732Z","iopub.status.idle":"2024-12-28T13:29:36.727900Z","shell.execute_reply.started":"2024-12-28T13:29:36.201711Z","shell.execute_reply":"2024-12-28T13:29:36.727212Z"}},"outputs":[{"name":"stdout","text":"mini_input_ids shape: (1595, 128)\nmini_attention_masks shape: (1595, 128)\nmini_labels shape: (1595, 6)\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"# Створюємо tf.data.Dataset для міні-вибірки\nmini_dataset = tf.data.Dataset.from_tensor_slices(({\n    'input_ids': mini_input_ids,\n    'attention_mask': mini_attention_masks\n}, mini_labels))\n\n# Перевірка кількості прикладів у міні-вибірці\nprint(f\"Кількість прикладів у mini_dataset: {len(mini_dataset)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T13:29:39.647658Z","iopub.execute_input":"2024-12-28T13:29:39.647950Z","iopub.status.idle":"2024-12-28T13:29:39.655036Z","shell.execute_reply.started":"2024-12-28T13:29:39.647930Z","shell.execute_reply":"2024-12-28T13:29:39.654022Z"}},"outputs":[{"name":"stdout","text":"Кількість прикладів у mini_dataset: 1595\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"# Перевірка структури mini_dataset\nfor X, Y in mini_dataset.take(1):  # Перевіряємо структуру\n    print(f\"X (input_ids): {X['input_ids'].shape}\")\n    print(f\"X (attention_mask): {X['attention_mask'].shape}\")\n    print(f\"Y (labels): {Y.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T13:29:41.896093Z","iopub.execute_input":"2024-12-28T13:29:41.896392Z","iopub.status.idle":"2024-12-28T13:29:41.908588Z","shell.execute_reply.started":"2024-12-28T13:29:41.896371Z","shell.execute_reply":"2024-12-28T13:29:41.907783Z"}},"outputs":[{"name":"stdout","text":"X (input_ids): (128,)\nX (attention_mask): (128,)\nY (labels): (6,)\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"'''\nрозбиття вибірки на тренувальну і валідаційну.\nОскільки на цьому етапі ми виконуємо тестову побудову моделі і її точність нам не важлива, \nрозділимо вибірку \"грубо\", ігноруючи диспропорції класів. При роботі із повною вибіркою у\nнаступних частинах коду цей підхід не припустимий та має бути змінений.\n'''\n# Розподіл mini_dataset на тренувальну та валідаційну вибірки\nvalidation_split = 0.2  # 20% для валідації\ntotal_size = len(mini_dataset)\nval_size = int(total_size * validation_split)\n\n# Використовуємо take() і skip() для поділу\nmini_val_dataset = mini_dataset.take(val_size)\nmini_train_dataset = mini_dataset.skip(val_size)\n\n# Перевірка розмірів\nprint(f\"Тренувальна вибірка: {len(mini_train_dataset)} прикладів\")\nprint(f\"Валідаційна вибірка: {len(mini_val_dataset)} прикладів\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T13:29:44.412200Z","iopub.execute_input":"2024-12-28T13:29:44.412506Z","iopub.status.idle":"2024-12-28T13:29:44.421393Z","shell.execute_reply.started":"2024-12-28T13:29:44.412485Z","shell.execute_reply":"2024-12-28T13:29:44.420522Z"}},"outputs":[{"name":"stdout","text":"Тренувальна вибірка: 1276 прикладів\nВалідаційна вибірка: 319 прикладів\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"# Мінімальний тест, щоб переконатись, що модель приймає оброблені дані\nfrom transformers import TFBertModel\n\n# Завантажуємо предобучену модель BERT\nbert_model = TFBertModel.from_pretrained(\"bert-base-uncased\")\n\n# Передаємо батч з розміром 1 у модель\nfor batch in mini_train_dataset.take(1):  # Беремо перший батч\n    mini_inputs, mini_labels = batch\n    mini_input_ids = tf.expand_dims(mini_inputs['input_ids'], axis=0)  # Додаємо розмір батчу\n    mini_attention_mask = tf.expand_dims(mini_inputs['attention_mask'], axis=0)  # Додаємо розмір батчу\n\n    # Передаємо дані у модель\n    outputs = bert_model(input_ids=mini_input_ids, attention_mask=mini_attention_mask)\n    print(\"Модель успішно прийняла дані!\")\n    print(f\"Вихідний shape: {outputs.last_hidden_state.shape}\")\n    break","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T13:29:49.420726Z","iopub.execute_input":"2024-12-28T13:29:49.421065Z","iopub.status.idle":"2024-12-28T13:29:50.796093Z","shell.execute_reply.started":"2024-12-28T13:29:49.421037Z","shell.execute_reply":"2024-12-28T13:29:50.795182Z"}},"outputs":[{"name":"stderr","text":"Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight']\n- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\nAll the weights of TFBertModel were initialized from the PyTorch model.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n","output_type":"stream"},{"name":"stdout","text":"Модель успішно прийняла дані!\nВихідний shape: (1, 128, 768)\n","output_type":"stream"}],"execution_count":26},{"cell_type":"markdown","source":"Модель успішно прийняла данні, що свідчить про те, що підготовка даних для подальної роботи виконана вірно","metadata":{}},{"cell_type":"markdown","source":"**Частина 2**\n\nПобудова і навчання тестової міні-моделі","metadata":{}},{"cell_type":"code","source":"# Створення та тестування кастомного шару для роботи із моделлю БЕРТ\n\nfrom transformers import TFBertModel\nfrom tensorflow.keras.layers import Input, Layer\nfrom tensorflow.keras.models import Model\nimport tensorflow as tf\n\n# Кастомний шар для інтеграції з BERT\nclass BertLayer(Layer):\n    def __init__(self, pretrained_model_name=\"bert-base-uncased\", trainable=False, **kwargs):\n        super(BertLayer, self).__init__(**kwargs)\n        # Завантажуємо попередньо навчений BERT\n        self.bert = TFBertModel.from_pretrained(pretrained_model_name)\n        self.bert.trainable = trainable  # Заморожуємо або розморожуємо шари залежно від параметра trainable\n\n    def call(self, inputs):\n        # Вхідні дані: input_ids та attention_mask\n        input_ids, attention_mask = inputs\n        # Передаємо дані через BERT\n        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n        return outputs.last_hidden_state  # Повертаємо тільки last_hidden_state\n\n# Вхідні тензори\nmini_input_ids = Input(shape=(128,), dtype=tf.int32, name=\"mini_input_ids\")\nmini_attention_mask = Input(shape=(128,), dtype=tf.int32, name=\"mini_attention_mask\")\n\n# Використовуємо кастомний шар BERT\ntest_bert_outputs = BertLayer(trainable=False)([mini_input_ids, mini_attention_mask])\n\n# Створюємо базу моделі\ntest_model = Model(inputs=[mini_input_ids, mini_attention_mask], outputs=test_bert_outputs)\n\n# Перевіряємо архітектуру моделі\ntest_model.summary()\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T13:29:58.662287Z","iopub.execute_input":"2024-12-28T13:29:58.662637Z","iopub.status.idle":"2024-12-28T13:30:01.908544Z","shell.execute_reply.started":"2024-12-28T13:29:58.662604Z","shell.execute_reply":"2024-12-28T13:30:01.907842Z"}},"outputs":[{"name":"stderr","text":"Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight']\n- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\nAll the weights of TFBertModel were initialized from the PyTorch model.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional_2\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_2\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ mini_input_ids            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ -                      │\n│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ mini_attention_mask       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ -                      │\n│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ bert_layer_2 (\u001b[38;5;33mBertLayer\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m768\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ mini_input_ids[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n│                           │                        │                │ mini_attention_mask[\u001b[38;5;34m0\u001b[0m… │\n└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ mini_input_ids            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ mini_attention_mask       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ bert_layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BertLayer</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ mini_input_ids[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n│                           │                        │                │ mini_attention_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}}],"execution_count":27},{"cell_type":"code","source":"'''\nпідготовка вагів для функції врат щоб врахувати незбалансованість вибірки\n'''\n# Підрахунок ваг для кожного класу\nclass_counts = {\n    0: 15294,  # toxic\n    1: 1595,   # severe_toxic\n    2: 8449,   # obscene\n    3: 478,    # threat\n    4: 7877,   # insult\n    5: 1405    # identity_hate\n}\n\n# Загальна кількість прикладів у вибірці\ntotal_samples = 159571\n\n# Вага для кожного класу буде пропорційною оберненому співвідношенню його частоти\nclass_weights = {}\nfor label, count in class_counts.items():\n    # Вага класу розраховується як обернене відношення загальної кількості прикладів\n    class_weights[label] = total_samples / count\n\n# Нормалізація ваг класів, щоб їх сума була рівна 1\nclass_weights = {k: v / sum(class_weights.values()) for k, v in class_weights.items()}\n\n# Виведення ваг класів\nprint(f\"Вага класів: {class_weights}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T14:08:18.246685Z","iopub.execute_input":"2024-12-28T14:08:18.247060Z","iopub.status.idle":"2024-12-28T14:08:18.253749Z","shell.execute_reply.started":"2024-12-28T14:08:18.247027Z","shell.execute_reply":"2024-12-28T14:08:18.252874Z"}},"outputs":[{"name":"stdout","text":"Вага класів: {0: 0.017475888539927716, 1: 0.16757130992454825, 2: 0.03163406785769375, 3: 0.5591553124051349, 4: 0.03393122246155319, 5: 0.190232198811142}\n","output_type":"stream"}],"execution_count":43},{"cell_type":"code","source":"'''\nу якості метрики обрано Ф-1 у зв'язку із незбалансованістю класів. \nПідготуємо функцію для неї\n'''\n\nimport tensorflow as tf\nfrom tensorflow.keras import backend as K\n\ndef f1_metric(y_true, y_pred):\n    # Преобразуем в бинарный формат для каждого класса\n    y_true = K.cast(y_true, 'int32')\n    y_pred = K.cast(K.greater_equal(y_pred, 0.5), 'int32')\n\n    # Вычисляем точность (precision) и полноту (recall)\n    true_positive = K.sum(K.cast(y_true * y_pred, 'float32'))\n    false_positive = K.sum(K.cast((1 - y_true) * y_pred, 'float32'))\n    false_negative = K.sum(K.cast(y_true * (1 - y_pred), 'float32'))\n\n    precision = true_positive / (true_positive + false_positive + K.epsilon())\n    recall = true_positive / (true_positive + false_negative + K.epsilon())\n\n    # F1-score = 2 * (precision * recall) / (precision + recall)\n    f1 = 2 * (precision * recall) / (precision + recall + K.epsilon())\n    \n    return f1\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T13:30:11.543125Z","iopub.execute_input":"2024-12-28T13:30:11.543431Z","iopub.status.idle":"2024-12-28T13:30:11.549052Z","shell.execute_reply.started":"2024-12-28T13:30:11.543408Z","shell.execute_reply":"2024-12-28T13:30:11.548331Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import backend as K\n\ndef weighted_f1_loss(y_true, y_pred, class_weights):\n    \"\"\"\n    Кастомна функція втрат для оптимізації макро F1-міри з урахуванням ваг класів.\n    \n    Args:\n        y_true: tf.Tensor, істинні мітки (розмірність [batch_size, num_classes]).\n        y_pred: tf.Tensor, передбачення моделі (розмірність [batch_size, num_classes]).\n        class_weights: dict, ваги класів (ключі - індекси класів, значення - ваги).\n\n    Returns:\n        tf.Tensor, значення функції втрат.\n    \"\"\"\n    # Застосовуємо сигмоїду до передбачень, якщо вони ще не пройшли через активацію\n    y_pred = K.sigmoid(y_pred)\n\n    # Перетворення ваг класів у тензор\n    class_weight_tensor = tf.constant([class_weights[i] for i in range(len(class_weights))], dtype=tf.float32)\n\n    # Обчислення TP, FP, FN\n    true_positives = K.sum(y_true * y_pred, axis=0)\n    predicted_positives = K.sum(y_pred, axis=0)\n    actual_positives = K.sum(y_true, axis=0)\n\n    # Обчислення Precision та Recall для кожного класу\n    precision = true_positives / (predicted_positives + K.epsilon())\n    recall = true_positives / (actual_positives + K.epsilon())\n\n    # Обчислення F1 для кожного класу\n    f1_per_class = 2 * (precision * recall) / (precision + recall + K.epsilon())\n\n    # Застосування ваг класів\n    weighted_f1 = f1_per_class * class_weight_tensor\n\n    # Середнє значення макро F1\n    macro_f1 = K.mean(weighted_f1)\n\n    # Повернення від'ємного значення F1 як функції втрат (для мінімізації)\n    return 1 - macro_f1\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T14:12:19.041972Z","iopub.execute_input":"2024-12-28T14:12:19.042298Z","iopub.status.idle":"2024-12-28T14:12:19.048113Z","shell.execute_reply.started":"2024-12-28T14:12:19.042274Z","shell.execute_reply":"2024-12-28T14:12:19.047285Z"}},"outputs":[],"execution_count":47},{"cell_type":"code","source":"from tensorflow.keras.layers import GlobalAveragePooling1D, Dense, Dropout\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Nadam\nfrom tensorflow.keras import Input\nfrom tensorflow.keras.metrics import Precision, Recall\nfrom tensorflow.keras.callbacks import EarlyStopping\n\n# Вхідні тензори, що відповідають підготовленим даним\ninput_ids = Input(shape=(128,), dtype=tf.int32, name=\"input_ids\")\nattention_mask = Input(shape=(128,), dtype=tf.int32, name=\"attention_mask\")\n\n# Використання кастомного шару BERT\nbert_outputs = BertLayer(trainable=False)([input_ids, attention_mask])\n\n# Додавання пулингу та денс-шарів\npooled_output = GlobalAveragePooling1D()(bert_outputs)\ndense_output = Dense(256, activation=\"swish\", name=\"dense_layer_1\")(pooled_output)\ndropout_output = Dropout(0.3, name=\"dropout_layer_1\")(dense_output)\nfinal_output = Dense(6, activation=\"sigmoid\", name=\"output_layer\")(dropout_output)\n\n# Створення моделі\nmini_model = Model(inputs=[input_ids, attention_mask], outputs=final_output)\n\n# Компіляція моделі\nmini_model.compile(\n    optimizer=Nadam(learning_rate=1e-4),\n    loss=lambda y_true, y_pred: weighted_f1_loss(y_true, y_pred, class_weights),\n    metrics=[\"accuracy\", Precision(name=\"precision\"), Recall(name=\"recall\"), f1_metric]\n)\n\n# Перевірка архітектури моделі\nmini_model.summary()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T14:12:35.104081Z","iopub.execute_input":"2024-12-28T14:12:35.104368Z","iopub.status.idle":"2024-12-28T14:12:38.104144Z","shell.execute_reply.started":"2024-12-28T14:12:35.104346Z","shell.execute_reply":"2024-12-28T14:12:38.103480Z"}},"outputs":[{"name":"stderr","text":"Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight']\n- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\nAll the weights of TFBertModel were initialized from the PyTorch model.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional_9\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_9\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ input_ids (\u001b[38;5;33mInputLayer\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ -                      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ attention_mask            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ -                      │\n│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ bert_layer_9 (\u001b[38;5;33mBertLayer\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m768\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ input_ids[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],       │\n│                           │                        │                │ attention_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ global_average_pooling1d… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ bert_layer_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)  │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_layer_1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │        \u001b[38;5;34m196,864\u001b[0m │ global_average_poolin… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_layer_1 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ dense_layer_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ output_layer (\u001b[38;5;33mDense\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)              │          \u001b[38;5;34m1,542\u001b[0m │ dropout_layer_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ input_ids (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ attention_mask            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ bert_layer_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BertLayer</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_ids[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       │\n│                           │                        │                │ attention_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ global_average_pooling1d… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ bert_layer_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)  │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">196,864</span> │ global_average_poolin… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ output_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)              │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,542</span> │ dropout_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m198,406\u001b[0m (775.02 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">198,406</span> (775.02 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m198,406\u001b[0m (775.02 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">198,406</span> (775.02 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}}],"execution_count":48},{"cell_type":"code","source":"# Додавання розбиття на батчі\nmini_train_dataset_batched = mini_train_dataset.batch(32)\nmini_val_dataset_batched = mini_val_dataset.batch(32)\n\n# Додавання ранньої зупинки\nearly_stopping = EarlyStopping(\n    monitor=\"val_f1_metric\",  # Моніторимо F1-score на валідаційній вибірці\n    mode=\"max\",  # Ми хочемо максимізувати F1-score\n    patience=3,  # Чекаємо 3 епохи без покращення\n    restore_best_weights=True  # Повертаємо ваги найкращої моделі\n)\n\n# Навчання моделі з додаванням ранньої зупинки\nmini_history = mini_model.fit(\n    mini_train_dataset_batched,  # Тренувальна вибірка\n    validation_data=mini_val_dataset_batched,  # Валідаційна вибірка\n    epochs=10,  \n    callbacks=[early_stopping]  # Додаємо ранню зупинку\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T14:13:15.174805Z","iopub.execute_input":"2024-12-28T14:13:15.175118Z","iopub.status.idle":"2024-12-28T14:16:00.985588Z","shell.execute_reply.started":"2024-12-28T14:13:15.175094Z","shell.execute_reply":"2024-12-28T14:16:00.984881Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/10\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 776ms/step - accuracy: 0.3621 - f1_metric: 0.0674 - loss: 0.9973 - precision: 0.0356 - recall: 0.8510 - val_accuracy: 0.6270 - val_f1_metric: 0.0602 - val_loss: 0.9972 - val_precision: 0.0321 - val_recall: 1.0000\nEpoch 2/10\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 304ms/step - accuracy: 0.3671 - f1_metric: 0.0665 - loss: 0.9973 - precision: 0.0349 - recall: 0.9362 - val_accuracy: 0.8464 - val_f1_metric: 0.0598 - val_loss: 0.9972 - val_precision: 0.0318 - val_recall: 1.0000\nEpoch 3/10\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 308ms/step - accuracy: 0.5059 - f1_metric: 0.0655 - loss: 0.9973 - precision: 0.0341 - recall: 0.9585 - val_accuracy: 0.8777 - val_f1_metric: 0.0601 - val_loss: 0.9972 - val_precision: 0.0320 - val_recall: 1.0000\nEpoch 4/10\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 312ms/step - accuracy: 0.6398 - f1_metric: 0.0679 - loss: 0.9973 - precision: 0.0355 - recall: 0.9918 - val_accuracy: 0.9248 - val_f1_metric: 0.0605 - val_loss: 0.9972 - val_precision: 0.0323 - val_recall: 1.0000\nEpoch 5/10\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 330ms/step - accuracy: 0.7880 - f1_metric: 0.0708 - loss: 0.9973 - precision: 0.0370 - recall: 0.9948 - val_accuracy: 0.9624 - val_f1_metric: 0.0618 - val_loss: 0.9972 - val_precision: 0.0330 - val_recall: 0.9833\nEpoch 6/10\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 340ms/step - accuracy: 0.9003 - f1_metric: 0.0724 - loss: 0.9972 - precision: 0.0380 - recall: 0.9920 - val_accuracy: 0.9624 - val_f1_metric: 0.0621 - val_loss: 0.9972 - val_precision: 0.0332 - val_recall: 1.0000\nEpoch 7/10\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 336ms/step - accuracy: 0.8851 - f1_metric: 0.0711 - loss: 0.9972 - precision: 0.0372 - recall: 0.9863 - val_accuracy: 0.9624 - val_f1_metric: 0.0657 - val_loss: 0.9972 - val_precision: 0.0350 - val_recall: 0.9667\nEpoch 8/10\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 330ms/step - accuracy: 0.8788 - f1_metric: 0.0763 - loss: 0.9972 - precision: 0.0401 - recall: 0.9880 - val_accuracy: 0.9624 - val_f1_metric: 0.0643 - val_loss: 0.9972 - val_precision: 0.0345 - val_recall: 0.9667\nEpoch 9/10\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 325ms/step - accuracy: 0.8791 - f1_metric: 0.0752 - loss: 0.9972 - precision: 0.0394 - recall: 0.9863 - val_accuracy: 0.9624 - val_f1_metric: 0.0672 - val_loss: 0.9972 - val_precision: 0.0361 - val_recall: 0.9667\nEpoch 10/10\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 325ms/step - accuracy: 0.8766 - f1_metric: 0.0766 - loss: 0.9972 - precision: 0.0403 - recall: 0.9697 - val_accuracy: 0.9624 - val_f1_metric: 0.0681 - val_loss: 0.9972 - val_precision: 0.0365 - val_recall: 0.9667\n","output_type":"stream"}],"execution_count":49},{"cell_type":"markdown","source":"У вибірці переважають приклади негативних класів, через що модель схиляється до прогнозування лише цих класів. Це спричиняє недостатнысть позитивних прогнозів, що, у свою чергу, призводить до низьких значень precision та f1_metric.\n\nПроте оскільки тестова модель працює із дуже малою вибіркою, при передачі на навчання повної вибірки, ситуація може дуже покращитись. \n\nОскільки мета данного етапу робіт підготувати та протестувати лише, чи підготовлений код робочий, фактичні результати тимчасово проігноруємо та перейдемо до наступних етапів - донавчання моделі із розмороженими верхніми шарами.","metadata":{}},{"cell_type":"code","source":"# Розморожування верхніх шарів моделі BERT\nfor layer in mini_model.layers:\n    if isinstance(layer, BertLayer):  # Перевіряємо, чи є шаром BERT\n        layer.bert.trainable = True  # Розморожуємо шари для навчання\n\n# Повторна компіляція моделі з меншою швидкістю навчання\nmini_model.compile(\n    optimizer=Nadam(learning_rate=1e-5),  # Зменшена швидкість навчання\n    loss=lambda y_true, y_pred: weighted_f1_loss(y_true, y_pred, class_weights),\n    metrics=[\"accuracy\", Precision(name=\"precision\"), Recall(name=\"recall\"), f1_metric]\n)\n\n# Файн-тюнінг моделі (навчання з розмороженими шарами)\nmini_fine_tune_history = mini_model.fit(\n    mini_train_dataset_batched,  # Тренувальний датасет\n    validation_data=mini_val_dataset_batched,  # Валідаційний датасет\n    epochs=3  # Кількість епох\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T14:21:49.525929Z","iopub.execute_input":"2024-12-28T14:21:49.526261Z","iopub.status.idle":"2024-12-28T14:23:00.951749Z","shell.execute_reply.started":"2024-12-28T14:21:49.526239Z","shell.execute_reply":"2024-12-28T14:23:00.951060Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/3\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 753ms/step - accuracy: 0.8864 - f1_metric: 0.0787 - loss: 0.9972 - precision: 0.0413 - recall: 0.9865 - val_accuracy: 0.9624 - val_f1_metric: 0.0681 - val_loss: 0.9972 - val_precision: 0.0365 - val_recall: 0.9667\nEpoch 2/3\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 292ms/step - accuracy: 0.8818 - f1_metric: 0.0792 - loss: 0.9972 - precision: 0.0417 - recall: 0.9871 - val_accuracy: 0.9624 - val_f1_metric: 0.0682 - val_loss: 0.9972 - val_precision: 0.0365 - val_recall: 0.9667\nEpoch 3/3\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 304ms/step - accuracy: 0.8759 - f1_metric: 0.0786 - loss: 0.9972 - precision: 0.0414 - recall: 0.9823 - val_accuracy: 0.9624 - val_f1_metric: 0.0685 - val_loss: 0.9972 - val_precision: 0.0367 - val_recall: 0.9667\n","output_type":"stream"}],"execution_count":50},{"cell_type":"markdown","source":"Результати метрики F-1 після фінтюнінгу все ще дуже малі, при роботі з повною вибіркою очікується що модель матиме більше прикладів токсичних коментарів різних типів і навчиться краще їх розрізняти. \n\nМета поточного етапу підготувати робочу версію шаблону коду для подальшого навчання моделі. Код відпрацював без помилок і його можна приймати як базу для подальшої роботи. ","metadata":{}},{"cell_type":"markdown","source":"**Частина 3**\n\nПідготовка повної вибірки для передачі у модель","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# Створюємо копію даних для розділення\ndata_copy = data.copy()\n\n# Створення колонки label_combination\ndata_copy['label_combination'] = data_copy[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']].apply(\n    lambda row: '-'.join(row.astype(str)), axis=1\n)\n\n# Видалення рідкісних комбінацій міток у копії\nlabel_counts = data_copy['label_combination'].value_counts()\ndata_copy = data_copy[data_copy['label_combination'].isin(label_counts[label_counts > 1].index)].copy()\n\n# Видалення тимчасової колонки\ndata_copy.drop(columns=['label_combination'], inplace=True)\n\n# Розділення на тренувальну і валідаційну вибірки\ntrain_data, val_data = train_test_split(\n    data_copy,\n    test_size=0.2,  # 20% для валідації\n    stratify=data_copy[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']],\n    random_state=42\n)\n\n# Перевірка розмірів\nprint(f\"Тренувальна вибірка: {len(train_data)} прикладів\")\nprint(f\"Валідаційна вибірка: {len(val_data)} прикладів\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T14:23:46.628053Z","iopub.execute_input":"2024-12-28T14:23:46.628348Z","iopub.status.idle":"2024-12-28T14:23:54.451441Z","shell.execute_reply.started":"2024-12-28T14:23:46.628328Z","shell.execute_reply":"2024-12-28T14:23:54.450609Z"}},"outputs":[{"name":"stdout","text":"Тренувальна вибірка: 127655 прикладів\nВалідаційна вибірка: 31914 прикладів\n","output_type":"stream"}],"execution_count":51},{"cell_type":"code","source":"# перевіряємо унікальні значення для кожного класу для тренувальної вибірки\n\n# Підрахунок кількості позитивних прикладів для кожного класу\nclass_distribution = train_data[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']].sum()\nprint(\"Кількість позитивних прикладів для кожного класу:\\n\", class_distribution)\n\n# Загальна кількість прикладів\ntotal_samples = len(train_data)\n\n# Відсоткове співвідношення по кожному класу\nclass_percentage = (class_distribution / total_samples) * 100\nprint(\"\\nВідсоткове співвідношення класів:\\n\", class_percentage)\n\n# Підрахунок нетоксичних прикладів\nnon_toxic_count = (train_data[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']].sum(axis=1) == 0).sum()\nnon_toxic_percentage = (non_toxic_count / total_samples) * 100\n\n# Виведення нетоксичних прикладів\nprint(f\"\\nКількість нетоксичних прикладів: {non_toxic_count}\")\nprint(f\"Відсоток нетоксичних прикладів: {non_toxic_percentage:.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T14:23:58.104394Z","iopub.execute_input":"2024-12-28T14:23:58.104701Z","iopub.status.idle":"2024-12-28T14:23:58.130267Z","shell.execute_reply.started":"2024-12-28T14:23:58.104678Z","shell.execute_reply":"2024-12-28T14:23:58.129544Z"}},"outputs":[{"name":"stdout","text":"Кількість позитивних прикладів для кожного класу:\n toxic            12233\nsevere_toxic      1274\nobscene           6759\nthreat             382\ninsult            6300\nidentity_hate     1122\ndtype: int64\n\nВідсоткове співвідношення класів:\n toxic            9.582860\nsevere_toxic     0.998002\nobscene          5.294740\nthreat           0.299244\ninsult           4.935177\nidentity_hate    0.878931\ndtype: float64\n\nКількість нетоксичних прикладів: 114677\nВідсоток нетоксичних прикладів: 89.83%\n","output_type":"stream"}],"execution_count":52},{"cell_type":"code","source":"# перевіряємо унікальні значення для кожного класу для валідаційної вибірки\n\n# Підрахунок кількості позитивних прикладів для кожного класу\nclass_distribution = val_data[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']].sum()\nprint(\"Кількість позитивних прикладів для кожного класу:\\n\", class_distribution)\n\n# Загальна кількість прикладів\ntotal_samples = len(val_data)\n\n# Відсоткове співвідношення по кожному класу\nclass_percentage = (class_distribution / total_samples) * 100\nprint(\"\\nВідсоткове співвідношення класів:\\n\", class_percentage)\n\n# Підрахунок нетоксичних прикладів\nnon_toxic_count = (val_data[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']].sum(axis=1) == 0).sum()\nnon_toxic_percentage = (non_toxic_count / total_samples) * 100\n\n# Виведення нетоксичних прикладів\nprint(f\"\\nКількість нетоксичних прикладів: {non_toxic_count}\")\nprint(f\"Відсоток нетоксичних прикладів: {non_toxic_percentage:.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T14:24:02.426806Z","iopub.execute_input":"2024-12-28T14:24:02.427233Z","iopub.status.idle":"2024-12-28T14:24:02.444593Z","shell.execute_reply.started":"2024-12-28T14:24:02.427192Z","shell.execute_reply":"2024-12-28T14:24:02.443559Z"}},"outputs":[{"name":"stdout","text":"Кількість позитивних прикладів для кожного класу:\n toxic            3059\nsevere_toxic      319\nobscene          1690\nthreat             94\ninsult           1576\nidentity_hate     282\ndtype: int64\n\nВідсоткове співвідношення класів:\n toxic            9.585135\nsevere_toxic     0.999561\nobscene          5.295482\nthreat           0.294542\ninsult           4.938272\nidentity_hate    0.883625\ndtype: float64\n\nКількість нетоксичних прикладів: 28669\nВідсоток нетоксичних прикладів: 89.83%\n","output_type":"stream"}],"execution_count":53},{"cell_type":"markdown","source":"Вибірка розподілена рівномірно з врахуванням пропорцій класів.","metadata":{}},{"cell_type":"code","source":"# Перетворення тренувальної вибірки\n\nimport tensorflow as tf\n\n# Перетворення input_ids та attention_masks у списки\ninput_ids = tf.convert_to_tensor(train_data['input_ids'].apply(eval).tolist())\nattention_masks = tf.convert_to_tensor(train_data['attention_masks'].apply(eval).tolist())\n\n# Перетворення labels у тензор\nlabels = tf.convert_to_tensor(train_data[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']].values)\n\n# Перевірка формату\nprint(f\"input_ids shape: {input_ids.shape}\")\nprint(f\"attention_masks shape: {attention_masks.shape}\")\nprint(f\"labels shape: {labels.shape}\")\n\n# Створюємо tf.data.Dataset\ntrain_dataset = tf.data.Dataset.from_tensor_slices(({\n    'input_ids': input_ids,\n    'attention_mask': attention_masks\n}, labels))\n\n# Перевірка кількості прикладів\nprint(f\"Кількість прикладів у dataset: {len(train_dataset)}\")\n\n# Перевірка структури train_dataset\nfor X, Y in train_dataset.take(1):  # Перевіряємо структуру\n    print(f\"X (input_ids): {X['input_ids'].shape}\")\n    print(f\"X (attention_mask): {X['attention_mask'].shape}\")\n    print(f\"Y (labels): {Y.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T14:24:10.013530Z","iopub.execute_input":"2024-12-28T14:24:10.013843Z","iopub.status.idle":"2024-12-28T14:24:52.777396Z","shell.execute_reply.started":"2024-12-28T14:24:10.013819Z","shell.execute_reply":"2024-12-28T14:24:52.776453Z"}},"outputs":[{"name":"stdout","text":"input_ids shape: (127655, 128)\nattention_masks shape: (127655, 128)\nlabels shape: (127655, 6)\nКількість прикладів у dataset: 127655\nX (input_ids): (128,)\nX (attention_mask): (128,)\nY (labels): (6,)\n","output_type":"stream"}],"execution_count":54},{"cell_type":"code","source":"# Перетворення валідаційної вибірки\n\n# Перетворення input_ids та attention_masks у списки для валідаційної вибірки\nval_input_ids = tf.convert_to_tensor(val_data['input_ids'].apply(eval).tolist())\nval_attention_masks = tf.convert_to_tensor(val_data['attention_masks'].apply(eval).tolist())\n\n# Перетворення labels у тензор для валідаційної вибірки\nval_labels = tf.convert_to_tensor(val_data[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']].values)\n\n# Перевірка формату\nprint(f\"val_input_ids shape: {val_input_ids.shape}\")\nprint(f\"val_attention_masks shape: {val_attention_masks.shape}\")\nprint(f\"val_labels shape: {val_labels.shape}\")\n\n# Створюємо tf.data.Dataset для валідаційної вибірки\nval_dataset = tf.data.Dataset.from_tensor_slices(({\n    'input_ids': val_input_ids,\n    'attention_mask': val_attention_masks\n}, val_labels))\n\n# Перевірка кількості прикладів\nprint(f\"Кількість прикладів у val_dataset: {len(val_dataset)}\")\n\n# Перевірка структури val_dataset\nfor X, Y in val_dataset.take(1):  # Перевіряємо структуру\n    print(f\"X (val_input_ids): {X['input_ids'].shape}\")\n    print(f\"X (val_attention_mask): {X['attention_mask'].shape}\")\n    print(f\"Y (val_labels): {Y.shape}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T14:24:56.092377Z","iopub.execute_input":"2024-12-28T14:24:56.092675Z","iopub.status.idle":"2024-12-28T14:25:06.559414Z","shell.execute_reply.started":"2024-12-28T14:24:56.092651Z","shell.execute_reply":"2024-12-28T14:25:06.558506Z"}},"outputs":[{"name":"stdout","text":"val_input_ids shape: (31914, 128)\nval_attention_masks shape: (31914, 128)\nval_labels shape: (31914, 6)\nКількість прикладів у val_dataset: 31914\nX (val_input_ids): (128,)\nX (val_attention_mask): (128,)\nY (val_labels): (6,)\n","output_type":"stream"}],"execution_count":55},{"cell_type":"code","source":"# Мінімальний тест, щоб переконатись, що модель приймає оброблені дані\nfrom transformers import TFBertModel\n\n# Завантажуємо предобучену модель BERT\nbert_model = TFBertModel.from_pretrained(\"bert-base-uncased\")\n\n# Передаємо батч з розміром 1 у модель\nfor batch in train_dataset.take(1):  # Беремо перший батч\n    inputs, labels = batch\n    input_ids = tf.expand_dims(inputs['input_ids'], axis=0)  # Додаємо розмір батчу\n    attention_mask = tf.expand_dims(inputs['attention_mask'], axis=0)  # Додаємо розмір батчу\n\n    # Передаємо дані у модель\n    outputs = bert_model(input_ids=input_ids, attention_mask=attention_mask)\n    print(\"Модель успішно прийняла дані!\")\n    print(f\"Вихідний shape: {outputs.last_hidden_state.shape}\")\n    break","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T14:25:15.739761Z","iopub.execute_input":"2024-12-28T14:25:15.740091Z","iopub.status.idle":"2024-12-28T14:25:17.285290Z","shell.execute_reply.started":"2024-12-28T14:25:15.740065Z","shell.execute_reply":"2024-12-28T14:25:17.284398Z"}},"outputs":[{"name":"stderr","text":"Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight']\n- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\nAll the weights of TFBertModel were initialized from the PyTorch model.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n","output_type":"stream"},{"name":"stdout","text":"Модель успішно прийняла дані!\nВихідний shape: (1, 128, 768)\n","output_type":"stream"}],"execution_count":56},{"cell_type":"markdown","source":"**Частина 4**\n\nСтворення моделі та навчання на повній вибірці даних","metadata":{}},{"cell_type":"code","source":"# Вхідні тензори\ninput_ids = Input(shape=(128,), dtype=tf.int32, name=\"input_ids\")\nattention_mask = Input(shape=(128,), dtype=tf.int32, name=\"attention_mask\")\n\n# Використання кастомного шару BERT\nbert_outputs = BertLayer(trainable=False)([input_ids, attention_mask])\n\n# Додавання пулингу та денс-шарів\npooled_output = GlobalAveragePooling1D()(bert_outputs)\ndense_output = Dense(256, activation=\"swish\", name=\"dense_layer_1\")(pooled_output)\ndropout_output = Dropout(0.3, name=\"dropout_layer_1\")(dense_output)\nfinal_output = Dense(6, activation=\"sigmoid\", name=\"output_layer\")(dropout_output)\n\n# Створення моделі\nmodel = Model(inputs=[input_ids, attention_mask], outputs=final_output)\n\n# Компіляція моделі\nmodel.compile(\n    optimizer=Nadam(learning_rate=1e-4),\n    loss=lambda y_true, y_pred: weighted_f1_loss(y_true, y_pred, class_weights),\n    metrics=[\"accuracy\", Precision(name=\"precision\"), Recall(name=\"recall\"), f1_metric]\n)\n\n# Перевірка архітектури моделі\nmodel.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T14:26:01.461596Z","iopub.execute_input":"2024-12-28T14:26:01.461948Z","iopub.status.idle":"2024-12-28T14:26:04.389190Z","shell.execute_reply.started":"2024-12-28T14:26:01.461920Z","shell.execute_reply":"2024-12-28T14:26:04.388306Z"}},"outputs":[{"name":"stderr","text":"Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight']\n- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\nAll the weights of TFBertModel were initialized from the PyTorch model.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional_10\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_10\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ input_ids (\u001b[38;5;33mInputLayer\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ -                      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ attention_mask            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ -                      │\n│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ bert_layer_10 (\u001b[38;5;33mBertLayer\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m768\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ input_ids[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],       │\n│                           │                        │                │ attention_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ global_average_pooling1d… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ bert_layer_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)  │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_layer_1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │        \u001b[38;5;34m196,864\u001b[0m │ global_average_poolin… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_layer_1 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ dense_layer_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ output_layer (\u001b[38;5;33mDense\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)              │          \u001b[38;5;34m1,542\u001b[0m │ dropout_layer_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ input_ids (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ attention_mask            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ bert_layer_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BertLayer</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_ids[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       │\n│                           │                        │                │ attention_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ global_average_pooling1d… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ bert_layer_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)  │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">196,864</span> │ global_average_poolin… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ output_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)              │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,542</span> │ dropout_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m198,406\u001b[0m (775.02 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">198,406</span> (775.02 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m198,406\u001b[0m (775.02 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">198,406</span> (775.02 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}}],"execution_count":57},{"cell_type":"code","source":"# Додавання розбиття на батчі, для повної вибірки розмір батчу збільшено\ntrain_dataset_batched = train_dataset.batch(128)\nval_dataset_batched = val_dataset.batch(128)\n\n# Додавання ранньої зупинки\nearly_stopping_new = EarlyStopping(\n    monitor=\"val_f1_metric\",  # Моніторимо F1-score на валідаційній вибірці\n    mode=\"max\",  # Ми хочемо максимізувати F1-score\n    patience=10,  # Чекаємо 10 епох без покращення\n    restore_best_weights=True  # Повертаємо ваги найкращої моделі\n)\n\n# Навчання моделі з додаванням ранньої зупинки\nhistory = model.fit(\n    train_dataset_batched,  # Тренувальна вибірка\n    validation_data=val_dataset_batched,  # Валідаційна вибірка\n    epochs=50,  # Збільшено кількість епох\n    callbacks=[early_stopping_new]  # Додаємо ранню зупинку\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T14:26:25.755131Z","iopub.execute_input":"2024-12-28T14:26:25.755415Z","iopub.status.idle":"2024-12-28T18:15:55.725793Z","shell.execute_reply.started":"2024-12-28T14:26:25.755395Z","shell.execute_reply":"2024-12-28T18:15:55.724809Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/50\n\u001b[1m998/998\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1284s\u001b[0m 1s/step - accuracy: 0.5651 - f1_metric: 0.0825 - loss: 0.9968 - precision: 0.0433 - recall: 0.8713 - val_accuracy: 0.8528 - val_f1_metric: 0.0970 - val_loss: 0.9968 - val_precision: 0.0521 - val_recall: 0.7269\nEpoch 2/50\n\u001b[1m998/998\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1251s\u001b[0m 1s/step - accuracy: 0.5937 - f1_metric: 0.0931 - loss: 0.9968 - precision: 0.0503 - recall: 0.6711 - val_accuracy: 0.8996 - val_f1_metric: 0.0924 - val_loss: 0.9968 - val_precision: 0.0498 - val_recall: 0.6725\nEpoch 3/50\n\u001b[1m998/998\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1248s\u001b[0m 1s/step - accuracy: 0.6232 - f1_metric: 0.0919 - loss: 0.9968 - precision: 0.0497 - recall: 0.6467 - val_accuracy: 0.5147 - val_f1_metric: 0.0916 - val_loss: 0.9967 - val_precision: 0.0495 - val_recall: 0.6500\nEpoch 4/50\n\u001b[1m998/998\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1249s\u001b[0m 1s/step - accuracy: 0.5727 - f1_metric: 0.0906 - loss: 0.9968 - precision: 0.0490 - recall: 0.6500 - val_accuracy: 0.7074 - val_f1_metric: 0.0898 - val_loss: 0.9967 - val_precision: 0.0485 - val_recall: 0.6430\nEpoch 5/50\n\u001b[1m998/998\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1249s\u001b[0m 1s/step - accuracy: 0.5292 - f1_metric: 0.0903 - loss: 0.9968 - precision: 0.0488 - recall: 0.6429 - val_accuracy: 0.8634 - val_f1_metric: 0.0903 - val_loss: 0.9967 - val_precision: 0.0486 - val_recall: 0.6671\nEpoch 6/50\n\u001b[1m998/998\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1249s\u001b[0m 1s/step - accuracy: 0.5979 - f1_metric: 0.0912 - loss: 0.9968 - precision: 0.0493 - recall: 0.6532 - val_accuracy: 0.6340 - val_f1_metric: 0.0885 - val_loss: 0.9967 - val_precision: 0.0475 - val_recall: 0.6708\nEpoch 7/50\n\u001b[1m998/998\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1248s\u001b[0m 1s/step - accuracy: 0.5315 - f1_metric: 0.0901 - loss: 0.9968 - precision: 0.0486 - recall: 0.6560 - val_accuracy: 0.4279 - val_f1_metric: 0.0878 - val_loss: 0.9967 - val_precision: 0.0473 - val_recall: 0.6464\nEpoch 8/50\n\u001b[1m998/998\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1248s\u001b[0m 1s/step - accuracy: 0.3646 - f1_metric: 0.0877 - loss: 0.9968 - precision: 0.0473 - recall: 0.6558 - val_accuracy: 0.6114 - val_f1_metric: 0.0887 - val_loss: 0.9967 - val_precision: 0.0477 - val_recall: 0.6717\nEpoch 9/50\n\u001b[1m998/998\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1249s\u001b[0m 1s/step - accuracy: 0.5014 - f1_metric: 0.0905 - loss: 0.9967 - precision: 0.0488 - recall: 0.6629 - val_accuracy: 0.7562 - val_f1_metric: 0.0891 - val_loss: 0.9967 - val_precision: 0.0480 - val_recall: 0.6625\nEpoch 10/50\n\u001b[1m998/998\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1248s\u001b[0m 1s/step - accuracy: 0.6021 - f1_metric: 0.0910 - loss: 0.9967 - precision: 0.0492 - recall: 0.6498 - val_accuracy: 0.5208 - val_f1_metric: 0.0893 - val_loss: 0.9967 - val_precision: 0.0480 - val_recall: 0.6701\nEpoch 11/50\n\u001b[1m998/998\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1247s\u001b[0m 1s/step - accuracy: 0.5008 - f1_metric: 0.0905 - loss: 0.9967 - precision: 0.0488 - recall: 0.6652 - val_accuracy: 0.6246 - val_f1_metric: 0.0885 - val_loss: 0.9967 - val_precision: 0.0476 - val_recall: 0.6674\n","output_type":"stream"}],"execution_count":58},{"cell_type":"code","source":"model.save(\"model.h5\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T18:18:30.126642Z","iopub.execute_input":"2024-12-28T18:18:30.127097Z","iopub.status.idle":"2024-12-28T18:18:30.160620Z","shell.execute_reply.started":"2024-12-28T18:18:30.127067Z","shell.execute_reply":"2024-12-28T18:18:30.159968Z"}},"outputs":[],"execution_count":59},{"cell_type":"code","source":"from sklearn.metrics import classification_report, confusion_matrix\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Підготовка даних з mini_dataset замість тестових\nx_test = []\ny_test = []\n\nfor x, y in mini_dataset.batch(1):\n    x_test.append({\n        'input_ids': x['input_ids'][0].numpy(),\n        'attention_mask': x['attention_mask'][0].numpy()\n    })\n    y_test.append(y.numpy()[0])\n\ny_test = np.array(y_test)\n\n# Додання класу нетоксичних коментарів у мітки (всі нулі)\nall_zeros_class = np.all(y_test == 0, axis=1)\ny_test_expanded = np.hstack((y_test, all_zeros_class.reshape(-1, 1)))\n\n# Перетворення x_test в формат, зрозумілий моделі\ninput_ids = np.array([sample['input_ids'] for sample in x_test])\nattention_masks = np.array([sample['attention_mask'] for sample in x_test])\n\n# Прогнозування\npredictions = mini_model.predict({'input_ids': input_ids, 'attention_mask': attention_masks})\npredicted_classes = (predictions > 0.5).astype(int)  # Бінарізація прогнозу\n\n# Додання класу нетоксичних коментарів у прогноз\npredicted_all_zeros_class = np.all(predicted_classes == 0, axis=1)\npredicted_classes_expanded = np.hstack((predicted_classes, predicted_all_zeros_class.reshape(-1, 1)))\n\n# Оцінка моделі\nprint(\"\\nКласифікаційний звіт:\\n\")\nprint(classification_report(y_test_expanded, predicted_classes_expanded, target_names=[\n    \"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\", \"non_toxic\"\n]))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T18:29:26.306027Z","iopub.execute_input":"2024-12-28T18:29:26.306318Z","iopub.status.idle":"2024-12-28T18:29:38.896499Z","shell.execute_reply.started":"2024-12-28T18:29:26.306296Z","shell.execute_reply":"2024-12-28T18:29:38.895568Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 222ms/step\n\nКласифікаційний звіт:\n\n               precision    recall  f1-score   support\n\n        toxic       0.10      1.00      0.18       153\n severe_toxic       0.02      0.71      0.03        21\n      obscene       0.06      1.00      0.11        96\n       threat       0.01      0.88      0.02         8\n       insult       0.05      1.00      0.10        80\nidentity_hate       0.01      1.00      0.02        16\n    non_toxic       0.00      0.00      0.00      1437\n\n    micro avg       0.05      0.20      0.08      1811\n    macro avg       0.03      0.80      0.07      1811\n weighted avg       0.01      0.20      0.03      1811\n  samples avg       0.05      0.10      0.06      1811\n\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"}],"execution_count":62},{"cell_type":"code","source":"# Розподіл класів в predicted_classes_expanded\npredicted_class_distribution = np.sum(predicted_classes_expanded, axis=0)\nprint(\"\\nРозподіл класів в predicted_classes_expanded:\")\nfor i, count in enumerate(predicted_class_distribution):\n    print(f\"Клас {i}: {count}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T19:09:09.471109Z","iopub.execute_input":"2024-12-28T19:09:09.471426Z","iopub.status.idle":"2024-12-28T19:09:09.478494Z","shell.execute_reply.started":"2024-12-28T19:09:09.471403Z","shell.execute_reply":"2024-12-28T19:09:09.477560Z"}},"outputs":[{"name":"stdout","text":"\nРозподіл класів в predicted_classes_expanded:\nКлас 0: 1595\nКлас 1: 923\nКлас 2: 1595\nКлас 3: 608\nКлас 4: 1595\nКлас 5: 1591\nКлас 6: 0\n","output_type":"stream"}],"execution_count":78},{"cell_type":"code","source":"# Розподіл дійсних класів\nclass_distribution = np.sum(y_test_expanded, axis=0)\nprint(\"Розподіл класів в y_test_expanded:\")\nfor i, count in enumerate(class_distribution):\n    print(f\"Клас {i}: {count}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T19:10:16.441805Z","iopub.execute_input":"2024-12-28T19:10:16.442136Z","iopub.status.idle":"2024-12-28T19:10:16.448673Z","shell.execute_reply.started":"2024-12-28T19:10:16.442110Z","shell.execute_reply":"2024-12-28T19:10:16.447839Z"}},"outputs":[{"name":"stdout","text":"Розподіл класів в y_test_expanded:\nКлас 0: 153\nКлас 1: 21\nКлас 2: 96\nКлас 3: 8\nКлас 4: 80\nКлас 5: 16\nКлас 6: 1437\n","output_type":"stream"}],"execution_count":79},{"cell_type":"code","source":"from sklearn.metrics import multilabel_confusion_matrix\n\n# Побудова багатоміткової confusion matrix\nconf_matrices = multilabel_confusion_matrix(y_test_expanded, predicted_classes_expanded)\n\n# Приклад виводу для окремої мітки (наприклад, \"toxic\")\nprint(\"Confusion matrix for 'toxic':\")\nprint(conf_matrices[0])\n\n# Візуалізація:\nplt.figure(figsize=(10, 8))\nsns.heatmap(conf_matrices[0], annot=True, fmt='d', cmap='Blues')\nplt.title(\"Confusion Matrix for 'toxic'\")\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"True\")\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T19:12:58.414224Z","iopub.execute_input":"2024-12-28T19:12:58.414531Z","iopub.status.idle":"2024-12-28T19:12:58.675716Z","shell.execute_reply.started":"2024-12-28T19:12:58.414509Z","shell.execute_reply":"2024-12-28T19:12:58.674788Z"}},"outputs":[{"name":"stdout","text":"Confusion matrix for 'toxic':\n[[   0 1442]\n [   0  153]]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 1000x800 with 2 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":80},{"cell_type":"code","source":"# Цей код не виконувався і показаний для прикладу\n# Розморожування верхніх шарів моделі BERT\nfor layer in model.layers:\n    if isinstance(layer, BertLayer):  # Перевіряємо, чи є шаром BERT\n        layer.bert.trainable = True  # Розморожуємо шари для навчання\n\n# Повторна компіляція моделі з меншою швидкістю навчання\nmodel.compile(\n    optimizer=Nadam(learning_rate=1e-5),  # Зменшена швидкість навчання\n    loss=lambda y_true, y_pred: weighted_f1_loss(y_true, y_pred, class_weights),\n    metrics=[\"accuracy\", Precision(name=\"precision\"), Recall(name=\"recall\"), f1_metric]\n)\n\n# Файн-тюнінг моделі (навчання з розмороженими шарами)\n'''\nЧерез погані результати попреднього етапу навчання моделі, скорочуємо кількість епох для мінімізації \nобчислень і отримання мінімальної робочої моделі для тестування наступних модулів. Паралельно буде \nпродовжена робота зі створення моделі із прийнятними результатами \n'''\nfine_tune_history = model.fit(\n    train_dataset_batched,  # Тренувальний датасет\n    validation_data=val_dataset_batched,  # Валідаційний датасет\n    epochs=5\n)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}