{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10357240,"sourceType":"datasetVersion","datasetId":6414196}],"dockerImageVersionId":30822,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Розробка моделі, здатної ідентифікувати та класифікувати різні рівні токсичності в коментарях, використовуючи можливості BERT (Bidirectional Encoder Representations from Transformers) для аналізу тексту.\n\nЗагальний опис проблеми та підходу.\n\nДля навчання наявна дуже незбалансована вибірка і задача з багатоміткової класифікації досить складна. Тому планується застосувати багатозадачний підхід і в моделі виконувати класифікацію у два етапи:\n\n* бінарна класифікація: токсичні - нетоксичні коментарі\n* серед токсичних коментарів: багатоміткова класифікація типу токсичності\n\nВ рамках цього модулю буде виконано:\n\n* Підготовка датасету до передачі у модель: перетворення форматів для прийняття даних моделлю, виділення міні-вибірки для навчання тестових версій моделі і вибору оптимальної архітектури.\n* Розробка і тестування архітектури моделі: на цьому етапі планується виконати декілька варіантів моделі із різною логікою, протестувати чи працює код, виконати навчання підготовлених моделей на міні-вибірці з метою вибору кращої архітектури.\n* Робота над покращенням архітектурних рішень у вибраному підході\n\nНавчання моделі на повному наборі тренувальних даних із вибраною архітектурою буде виконано у окремому ноутбуці (другий розділ).\n\n","metadata":{}},{"cell_type":"code","source":"# Перевірка підключення GPU\nimport tensorflow as tf\nprint(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T12:54:56.304948Z","iopub.execute_input":"2025-01-03T12:54:56.305137Z","iopub.status.idle":"2025-01-03T12:55:11.328411Z","shell.execute_reply.started":"2025-01-03T12:54:56.305119Z","shell.execute_reply":"2025-01-03T12:55:11.327661Z"}},"outputs":[{"name":"stdout","text":"Num GPUs Available:  2\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.layers import Input, Dense, Layer, Dropout, GlobalAveragePooling1D\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.metrics import Precision, Recall\n\n\nfrom transformers import TFBertForSequenceClassification, TFBertModel\n\nimport numpy as np\nimport pandas as pd\nfrom sklearn.metrics import classification_report, multilabel_confusion_matrix\nfrom sklearn.model_selection import train_test_split\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T12:55:14.530123Z","iopub.execute_input":"2025-01-03T12:55:14.530486Z","iopub.status.idle":"2025-01-03T12:55:22.950001Z","shell.execute_reply.started":"2025-01-03T12:55:14.530457Z","shell.execute_reply":"2025-01-03T12:55:22.949297Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"**Підготовка тренувальних даних**","metadata":{}},{"cell_type":"code","source":"data_path = '/kaggle/input/dataset-new/train_data.csv'\ndf = pd.read_csv(data_path)\n\n# список категорій:\nLABEL_COLUMNS = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n\n# Конвертація токенізованих даних з рядків у масиви\nfor column in ['input_ids', 'attention_masks']:\n    df[column] = df[column].apply(eval).apply(np.array)\n\n# Виділяємо токенізовані вектори та мітки\ninput_ids = np.stack(df['input_ids'].values)\nattention_mask = np.stack(df['attention_masks'].values)\nlabels = np.array(df[LABEL_COLUMNS].values)\nlabels = labels.astype('float32')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T13:46:35.949791Z","iopub.execute_input":"2025-01-03T13:46:35.950117Z","iopub.status.idle":"2025-01-03T13:47:23.489477Z","shell.execute_reply.started":"2025-01-03T13:46:35.950090Z","shell.execute_reply":"2025-01-03T13:47:23.488751Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"# Розділення на тренувальну та тестову вибірки (повний набір даних)\n\ntrain_input_ids, val_input_ids, train_attention_mask, val_attention_mask, train_labels, val_labels = train_test_split(\n    input_ids, attention_mask, labels, test_size=0.2, random_state=42\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T08:36:53.933547Z","iopub.execute_input":"2025-01-03T08:36:53.933786Z","iopub.status.idle":"2025-01-03T08:36:54.062212Z","shell.execute_reply.started":"2025-01-03T08:36:53.933765Z","shell.execute_reply":"2025-01-03T08:36:54.061471Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# Виділення міні-вибірки 5%\n\n_, mini_input_ids, _, mini_attention_mask, _, mini_labels = train_test_split(\n    input_ids, attention_mask, labels, test_size=0.05, random_state=42\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T10:23:06.610296Z","iopub.execute_input":"2025-01-03T10:23:06.610631Z","iopub.status.idle":"2025-01-03T10:23:06.759609Z","shell.execute_reply.started":"2025-01-03T10:23:06.610605Z","shell.execute_reply":"2025-01-03T10:23:06.758705Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# розділення міні вибірки на тренувальну та валідаційну\nt_input_ids, v_input_ids, t_attention_mask, v_attention_mask, t_labels, v_labels = train_test_split(\n    mini_input_ids, mini_attention_mask, mini_labels, test_size=0.2, random_state=42\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T10:23:14.262573Z","iopub.execute_input":"2025-01-03T10:23:14.262874Z","iopub.status.idle":"2025-01-03T10:23:14.271502Z","shell.execute_reply.started":"2025-01-03T10:23:14.262847Z","shell.execute_reply":"2025-01-03T10:23:14.270639Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# \"Розподіл класів у повній вибірці\nprint(\"Розподіл класів у повній вибірці:\\n\", labels.sum(axis=0))\nprint(\"Кількість прикладів нетоксичних коментарів:\", (labels.sum(axis=1) == 0).sum())\nprint(\"Кількість прикладів у повній вибірці:\", len(labels))\n\n# Розподіл класів у міні вибірці\nprint(\"Розподіл класів у міні вибірці:\\n\", mini_labels.sum(axis=0))\nprint(\"Кількість прикладів нетоксичних коментарів:\", (mini_labels.sum(axis=1) == 0).sum())\nprint(\"Кількість прикладів у міні вибірці:\",len(mini_labels))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T08:36:54.222466Z","iopub.execute_input":"2025-01-03T08:36:54.222886Z","iopub.status.idle":"2025-01-03T08:36:54.231634Z","shell.execute_reply.started":"2025-01-03T08:36:54.222862Z","shell.execute_reply":"2025-01-03T08:36:54.230801Z"}},"outputs":[{"name":"stdout","text":"Розподіл класів у повній вибірці:\n [15294.  1595.  8449.   478.  7877.  1405.]\nКількість прикладів нетоксичних коментарів: 143346\nКількість прикладів у повній вибірці: 159571\nРозподіл класів у міні вибірці:\n [748.  80. 421.  13. 410.  71.]\nКількість прикладів нетоксичних коментарів: 7181\nКількість прикладів у міні вибірці: 7979\n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"**Підбір архітектури моделі на міні-вибірці**","metadata":{}},{"cell_type":"markdown","source":"Для роботи із незбалансованими даними у якості метрики доцільно використовувати F1 метрику.\n\nПроте її використання на пряму (врахування у функції втрат) має певні проблеми і планується використовувати вбудовані функції втрат.\n\n* метрика Ф-1 є нелінійною та залежить від precision та recall. Її оптимізація на пряму через функцію втрат вимагає складних розрахунків які можуть бути не стабільними\n* спроби оптимізувати Ф1 на пряму можуть призвести до того, що градієнти стануть надто малими і навчання буде стагнувати\n* тому планується додати кастомну метрику Ф-1 для відслідковування, а у якості функції втрат використовувати вбудовані функції (тобто модель при навчанні не буде її оптимізувати на пряму).\n* на етапі вибору моделі пріоритет матимуть моделі які показали найкращу динаміку по метриці Ф-1\n* у функції втрат планується додати ваги класів для того, щоб врахувати дисбаланс даних\n\n","metadata":{}},{"cell_type":"markdown","source":"В рамках цього етапу планується реалізувати 3 стратегії побудови моделі:\n\n* Єдина модель із двома незалежними \"головами\" для бінарної класифікації токсичних-нетоксичних коментарів та для мультиміткової класифікації токсичних коментарів. Обидві голови будуть навчатись на повних вибірках даних. Модель буде мати занижену точність у порівнянні із фактичною за рахунок помилок другої голови на нетоксичних прикладах.\n* Єдина модель аналогічна першій, проте друга модель буде навчатись лише на токсичних прикладах для більш сфокусованого навчання.\n* Дві послідовні моделі, перша з яких виконає бінарну класифікацію, а друга повністю незалежно навчається лише на токсичних коментарях і виконує їх класифікацію.\n\nЧерез обмеження обчислювальних ресурсів ми не будемо підбирати параметри моделей та викорастаємо \"best prаctices\". Також на этапі експериментів ми будемо виконувати лише feature extraction без fine-tuning для економії ресурсів.\n\nЗа результатами оцінки буде вибрано кращу стратегію та на основі її побудовано фінальну модель та навчено на повній вибірці даних.\n","metadata":{}},{"cell_type":"code","source":"# Кастомний шар для інтеграції з BERT\nclass BertLayer(Layer):\n    def __init__(self, pretrained_model_name=\"bert-base-uncased\", trainable=False, **kwargs):\n        super(BertLayer, self).__init__(**kwargs)\n        # Завантажуємо попередньо навчений BERT\n        self.bert = TFBertModel.from_pretrained(pretrained_model_name)\n        self.bert.trainable = trainable  # Заморожуємо або розморожуємо шари залежно від параметра trainable\n\n    def call(self, inputs):\n        # Вхідні дані: input_ids та attention_mask\n        input_ids, attention_mask = inputs\n        # Передаємо дані через BERT\n        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n        return outputs.last_hidden_state  # Повертаємо тільки last_hidden_state","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T12:56:26.023606Z","iopub.execute_input":"2025-01-03T12:56:26.023887Z","iopub.status.idle":"2025-01-03T12:56:26.028602Z","shell.execute_reply.started":"2025-01-03T12:56:26.023863Z","shell.execute_reply":"2025-01-03T12:56:26.027896Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"'''\nу якості метрики обрано Ф-1 у зв'язку із незбалансованістю класів. \nПідготуємо функцію для неї\n'''\n\nimport tensorflow as tf\nfrom tensorflow.keras import backend as K\n\ndef f1_metric(y_true, y_pred):\n    # Преобразуем в бинарный формат для каждого класса\n    y_true = K.cast(y_true, 'int32')\n    y_pred = K.cast(K.greater_equal(y_pred, 0.5), 'int32')\n\n    # Вычисляем точность (precision) и полноту (recall)\n    true_positive = K.sum(K.cast(y_true * y_pred, 'float32'))\n    false_positive = K.sum(K.cast((1 - y_true) * y_pred, 'float32'))\n    false_negative = K.sum(K.cast(y_true * (1 - y_pred), 'float32'))\n\n    precision = true_positive / (true_positive + false_positive + K.epsilon())\n    recall = true_positive / (true_positive + false_negative + K.epsilon())\n\n    # F1-score = 2 * (precision * recall) / (precision + recall)\n    f1 = 2 * (precision * recall) / (precision + recall + K.epsilon())\n    \n    return f1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T12:56:28.918129Z","iopub.execute_input":"2025-01-03T12:56:28.918474Z","iopub.status.idle":"2025-01-03T12:56:28.923865Z","shell.execute_reply.started":"2025-01-03T12:56:28.918447Z","shell.execute_reply":"2025-01-03T12:56:28.923048Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# ваги класів \n\n# Розподіл класів у повній вибірці\nclass_distribution = np.array([15294., 1595., 8449., 478., 7877., 1405.])\n\n# Розрахунок ваг класів\ntotal_samples = np.sum(class_distribution)\nclass_weights = total_samples / (len(class_distribution) * class_distribution)\n\n# Нормалізація ваг\nclass_weights = class_weights / np.min(class_weights)\n\n# Вивід розрахованих ваг\nprint(f\"Class weights for multilabel_output: {class_weights}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T13:49:22.317259Z","iopub.execute_input":"2025-01-03T13:49:22.317584Z","iopub.status.idle":"2025-01-03T13:49:22.323135Z","shell.execute_reply.started":"2025-01-03T13:49:22.317558Z","shell.execute_reply":"2025-01-03T13:49:22.322327Z"}},"outputs":[{"name":"stdout","text":"Class weights for multilabel_output: [ 1.          9.58871473  1.81015505 31.9958159   1.94160213 10.88540925]\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"# Кастомна функція втрат для врахування ваг класів\n\ndef weighted_binary_crossentropy(class_weights):\n    def loss(y_true, y_pred):\n        # Применяем веса для каждого класса\n        weights = tf.reduce_sum(class_weights * y_true, axis=-1)\n        # Бинарная кроссэнтропия\n        bce = tf.keras.losses.binary_crossentropy(y_true, y_pred)\n        # Взвешиваем loss\n        return bce * weights\n    return loss","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T13:49:25.500486Z","iopub.execute_input":"2025-01-03T13:49:25.500777Z","iopub.status.idle":"2025-01-03T13:49:25.504941Z","shell.execute_reply.started":"2025-01-03T13:49:25.500754Z","shell.execute_reply":"2025-01-03T13:49:25.504277Z"}},"outputs":[],"execution_count":27},{"cell_type":"markdown","source":"**Перша версія моделі**","metadata":{}},{"cell_type":"code","source":"# Вхідні дані\ninput_ids = Input(shape=(128,), dtype=tf.int32, name=\"input_ids\")\nattention_mask = Input(shape=(128,), dtype=tf.int32, name=\"attention_mask\")\n\n# BERT шар\nbert_outputs = BertLayer(trainable=False)([input_ids, attention_mask])\n\n# Пулінг\npooled_output = GlobalAveragePooling1D()(bert_outputs)\n\n# Перша голова - бінарна класифікація\nbinary_dense = Dense(128, activation=\"swish\")(pooled_output)\nbinary_dropout = Dropout(0.3)(binary_dense)\nbinary_output = Dense(1, activation=\"sigmoid\", name=\"binary_output\")(binary_dropout)\n\n# Друга голова - багатоміткова класифікація токсичних коментарів\nmultilabel_dense = Dense(128, activation=\"swish\")(pooled_output)\nmultilabel_dropout = Dropout(0.3)(multilabel_dense)\nmultilabel_output = Dense(6, activation=\"sigmoid\", name=\"multilabel_output\")(multilabel_dropout)\n\n# Модель\nmodel_1 = Model(\n    inputs=[input_ids, attention_mask],\n    outputs=[binary_output, multilabel_output]\n)\n\nclass_weights_tensor = tf.constant(class_weights, dtype=tf.float32)\n\n# Компіляція моделі\nmodel_1.compile(\n    optimizer=Adam(learning_rate=1e-4),\n    loss={\n        \"binary_output\": \"binary_crossentropy\",\n        \"multilabel_output\": weighted_binary_crossentropy(class_weights_tensor)\n    },\n    loss_weights={\n        \"binary_output\": 0.5,\n        \"multilabel_output\": 1.0\n    },\n    metrics={\n        \"binary_output\": [\"accuracy\"],\n        \"multilabel_output\": [\"accuracy\", Precision(name=\"precision\"), Recall(name=\"recall\"), f1_metric]\n    }\n)\n\nmodel_1.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T08:36:54.287099Z","iopub.execute_input":"2025-01-03T08:36:54.287388Z","iopub.status.idle":"2025-01-03T08:37:02.585590Z","shell.execute_reply.started":"2025-01-03T08:36:54.287361Z","shell.execute_reply":"2025-01-03T08:37:02.584766Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3774bf486a844f5a9d748ca1dfbe967d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"15123e117ace49a6b91ba946ce95dde8"}},"metadata":{}},{"name":"stderr","text":"Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight']\n- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\nAll the weights of TFBertModel were initialized from the PyTorch model.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ input_ids (\u001b[38;5;33mInputLayer\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ -                      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ attention_mask            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ -                      │\n│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ bert_layer (\u001b[38;5;33mBertLayer\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m768\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ input_ids[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],       │\n│                           │                        │                │ attention_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ global_average_pooling1d  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ bert_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)  │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m98,432\u001b[0m │ global_average_poolin… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_1 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m98,432\u001b[0m │ global_average_poolin… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout (\u001b[38;5;33mDropout\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ binary_output (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m129\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ multilabel_output (\u001b[38;5;33mDense\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)              │            \u001b[38;5;34m774\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ input_ids (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ attention_mask            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ bert_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BertLayer</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_ids[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       │\n│                           │                        │                │ attention_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ global_average_pooling1d  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ bert_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)  │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">98,432</span> │ global_average_poolin… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">98,432</span> │ global_average_poolin… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ binary_output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ multilabel_output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">774</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m197,767\u001b[0m (772.53 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">197,767</span> (772.53 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m197,767\u001b[0m (772.53 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">197,767</span> (772.53 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"# Генерація міток для першої голови (binary_output)\nt_binary_labels = np.where(np.all(t_labels == 0, axis=1), 1, 0).astype('float32')\nv_binary_labels = np.where(np.all(v_labels == 0, axis=1), 1, 0).astype('float32')\n\nprint(f\"Shape of t_binary_labels: {t_binary_labels.shape}\")\nprint(f\"Example t_binary_labels: {t_binary_labels[:10]}\")\nprint(f\"Shape of v_binary_labels: {v_binary_labels.shape}\")\nprint(f\"Example v_binary_labels: {v_binary_labels[:10]}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T08:37:02.586528Z","iopub.execute_input":"2025-01-03T08:37:02.586863Z","iopub.status.idle":"2025-01-03T08:37:02.593871Z","shell.execute_reply.started":"2025-01-03T08:37:02.586833Z","shell.execute_reply":"2025-01-03T08:37:02.593233Z"}},"outputs":[{"name":"stdout","text":"Shape of t_binary_labels: (6383,)\nExample t_binary_labels: [1. 1. 1. 0. 1. 1. 1. 1. 1. 1.]\nShape of v_binary_labels: (1596,)\nExample v_binary_labels: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"# Підготовка даних для двух голов\nt_data = {\n    \"input_ids\": t_input_ids,\n    \"attention_mask\": t_attention_mask,\n}\n\nv_data = {\n    \"input_ids\": v_input_ids,\n    \"attention_mask\": v_attention_mask,\n}\n\nt_labels_combined = {\n    \"binary_output\": t_binary_labels,\n    \"multilabel_output\": t_labels,\n}\n\nv_labels_combined = {\n    \"binary_output\": v_binary_labels,\n    \"multilabel_output\": v_labels,\n}\n\n\n# Навчання моделі\nhistory = model_1.fit(\n    t_data,\n    t_labels_combined,\n    validation_data=(v_data, v_labels_combined),\n    epochs=5,  \n    batch_size=32\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T08:37:02.594794Z","iopub.execute_input":"2025-01-03T08:37:02.595022Z","iopub.status.idle":"2025-01-03T08:42:28.031486Z","shell.execute_reply.started":"2025-01-03T08:37:02.595004Z","shell.execute_reply":"2025-01-03T08:42:28.030790Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/5\n\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 368ms/step - binary_output_accuracy: 0.8108 - loss: 0.5167 - multilabel_output_accuracy: 0.6573 - multilabel_output_f1_metric: 0.1059 - multilabel_output_precision: 0.0588 - multilabel_output_recall: 0.7679 - val_binary_output_accuracy: 0.8966 - val_loss: 0.4162 - val_multilabel_output_accuracy: 0.9944 - val_multilabel_output_f1_metric: 0.1259 - val_multilabel_output_precision: 0.0692 - val_multilabel_output_recall: 0.9208\nEpoch 2/5\n\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 284ms/step - binary_output_accuracy: 0.9002 - loss: 0.4566 - multilabel_output_accuracy: 0.9586 - multilabel_output_f1_metric: 0.1179 - multilabel_output_precision: 0.0645 - multilabel_output_recall: 0.9064 - val_binary_output_accuracy: 0.8966 - val_loss: 0.4221 - val_multilabel_output_accuracy: 0.9944 - val_multilabel_output_f1_metric: 0.1264 - val_multilabel_output_precision: 0.0695 - val_multilabel_output_recall: 0.9208\nEpoch 3/5\n\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 290ms/step - binary_output_accuracy: 0.9012 - loss: 0.4191 - multilabel_output_accuracy: 0.9816 - multilabel_output_f1_metric: 0.1144 - multilabel_output_precision: 0.0625 - multilabel_output_recall: 0.9091 - val_binary_output_accuracy: 0.8966 - val_loss: 0.4162 - val_multilabel_output_accuracy: 0.9944 - val_multilabel_output_f1_metric: 0.1274 - val_multilabel_output_precision: 0.0702 - val_multilabel_output_recall: 0.9180\nEpoch 4/5\n\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 289ms/step - binary_output_accuracy: 0.9052 - loss: 0.3966 - multilabel_output_accuracy: 0.9785 - multilabel_output_f1_metric: 0.1125 - multilabel_output_precision: 0.0612 - multilabel_output_recall: 0.9022 - val_binary_output_accuracy: 0.8966 - val_loss: 0.4118 - val_multilabel_output_accuracy: 0.9944 - val_multilabel_output_f1_metric: 0.1274 - val_multilabel_output_precision: 0.0702 - val_multilabel_output_recall: 0.9180\nEpoch 5/5\n\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 289ms/step - binary_output_accuracy: 0.8984 - loss: 0.4466 - multilabel_output_accuracy: 0.9882 - multilabel_output_f1_metric: 0.1225 - multilabel_output_precision: 0.0671 - multilabel_output_recall: 0.9000 - val_binary_output_accuracy: 0.8966 - val_loss: 0.4089 - val_multilabel_output_accuracy: 0.9944 - val_multilabel_output_f1_metric: 0.1274 - val_multilabel_output_precision: 0.0702 - val_multilabel_output_recall: 0.9180\n","output_type":"stream"}],"execution_count":15},{"cell_type":"markdown","source":"**Друга версія моделі**","metadata":{}},{"cell_type":"markdown","source":"***ПРИМІТКА:***\n\nДругий підхід не вдалось реалізувати через вимоги бібліотеки Керас. \n\nЗгідно із логікою запропонованої архітектури модель повина мати два окремі входи: \n* повний набір даних із бінарними мітками для бінарної голови\n* частковий набір даних лише із токсичними коментарями та мультимітками для мультиміткової голови і такий набор даних очевидно коротший за перший.\n\nПроте бібіліотека Keras вимагає, щоб всі вхідні дані та вихідні мітки мали однакову довжину. \n\nНаступний код поданий у закоментованому вигляді для референсу. \n","metadata":{}},{"cell_type":"code","source":"\"\"\"\n# Вхідні дані для двох голов (окремі входи для кожної голови моделі)\nbinary_input_ids = Input(shape=(128,), dtype=tf.int32, name=\"binary_input_ids\")\nbinary_attention_mask = Input(shape=(128,), dtype=tf.int32, name=\"binary_attention_mask\")\n\nmultilabel_input_ids = Input(shape=(128,), dtype=tf.int32, name=\"multilabel_input_ids\")\nmultilabel_attention_mask = Input(shape=(128,), dtype=tf.int32, name=\"multilabel_attention_mask\")\n\n# BERT шар для обох голов \nbert_outputs_binary = BertLayer(trainable=False)([binary_input_ids, binary_attention_mask])\nbert_outputs_multilabel = BertLayer(trainable=False)([multilabel_input_ids, multilabel_attention_mask])\n\n# Пулінг для першої голови\npooled_output_binary = GlobalAveragePooling1D()(bert_outputs_binary)\nbinary_dense = Dense(128, activation=\"swish\")(pooled_output_binary)\nbinary_dropout = Dropout(0.3)(binary_dense)\nbinary_output = Dense(1, activation=\"sigmoid\", name=\"binary_output\")(binary_dropout)\n\n# Пулінг для другої голови\npooled_output_multilabel = GlobalAveragePooling1D()(bert_outputs_multilabel)\nmultilabel_dense = Dense(128, activation=\"swish\")(pooled_output_multilabel)\nmultilabel_dropout = Dropout(0.3)(multilabel_dense)\nmultilabel_output = Dense(6, activation=\"sigmoid\", name=\"multilabel_output\")(multilabel_dropout)\n\n# Модель\nmodel_2 = Model(\n    inputs=[\n        binary_input_ids, \n        binary_attention_mask, \n        multilabel_input_ids, \n        multilabel_attention_mask\n    ],\n    outputs=[binary_output, multilabel_output]\n)\n\nclass_weights_tensor = tf.constant(class_weights, dtype=tf.float32)\n\n# Компіляція моделі\nmodel_2.compile(\n    optimizer=Adam(learning_rate=1e-4),\n    loss={\n        \"binary_output\": \"binary_crossentropy\",\n        \"multilabel_output\": weighted_binary_crossentropy(class_weights_tensor)\n    },\n    loss_weights={\n        \"binary_output\": 0.5,\n        \"multilabel_output\": 1.0\n    },\n    metrics={\n        \"binary_output\": [\"accuracy\"],\n        \"multilabel_output\": [\"accuracy\", Precision(name=\"precision\"), Recall(name=\"recall\"), f1_metric]\n    }\n)\n\nmodel_2.summary()\n\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T08:42:28.032664Z","iopub.execute_input":"2025-01-03T08:42:28.032917Z","iopub.status.idle":"2025-01-03T08:42:28.038327Z","shell.execute_reply.started":"2025-01-03T08:42:28.032896Z","shell.execute_reply":"2025-01-03T08:42:28.037510Z"}},"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"'\\n# Вхідні дані для двох голов (окремі входи для кожної голови моделі)\\nbinary_input_ids = Input(shape=(128,), dtype=tf.int32, name=\"binary_input_ids\")\\nbinary_attention_mask = Input(shape=(128,), dtype=tf.int32, name=\"binary_attention_mask\")\\n\\nmultilabel_input_ids = Input(shape=(128,), dtype=tf.int32, name=\"multilabel_input_ids\")\\nmultilabel_attention_mask = Input(shape=(128,), dtype=tf.int32, name=\"multilabel_attention_mask\")\\n\\n# BERT шар для обох голов \\nbert_outputs_binary = BertLayer(trainable=False)([binary_input_ids, binary_attention_mask])\\nbert_outputs_multilabel = BertLayer(trainable=False)([multilabel_input_ids, multilabel_attention_mask])\\n\\n# Пулінг для першої голови\\npooled_output_binary = GlobalAveragePooling1D()(bert_outputs_binary)\\nbinary_dense = Dense(128, activation=\"swish\")(pooled_output_binary)\\nbinary_dropout = Dropout(0.3)(binary_dense)\\nbinary_output = Dense(1, activation=\"sigmoid\", name=\"binary_output\")(binary_dropout)\\n\\n# Пулінг для другої голови\\npooled_output_multilabel = GlobalAveragePooling1D()(bert_outputs_multilabel)\\nmultilabel_dense = Dense(128, activation=\"swish\")(pooled_output_multilabel)\\nmultilabel_dropout = Dropout(0.3)(multilabel_dense)\\nmultilabel_output = Dense(6, activation=\"sigmoid\", name=\"multilabel_output\")(multilabel_dropout)\\n\\n# Модель\\nmodel_2 = Model(\\n    inputs=[\\n        binary_input_ids, \\n        binary_attention_mask, \\n        multilabel_input_ids, \\n        multilabel_attention_mask\\n    ],\\n    outputs=[binary_output, multilabel_output]\\n)\\n\\nclass_weights_tensor = tf.constant(class_weights, dtype=tf.float32)\\n\\n# Компіляція моделі\\nmodel_2.compile(\\n    optimizer=Adam(learning_rate=1e-4),\\n    loss={\\n        \"binary_output\": \"binary_crossentropy\",\\n        \"multilabel_output\": weighted_binary_crossentropy(class_weights_tensor)\\n    },\\n    loss_weights={\\n        \"binary_output\": 0.5,\\n        \"multilabel_output\": 1.0\\n    },\\n    metrics={\\n        \"binary_output\": [\"accuracy\"],\\n        \"multilabel_output\": [\"accuracy\", Precision(name=\"precision\"), Recall(name=\"recall\"), f1_metric]\\n    }\\n)\\n\\nmodel_2.summary()\\n'"},"metadata":{}}],"execution_count":16},{"cell_type":"code","source":"\"\"\"\n# Генерація міток для першої голови (binary_output) - без змін у порівнянні із першою версією\nt_binary_labels = np.where(np.all(t_labels == 0, axis=1), 1, 0).astype('float32')\nv_binary_labels = np.where(np.all(v_labels == 0, axis=1), 1, 0).astype('float32')\n\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T08:42:28.039153Z","iopub.execute_input":"2025-01-03T08:42:28.039473Z","iopub.status.idle":"2025-01-03T08:42:28.056996Z","shell.execute_reply.started":"2025-01-03T08:42:28.039446Z","shell.execute_reply":"2025-01-03T08:42:28.056180Z"}},"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"\"\\n# Генерація міток для першої голови (binary_output) - без змін у порівнянні із першою версією\\nt_binary_labels = np.where(np.all(t_labels == 0, axis=1), 1, 0).astype('float32')\\nv_binary_labels = np.where(np.all(v_labels == 0, axis=1), 1, 0).astype('float32')\\n\""},"metadata":{}}],"execution_count":17},{"cell_type":"code","source":"\"\"\"\n# Підготовка даних для двух голов (змінено для другої версії моделі)\n\n# Видбірка токсичних коментарів для другої голови\nt_toxic_indices = np.any(t_labels == 1, axis=1)\nv_toxic_indices = np.any(v_labels == 1, axis=1)\n\n# Вхідні дані лише для токсичних прикладів\nt_toxic_input_ids = t_input_ids[t_toxic_indices]\nt_toxic_attention_mask = t_attention_mask[t_toxic_indices]\nt_toxic_labels = t_labels[t_toxic_indices]\n\nv_toxic_input_ids = v_input_ids[v_toxic_indices]\nv_toxic_attention_mask = v_attention_mask[v_toxic_indices]\nv_toxic_labels = v_labels[v_toxic_indices]\n\n# Підготовка даних для двох голов\n# Перша голова отримує повну вибірку\nt_data_binary = {\n    \"input_ids\": t_input_ids,\n    \"attention_mask\": t_attention_mask,\n}\n\nv_data_binary = {\n    \"input_ids\": v_input_ids,\n    \"attention_mask\": v_attention_mask,\n}\n\n# Друга голова отримує лише токсичні приклади\nt_data_multilabel = {\n    \"input_ids\": t_toxic_input_ids,\n    \"attention_mask\": t_toxic_attention_mask,\n}\n\nv_data_multilabel = {\n    \"input_ids\": v_toxic_input_ids,\n    \"attention_mask\": v_toxic_attention_mask,\n}\n\n# Підготовка міток для двох голов\nt_labels_combined = {\n    \"binary_output\": t_binary_labels,\n    \"multilabel_output\": t_toxic_labels,\n}\n\nv_labels_combined = {\n    \"binary_output\": v_binary_labels,\n    \"multilabel_output\": v_toxic_labels,\n}\n\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T08:42:28.057937Z","iopub.execute_input":"2025-01-03T08:42:28.058264Z","iopub.status.idle":"2025-01-03T08:42:28.068989Z","shell.execute_reply.started":"2025-01-03T08:42:28.058235Z","shell.execute_reply":"2025-01-03T08:42:28.068303Z"}},"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"'\\n# Підготовка даних для двух голов (змінено для другої версії моделі)\\n\\n# Видбірка токсичних коментарів для другої голови\\nt_toxic_indices = np.any(t_labels == 1, axis=1)\\nv_toxic_indices = np.any(v_labels == 1, axis=1)\\n\\n# Вхідні дані лише для токсичних прикладів\\nt_toxic_input_ids = t_input_ids[t_toxic_indices]\\nt_toxic_attention_mask = t_attention_mask[t_toxic_indices]\\nt_toxic_labels = t_labels[t_toxic_indices]\\n\\nv_toxic_input_ids = v_input_ids[v_toxic_indices]\\nv_toxic_attention_mask = v_attention_mask[v_toxic_indices]\\nv_toxic_labels = v_labels[v_toxic_indices]\\n\\n# Підготовка даних для двох голов\\n# Перша голова отримує повну вибірку\\nt_data_binary = {\\n    \"input_ids\": t_input_ids,\\n    \"attention_mask\": t_attention_mask,\\n}\\n\\nv_data_binary = {\\n    \"input_ids\": v_input_ids,\\n    \"attention_mask\": v_attention_mask,\\n}\\n\\n# Друга голова отримує лише токсичні приклади\\nt_data_multilabel = {\\n    \"input_ids\": t_toxic_input_ids,\\n    \"attention_mask\": t_toxic_attention_mask,\\n}\\n\\nv_data_multilabel = {\\n    \"input_ids\": v_toxic_input_ids,\\n    \"attention_mask\": v_toxic_attention_mask,\\n}\\n\\n# Підготовка міток для двох голов\\nt_labels_combined = {\\n    \"binary_output\": t_binary_labels,\\n    \"multilabel_output\": t_toxic_labels,\\n}\\n\\nv_labels_combined = {\\n    \"binary_output\": v_binary_labels,\\n    \"multilabel_output\": v_toxic_labels,\\n}\\n'"},"metadata":{}}],"execution_count":18},{"cell_type":"code","source":"\"\"\"\nhistory = model_2.fit(\n    {\n        \"binary_input_ids\": t_input_ids,  # Повна вибірка для першої голови\n        \"binary_attention_mask\": t_attention_mask,\n        \"multilabel_input_ids\": t_toxic_input_ids,  # Токсичні дані для другої голови\n        \"multilabel_attention_mask\": t_toxic_attention_mask,\n    },\n    {\n        \"binary_output\": t_binary_labels,  # Повні мітки для першої голови\n        \"multilabel_output\": t_toxic_labels,  # Мітки лише для токсичних прикладів\n    },\n    validation_data=(\n        {\n            \"binary_input_ids\": v_input_ids,  # Повна вибірка для першої голови\n            \"binary_attention_mask\": v_attention_mask,\n            \"multilabel_input_ids\": v_toxic_input_ids,  # Токсичні дані для другої голови\n            \"multilabel_attention_mask\": v_toxic_attention_mask,\n        },\n        {\n            \"binary_output\": v_binary_labels,  # Повні мітки для першої голови\n            \"multilabel_output\": v_toxic_labels,  # Мітки лише для токсичних прикладів\n        }\n    ),\n    epochs=5,\n    batch_size=32\n)\n\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T08:42:28.069896Z","iopub.execute_input":"2025-01-03T08:42:28.070174Z","iopub.status.idle":"2025-01-03T08:42:28.083781Z","shell.execute_reply.started":"2025-01-03T08:42:28.070154Z","shell.execute_reply":"2025-01-03T08:42:28.082937Z"}},"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"'\\nhistory = model_2.fit(\\n    {\\n        \"binary_input_ids\": t_input_ids,  # Повна вибірка для першої голови\\n        \"binary_attention_mask\": t_attention_mask,\\n        \"multilabel_input_ids\": t_toxic_input_ids,  # Токсичні дані для другої голови\\n        \"multilabel_attention_mask\": t_toxic_attention_mask,\\n    },\\n    {\\n        \"binary_output\": t_binary_labels,  # Повні мітки для першої голови\\n        \"multilabel_output\": t_toxic_labels,  # Мітки лише для токсичних прикладів\\n    },\\n    validation_data=(\\n        {\\n            \"binary_input_ids\": v_input_ids,  # Повна вибірка для першої голови\\n            \"binary_attention_mask\": v_attention_mask,\\n            \"multilabel_input_ids\": v_toxic_input_ids,  # Токсичні дані для другої голови\\n            \"multilabel_attention_mask\": v_toxic_attention_mask,\\n        },\\n        {\\n            \"binary_output\": v_binary_labels,  # Повні мітки для першої голови\\n            \"multilabel_output\": v_toxic_labels,  # Мітки лише для токсичних прикладів\\n        }\\n    ),\\n    epochs=5,\\n    batch_size=32\\n)\\n'"},"metadata":{}}],"execution_count":19},{"cell_type":"markdown","source":"**Третя версія моделі (дві послідовні моделі)**","metadata":{}},{"cell_type":"code","source":"# Модель для бінарної класифікації, навчена на повних даних \n\n# Вхідні дані\ninput_ids = Input(shape=(128,), dtype=tf.int32, name=\"input_ids\")\nattention_mask = Input(shape=(128,), dtype=tf.int32, name=\"attention_mask\")\n\n# BERT шар\nbert_outputs = BertLayer(trainable=False)([input_ids, attention_mask])\n\n# Пулінг\npooled_output = GlobalAveragePooling1D()(bert_outputs)\n\n# бінарна класифікація\nbinary_dense = Dense(128, activation=\"swish\")(pooled_output)\nbinary_dropout = Dropout(0.3)(binary_dense)\nbinary_output = Dense(1, activation=\"sigmoid\", name=\"binary_output\")(binary_dropout)\n\n# Модель\nmodel_3_1 = Model(\n    inputs=[input_ids, attention_mask],\n    outputs=[binary_output]\n)\n\n# Компіляція моделі\nmodel_3_1.compile(\n    optimizer=Adam(learning_rate=1e-4),\n    loss=\"binary_crossentropy\",\n    metrics=[\"accuracy\"]\n)\n\nmodel_3_1.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T08:42:28.086908Z","iopub.execute_input":"2025-01-03T08:42:28.087096Z","iopub.status.idle":"2025-01-03T08:42:31.019150Z","shell.execute_reply.started":"2025-01-03T08:42:28.087079Z","shell.execute_reply":"2025-01-03T08:42:31.018505Z"}},"outputs":[{"name":"stderr","text":"Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight']\n- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\nAll the weights of TFBertModel were initialized from the PyTorch model.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional_1\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ input_ids (\u001b[38;5;33mInputLayer\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ -                      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ attention_mask            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ -                      │\n│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ bert_layer_1 (\u001b[38;5;33mBertLayer\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m768\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ input_ids[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],       │\n│                           │                        │                │ attention_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ global_average_pooling1d… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ bert_layer_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)  │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_2 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m98,432\u001b[0m │ global_average_poolin… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ binary_output (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m129\u001b[0m │ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ input_ids (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ attention_mask            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ bert_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BertLayer</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_ids[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       │\n│                           │                        │                │ attention_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ global_average_pooling1d… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ bert_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)  │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">98,432</span> │ global_average_poolin… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ binary_output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m98,561\u001b[0m (385.00 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">98,561</span> (385.00 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m98,561\u001b[0m (385.00 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">98,561</span> (385.00 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}}],"execution_count":20},{"cell_type":"code","source":"# Генерація міток для бінарної моделі\nt_binary_labels = np.where(np.all(t_labels == 0, axis=1), 1, 0).astype('float32')\nv_binary_labels = np.where(np.all(v_labels == 0, axis=1), 1, 0).astype('float32')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T10:24:25.850446Z","iopub.execute_input":"2025-01-03T10:24:25.850728Z","iopub.status.idle":"2025-01-03T10:24:25.855178Z","shell.execute_reply.started":"2025-01-03T10:24:25.850707Z","shell.execute_reply":"2025-01-03T10:24:25.854477Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# Навчання моделі\nhistory_3_1 = model_3_1.fit(\n    t_data,\n    t_binary_labels,\n    validation_data=(v_data, v_binary_labels),\n    epochs=5,  \n    batch_size=32\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T08:42:31.026114Z","iopub.execute_input":"2025-01-03T08:42:31.026388Z","iopub.status.idle":"2025-01-03T08:47:54.998399Z","shell.execute_reply.started":"2025-01-03T08:42:31.026366Z","shell.execute_reply":"2025-01-03T08:47:54.997685Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/5\n\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 380ms/step - accuracy: 0.8959 - loss: 0.3490 - val_accuracy: 0.8966 - val_loss: 0.3319\nEpoch 2/5\n\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 294ms/step - accuracy: 0.9008 - loss: 0.3294 - val_accuracy: 0.8966 - val_loss: 0.3352\nEpoch 3/5\n\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 286ms/step - accuracy: 0.9008 - loss: 0.3214 - val_accuracy: 0.8966 - val_loss: 0.3313\nEpoch 4/5\n\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 287ms/step - accuracy: 0.9029 - loss: 0.3178 - val_accuracy: 0.8966 - val_loss: 0.3355\nEpoch 5/5\n\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 288ms/step - accuracy: 0.9050 - loss: 0.3142 - val_accuracy: 0.8966 - val_loss: 0.3318\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"# Модель для мультиміткової класифікації, навчена на токсичних коментарях \n\n# Вхідні дані\ninput_ids = Input(shape=(128,), dtype=tf.int32, name=\"input_ids\")\nattention_mask = Input(shape=(128,), dtype=tf.int32, name=\"attention_mask\")\n\n# BERT шар\nbert_outputs = BertLayer(trainable=False)([input_ids, attention_mask])\n\n# Пулінг\npooled_output = GlobalAveragePooling1D()(bert_outputs)\n\n# багатоміткова класифікація токсичних коментарів\nmultilabel_dense = Dense(128, activation=\"swish\")(pooled_output)\nmultilabel_dropout = Dropout(0.3)(multilabel_dense)\nmultilabel_output = Dense(6, activation=\"sigmoid\", name=\"multilabel_output\")(multilabel_dropout)\n\n# Модель\nmodel_3_2 = Model(\n    inputs=[input_ids, attention_mask],\n    outputs=[multilabel_output]\n)\n\nclass_weights_tensor = tf.constant(class_weights, dtype=tf.float32)\n\n# Компіляція моделі\nmodel_3_2.compile(\n    optimizer=Adam(learning_rate=1e-4),\n    loss=weighted_binary_crossentropy(class_weights_tensor),\n    metrics=[\"accuracy\", Precision(name=\"precision\"), Recall(name=\"recall\"), f1_metric]\n)\n\nmodel_3_2.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T08:47:54.999535Z","iopub.execute_input":"2025-01-03T08:47:54.999824Z","iopub.status.idle":"2025-01-03T08:47:58.265518Z","shell.execute_reply.started":"2025-01-03T08:47:54.999802Z","shell.execute_reply":"2025-01-03T08:47:58.264684Z"}},"outputs":[{"name":"stderr","text":"Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight']\n- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\nAll the weights of TFBertModel were initialized from the PyTorch model.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional_2\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_2\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ input_ids (\u001b[38;5;33mInputLayer\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ -                      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ attention_mask            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ -                      │\n│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ bert_layer_2 (\u001b[38;5;33mBertLayer\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m768\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ input_ids[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],       │\n│                           │                        │                │ attention_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ global_average_pooling1d… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ bert_layer_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)  │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_3 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m98,432\u001b[0m │ global_average_poolin… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ dense_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ multilabel_output (\u001b[38;5;33mDense\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)              │            \u001b[38;5;34m774\u001b[0m │ dropout_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ input_ids (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ attention_mask            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ bert_layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BertLayer</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_ids[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       │\n│                           │                        │                │ attention_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ global_average_pooling1d… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ bert_layer_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)  │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">98,432</span> │ global_average_poolin… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ multilabel_output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">774</span> │ dropout_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m99,206\u001b[0m (387.52 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">99,206</span> (387.52 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m99,206\u001b[0m (387.52 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">99,206</span> (387.52 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}}],"execution_count":23},{"cell_type":"code","source":"# Підготовка даних для мультиміткової моделі (лише токсичні коментарі)\n\n# Видбірка токсичних коментарів\nt_toxic_indices = np.any(t_labels == 1, axis=1)\nv_toxic_indices = np.any(v_labels == 1, axis=1)\n\n# Вхідні дані лише для токсичних прикладів\nt_toxic_input_ids = t_input_ids[t_toxic_indices]\nt_toxic_attention_mask = t_attention_mask[t_toxic_indices]\nt_toxic_labels = t_labels[t_toxic_indices]\n\nv_toxic_input_ids = v_input_ids[v_toxic_indices]\nv_toxic_attention_mask = v_attention_mask[v_toxic_indices]\nv_toxic_labels = v_labels[v_toxic_indices]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T08:47:58.266410Z","iopub.execute_input":"2025-01-03T08:47:58.266731Z","iopub.status.idle":"2025-01-03T08:47:58.272434Z","shell.execute_reply.started":"2025-01-03T08:47:58.266681Z","shell.execute_reply":"2025-01-03T08:47:58.271651Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"# Навчання моделі\nhistory_3_2 = model_3_2.fit(\n    {\n        'input_ids': t_toxic_input_ids,\n        'attention_mask': t_toxic_attention_mask\n    },\n    t_toxic_labels,\n    validation_data=(\n        {\n            'input_ids': v_toxic_input_ids,\n            'attention_mask': v_toxic_attention_mask\n        },\n        v_toxic_labels),\n    epochs=5,  \n    batch_size=32\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T08:47:58.273426Z","iopub.execute_input":"2025-01-03T08:47:58.273752Z","iopub.status.idle":"2025-01-03T08:49:06.641026Z","shell.execute_reply.started":"2025-01-03T08:47:58.273697Z","shell.execute_reply":"2025-01-03T08:49:06.640207Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/5\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 1s/step - accuracy: 0.1027 - f1_metric: 0.4004 - loss: 4.6195 - precision: 0.3323 - recall: 0.5072 - val_accuracy: 0.9030 - val_f1_metric: 0.7214 - val_loss: 2.7634 - val_precision: 0.6188 - val_recall: 0.9180\nEpoch 2/5\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 292ms/step - accuracy: 0.5983 - f1_metric: 0.7020 - loss: 2.7162 - precision: 0.5813 - recall: 0.8891 - val_accuracy: 0.9455 - val_f1_metric: 0.7681 - val_loss: 2.4247 - val_precision: 0.6788 - val_recall: 0.9180\nEpoch 3/5\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 302ms/step - accuracy: 0.8162 - f1_metric: 0.7461 - loss: 2.5293 - precision: 0.6350 - recall: 0.9063 - val_accuracy: 0.9455 - val_f1_metric: 0.7681 - val_loss: 2.4038 - val_precision: 0.6788 - val_recall: 0.9180\nEpoch 4/5\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 306ms/step - accuracy: 0.9092 - f1_metric: 0.7360 - loss: 2.7065 - precision: 0.6222 - recall: 0.9053 - val_accuracy: 0.9455 - val_f1_metric: 0.7681 - val_loss: 2.4030 - val_precision: 0.6788 - val_recall: 0.9180\nEpoch 5/5\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 306ms/step - accuracy: 0.9301 - f1_metric: 0.7523 - loss: 2.4709 - precision: 0.6418 - recall: 0.9108 - val_accuracy: 0.9455 - val_f1_metric: 0.7630 - val_loss: 2.3713 - val_precision: 0.6687 - val_recall: 0.9208\n","output_type":"stream"}],"execution_count":25},{"cell_type":"markdown","source":"**Порівняння точності двох моделей та виконання прогнозів**","metadata":{}},{"cell_type":"markdown","source":"Для прогнозування і оцінки тестових моделей використаємо валідаційну міні вибірку:\n\nv_input_ids, v_attention_mask, v_labels","metadata":{}},{"cell_type":"code","source":"# Оцінка першої версії моделі\n\n# Додання класу нетоксичних коментарів (всі нулі)\nall_zeros_class = np.all(v_labels == 0, axis=1).astype(int)  \ny_test_expanded = np.hstack((v_labels, all_zeros_class.reshape(-1, 1)))  \n\n# Отримання прогнозів\npredictions_test = model_1.predict(\n    {'input_ids': v_input_ids, 'attention_mask': v_attention_mask},\n    batch_size=64\n)\n\n# Розділення прогнозів по головам\nbinary_output = predictions_test[0]  \nmultilabel_output = predictions_test[1]  \n\n# Перетворення бінарного виходу\nbinary_predictions = (binary_output > 0.5).astype(int)  # Перетворення в 0 або 1\n\n# Перетворення мультиміткового виходу\nmultilabel_predictions = (multilabel_output > 0.5).astype(int)  # \n\n# Формування вектору результатів\nfinal_predictions = []\nfor binary, multilabel in zip(binary_predictions, multilabel_predictions):\n    if binary == 1:\n        # Якщо binary_output = 1, то всі інші мітки = 0\n        final_predictions.append([0, 0, 0, 0, 0, 0, 1])  # Індекс 6 для binary_output\n    else:\n        # Якщо binary_output = 0, то використовуємо multilabel_output\n        multilabel_result = multilabel.tolist() + [0]  # Додаємо 0 замість binary_output\n        final_predictions.append(multilabel_result)\n\nfinal_predictions = np.array(final_predictions)\n\n# Оцінка моделі\nprint(\"\\nКласифікаційний звіт для першого підходу:\\n\")\nprint(classification_report(y_test_expanded, final_predictions, target_names=[\n    \"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\", \"non_toxic\"\n]))\n\n# Побудова багатоміткової матриці помилок\nconf_matrices = multilabel_confusion_matrix(y_test_expanded, final_predictions)\n\n# Приклад виводу (наприклад для \"toxic\")\nprint(\"Confusion matrix for 'toxic':\")\nprint(conf_matrices[0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T08:49:06.642353Z","iopub.execute_input":"2025-01-03T08:49:06.642657Z","iopub.status.idle":"2025-01-03T08:49:32.457953Z","shell.execute_reply.started":"2025-01-03T08:49:06.642635Z","shell.execute_reply":"2025-01-03T08:49:32.457044Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 771ms/step\n\nКласифікаційний звіт для першого підходу:\n\n               precision    recall  f1-score   support\n\n        toxic       0.00      0.00      0.00       156\n severe_toxic       0.00      0.00      0.00        18\n      obscene       0.00      0.00      0.00        89\n       threat       0.00      0.00      0.00         3\n       insult       0.00      0.00      0.00        91\nidentity_hate       0.00      0.00      0.00         9\n    non_toxic       0.90      1.00      0.95      1431\n\n    micro avg       0.90      0.80      0.84      1797\n    macro avg       0.13      0.14      0.14      1797\n weighted avg       0.71      0.80      0.75      1797\n  samples avg       0.90      0.90      0.90      1797\n\nConfusion matrix for 'toxic':\n[[1440    0]\n [ 156    0]]\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"# Оцінка другої версії моделі\n\n# Додання класу нетоксичних коментарів (всі нулі)\nall_zeros_class = np.all(v_labels == 0, axis=1).astype(int)  \ny_test_expanded = np.hstack((v_labels, all_zeros_class.reshape(-1, 1)))  \n\n# Отримання прогнозів для першої моделі\nbinary_predictions = model_3_1.predict(\n    {'input_ids': v_input_ids, 'attention_mask': v_attention_mask},\n    batch_size=64\n)\nbinary_predictions = (binary_output > 0.5).astype(int)  # Перетворення в 0 або 1\n\nfinal_predictions = []\n\n# Прододимо по кодному прикладу валідаційних даних\nfor i in range(len(v_input_ids)):\n    binary_prediction = binary_predictions[i]  # Прогноз бінарної моделі для поточного приклада\n\n    if binary_prediction == 1:\n        # Якщо коментар не токсичний, формуємо фінальний вектор\n        final_predictions.append([0, 0, 0, 0, 0, 0, 1])  # Всі нулі + 1 на останьому індексі\n    else:\n        # Якщо коментар токсичний, формуємо прогноз мультимітковою моделлю\n        toxic_input_ids = v_input_ids[i].reshape(1, -1)  # Приклад в форматі (1, 128)\n        toxic_attention_mask = v_attention_mask[i].reshape(1, -1)\n\n        # Прогноз мультимітковою моделлю\n        multilabel_prediction = model_3_2.predict(\n            {'input_ids': toxic_input_ids, 'attention_mask': toxic_attention_mask},\n            batch_size=1\n        )\n\n        # Перетворення прогнозів\n        multilabel_result = (multilabel_prediction > 0.5).astype(int).flatten().tolist()\n        multilabel_result.append(0)  # Дадаємо 0 в останній індекс \n\n        # Додаємо результат у фінальні прогнози\n        final_predictions.append(multilabel_result)\n\n# Перетворення фінальних прогнозів в numpy-масив\nfinal_predictions = np.array(final_predictions)\n\n# Оцінка моделі\nprint(\"\\nКласифікаційний звіт для другого підходу моделі:\\n\")\nprint(classification_report(y_test_expanded, final_predictions, target_names=[\n    \"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\", \"non_toxic\"\n]))\n\n# Побудова багатоміткової матриці помилок\nconf_matrices = multilabel_confusion_matrix(y_test_expanded, final_predictions)\n\n# Приклад виводу (наприклад для \"toxic\")\nprint(\"Confusion matrix for 'toxic':\")\nprint(conf_matrices[0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T08:49:32.458776Z","iopub.execute_input":"2025-01-03T08:49:32.459061Z","iopub.status.idle":"2025-01-03T08:49:55.765367Z","shell.execute_reply.started":"2025-01-03T08:49:32.459026Z","shell.execute_reply":"2025-01-03T08:49:55.764457Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 729ms/step\n\nКласифікаційний звіт для другого підходу моделі:\n\n               precision    recall  f1-score   support\n\n        toxic       0.00      0.00      0.00       156\n severe_toxic       0.00      0.00      0.00        18\n      obscene       0.00      0.00      0.00        89\n       threat       0.00      0.00      0.00         3\n       insult       0.00      0.00      0.00        91\nidentity_hate       0.00      0.00      0.00         9\n    non_toxic       0.90      1.00      0.95      1431\n\n    micro avg       0.90      0.80      0.84      1797\n    macro avg       0.13      0.14      0.14      1797\n weighted avg       0.71      0.80      0.75      1797\n  samples avg       0.90      0.90      0.90      1797\n\nConfusion matrix for 'toxic':\n[[1440    0]\n [ 156    0]]\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"}],"execution_count":27},{"cell_type":"markdown","source":"**Висновки**\n\nОбидві моделі показали незадовільні результати. Оскільки логіка побудови моделей вірна, проблема саме в тренувальних даних та їх незбалансованості. \n\nДалі ми спробуємо виконати обробку тренувальної вибірки (андерсемплінг та оверсемплінг), та покращити архітектуру моделей. \n\nОскільки третій підхід (дві послідовні моделі) виявляється більш легким для відстежування результатів кожного етапу, сконцентруємось на ньому.\n","metadata":{}},{"cell_type":"markdown","source":"**Розробка покращеної бінарної моделі**","metadata":{}},{"cell_type":"markdown","source":"Поточна версія бінарної моделі протемонструвала схильність до визначення всіх коментарів як нетоксичних. Оскільки тренувальна вибірка незбалансована і має 90% нетоксичних прикладів, модель продемонстувала оманливо високу точність, проте вона не здатна виявляти токсичні коментарі. \n\nДля покращення результату спробуємо виконати балансування тренувальних даних. ","metadata":{}},{"cell_type":"code","source":"from imblearn.over_sampling import SMOTE\n\nt_features = np.hstack((t_input_ids, t_attention_mask))\n\nsmote = SMOTE(random_state=42)\nt_data_resampled, t_binary_labels_resampled = smote.fit_resample(t_features, t_binary_labels)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T10:24:39.666678Z","iopub.execute_input":"2025-01-03T10:24:39.666980Z","iopub.status.idle":"2025-01-03T10:24:39.726200Z","shell.execute_reply.started":"2025-01-03T10:24:39.666954Z","shell.execute_reply":"2025-01-03T10:24:39.724985Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"# До SMOTEENN\nprint(\"До обробки:\")\nprint(f\"Нетоксичні: {np.sum(t_binary_labels == 0)}\")\nprint(f\"Токсичні: {np.sum(t_binary_labels == 1)}\")\n\n# Після SMOTEENN\nprint(\"\\nПісля обробки:\")\nprint(f\"Нетоксичні: {np.sum(t_binary_labels_resampled == 0)}\")\nprint(f\"Токсичні: {np.sum(t_binary_labels_resampled == 1)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T10:24:43.585795Z","iopub.execute_input":"2025-01-03T10:24:43.586077Z","iopub.status.idle":"2025-01-03T10:24:43.593052Z","shell.execute_reply.started":"2025-01-03T10:24:43.586056Z","shell.execute_reply":"2025-01-03T10:24:43.592107Z"}},"outputs":[{"name":"stdout","text":"До обробки:\nНетоксичні: 633\nТоксичні: 5750\n\nПісля обробки:\nНетоксичні: 5750\nТоксичні: 5750\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# Зворотне перетворення на t_input_ids і t_attention_mask\n\n# Вихідні розміри t_input_ids и t_attention_mask\ninput_ids_size = t_input_ids.shape[1]\nattention_mask_size = t_attention_mask.shape[1]\n\n# Зворотній розподіл\nt_input_ids_resampled = t_data_resampled[:, :input_ids_size]\nt_attention_mask_resampled = t_data_resampled[:, input_ids_size:]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T10:24:47.671260Z","iopub.execute_input":"2025-01-03T10:24:47.671563Z","iopub.status.idle":"2025-01-03T10:24:47.675560Z","shell.execute_reply.started":"2025-01-03T10:24:47.671536Z","shell.execute_reply":"2025-01-03T10:24:47.674695Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"t_data = {\n    \"input_ids\": t_input_ids_resampled,\n    \"attention_mask\": t_attention_mask_resampled,\n}\n\nv_data = {\n    \"input_ids\": v_input_ids,\n    \"attention_mask\": v_attention_mask,\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T10:24:51.333983Z","iopub.execute_input":"2025-01-03T10:24:51.334318Z","iopub.status.idle":"2025-01-03T10:24:51.338006Z","shell.execute_reply.started":"2025-01-03T10:24:51.334287Z","shell.execute_reply":"2025-01-03T10:24:51.337205Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"# Модель для бінарної класифікації\n\n# Вхідні дані\ninput_ids = Input(shape=(128,), dtype=tf.int32, name=\"input_ids\")\nattention_mask = Input(shape=(128,), dtype=tf.int32, name=\"attention_mask\")\n\n# BERT шар\nbert_outputs = BertLayer(trainable=False)([input_ids, attention_mask])\n\n# Пулінг\npooled_output = GlobalAveragePooling1D()(bert_outputs)\n\n# бінарна класифікація\nbinary_dense = Dense(128, activation=\"swish\")(pooled_output)\nbinary_dropout = Dropout(0.3)(binary_dense)\nbinary_output = Dense(1, activation=\"sigmoid\", name=\"binary_output\")(binary_dropout)\n\n# Модель\nmodel_3_1 = Model(\n    inputs=[input_ids, attention_mask],\n    outputs=[binary_output]\n)\n\n# Компіляція моделі\nmodel_3_1.compile(\n    optimizer=Adam(learning_rate=1e-4),\n    loss=\"binary_crossentropy\",\n    metrics=[\"accuracy\"]\n)\n\nmodel_3_1.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T10:25:14.642029Z","iopub.execute_input":"2025-01-03T10:25:14.642384Z","iopub.status.idle":"2025-01-03T10:25:22.910898Z","shell.execute_reply.started":"2025-01-03T10:25:14.642353Z","shell.execute_reply":"2025-01-03T10:25:22.910281Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f42006839df649ed99db1c2050c6748f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c6270df9f10640079a77f9aa58433077"}},"metadata":{}},{"name":"stderr","text":"Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']\n- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\nAll the weights of TFBertModel were initialized from the PyTorch model.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ input_ids (\u001b[38;5;33mInputLayer\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ -                      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ attention_mask            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ -                      │\n│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ bert_layer (\u001b[38;5;33mBertLayer\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m768\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ input_ids[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],       │\n│                           │                        │                │ attention_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ global_average_pooling1d  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ bert_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)  │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m98,432\u001b[0m │ global_average_poolin… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout (\u001b[38;5;33mDropout\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ binary_output (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m129\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ input_ids (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ attention_mask            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ bert_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BertLayer</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_ids[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       │\n│                           │                        │                │ attention_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ global_average_pooling1d  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ bert_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)  │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">98,432</span> │ global_average_poolin… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ binary_output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m98,561\u001b[0m (385.00 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">98,561</span> (385.00 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m98,561\u001b[0m (385.00 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">98,561</span> (385.00 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"# Навчання моделі\nhistory_3_1 = model_3_1.fit(\n    t_data,\n    t_binary_labels_resampled,\n    validation_data=(v_data, v_binary_labels),\n    epochs=5,  \n    batch_size=32\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T10:25:32.189390Z","iopub.execute_input":"2025-01-03T10:25:32.189704Z","iopub.status.idle":"2025-01-03T10:34:56.484704Z","shell.execute_reply.started":"2025-01-03T10:25:32.189671Z","shell.execute_reply":"2025-01-03T10:34:56.483960Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/5\n\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 314ms/step - accuracy: 0.5502 - loss: 0.6985 - val_accuracy: 0.5013 - val_loss: 0.7121\nEpoch 2/5\n\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 301ms/step - accuracy: 0.5769 - loss: 0.6780 - val_accuracy: 0.5069 - val_loss: 0.7238\nEpoch 3/5\n\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 298ms/step - accuracy: 0.5858 - loss: 0.6710 - val_accuracy: 0.5088 - val_loss: 0.6964\nEpoch 4/5\n\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 301ms/step - accuracy: 0.5937 - loss: 0.6701 - val_accuracy: 0.5363 - val_loss: 0.6824\nEpoch 5/5\n\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 301ms/step - accuracy: 0.5901 - loss: 0.6704 - val_accuracy: 0.5746 - val_loss: 0.6595\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"# Отримання прогнозів для першої моделі\nbinary_predictions = model_3_1.predict(\n    {'input_ids': v_input_ids, 'attention_mask': v_attention_mask},\n    batch_size=64\n)\n\n# Преобразуем результат в NumPy-массив, если это необходимо\nbinary_predictions = (binary_predictions > 0.5).astype(int)  # Перетворення в 0 або 1\n\n# Розподіл прогнозів бінарної моделі\nunique, counts = np.unique(binary_predictions, return_counts=True)\nbinary_distribution = dict(zip(unique, counts))\n\nprint(\"Розподіл міток:\")\nprint(f\"Нетоксичні (1): {binary_distribution.get(1, 0)}\")\nprint(f\"Токсичні (0): {binary_distribution.get(0, 0)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T10:35:01.648869Z","iopub.execute_input":"2025-01-03T10:35:01.649189Z","iopub.status.idle":"2025-01-03T10:35:28.582816Z","shell.execute_reply.started":"2025-01-03T10:35:01.649163Z","shell.execute_reply":"2025-01-03T10:35:28.581931Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 821ms/step\nРозподіл міток:\nНетоксичні (1): 934\nТоксичні (0): 662\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"# Розподіл істинних міток\nunique, counts = np.unique(v_binary_labels, return_counts=True)\ntrue_distribution = dict(zip(unique, counts))\n\nprint(\"Розподіл істинних міток:\")\nprint(f\"Нетоксичні (1): {true_distribution.get(1, 0)}\")\nprint(f\"Токсичні (0): {true_distribution.get(0, 0)}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T09:05:09.412012Z","iopub.execute_input":"2025-01-03T09:05:09.412325Z","iopub.status.idle":"2025-01-03T09:05:09.418598Z","shell.execute_reply.started":"2025-01-03T09:05:09.412301Z","shell.execute_reply":"2025-01-03T09:05:09.417911Z"}},"outputs":[{"name":"stdout","text":"Розподіл істинних міток:\nНетоксичні (1): 1431\nТоксичні (0): 165\n","output_type":"stream"}],"execution_count":40},{"cell_type":"code","source":"# Оцінка моделі\nprint(\"\\nКласифікаційний звіт для бінарної моделі:\\n\")\nprint(classification_report(v_binary_labels, binary_predictions, target_names=[\n    \"non_toxic\", \"toxic\"\n]))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T10:36:03.318003Z","iopub.execute_input":"2025-01-03T10:36:03.318355Z","iopub.status.idle":"2025-01-03T10:36:03.332304Z","shell.execute_reply.started":"2025-01-03T10:36:03.318325Z","shell.execute_reply":"2025-01-03T10:36:03.331403Z"}},"outputs":[{"name":"stdout","text":"\nКласифікаційний звіт для бінарної моделі:\n\n              precision    recall  f1-score   support\n\n   non_toxic       0.11      0.45      0.18       165\n       toxic       0.90      0.59      0.71      1431\n\n    accuracy                           0.57      1596\n   macro avg       0.51      0.52      0.45      1596\nweighted avg       0.82      0.57      0.66      1596\n\n","output_type":"stream"}],"execution_count":16},{"cell_type":"markdown","source":"Досягненням є те, що тепер модель здатна визначати як токсичні, так у нетоксичні коментарі. Проте на цьому етапі модель демонструє схильність до хибного віднесення коментарів до токсичних. \n\nТреба враховувати що поточний цикл навчання виконується із вибіркою всього у 5% від загальної. При навчані на повних даних, модель матиме більше прикладів та теоретично краще зможе розрізняти класи коментарів.\n\nВиконанаємо фінтюнінг, щоб побачити чи є динаміка на покращення результатів. \n\nУ тестовій моделі розморозимо лише 2 верхніх шари БЕРТ. При навчанні на повній вибірці будемо розморожувати 4. ","metadata":{}},{"cell_type":"code","source":"# Разморозка останніх 2-х шарів BERT\nfor layer in model_3_1.layers:\n    if isinstance(layer, BertLayer):  \n        for bert_layer in layer.bert.bert.encoder.layer[-2:]:  \n            bert_layer.trainable = True\n\nmodel_3_1.compile(\n    optimizer=Adam(learning_rate=1e-5),  # Низкий learning rate для фінтюнинга\n    loss=\"binary_crossentropy\",\n    metrics=[\"accuracy\"]\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T10:36:29.308644Z","iopub.execute_input":"2025-01-03T10:36:29.308924Z","iopub.status.idle":"2025-01-03T10:36:29.318910Z","shell.execute_reply.started":"2025-01-03T10:36:29.308905Z","shell.execute_reply":"2025-01-03T10:36:29.318101Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"# Навчання моделі\nhistory_3_1 = model_3_1.fit(\n    t_data,\n    t_binary_labels_resampled,\n    validation_data=(v_data, v_binary_labels),\n    epochs=3,  \n    batch_size=32\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T10:36:33.177089Z","iopub.execute_input":"2025-01-03T10:36:33.177433Z","iopub.status.idle":"2025-01-03T10:42:32.529251Z","shell.execute_reply.started":"2025-01-03T10:36:33.177409Z","shell.execute_reply":"2025-01-03T10:42:32.528561Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/3\n\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 348ms/step - accuracy: 0.6053 - loss: 0.6616 - val_accuracy: 0.5783 - val_loss: 0.6544\nEpoch 2/3\n\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 303ms/step - accuracy: 0.5980 - loss: 0.6649 - val_accuracy: 0.5551 - val_loss: 0.6753\nEpoch 3/3\n\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 300ms/step - accuracy: 0.5996 - loss: 0.6631 - val_accuracy: 0.5909 - val_loss: 0.6521\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"# Отримання прогнозів для першої моделі\nbinary_predictions = model_3_1.predict(\n    {'input_ids': v_input_ids, 'attention_mask': v_attention_mask},\n    batch_size=64\n)\n\n# Перетворимо результат в NumPy-массив, якщо це необхідно\nbinary_predictions = (binary_predictions > 0.5).astype(int)  # Перетворення в 0 або 1\n\n# Розподіл прогнозів бінарної моделі\nunique, counts = np.unique(binary_predictions, return_counts=True)\nbinary_distribution = dict(zip(unique, counts))\n\nprint(\"Розподіл міток:\")\nprint(f\"Нетоксичні (1): {binary_distribution.get(1, 0)}\")\nprint(f\"Токсичні (0): {binary_distribution.get(0, 0)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T10:42:38.128013Z","iopub.execute_input":"2025-01-03T10:42:38.128346Z","iopub.status.idle":"2025-01-03T10:43:02.209608Z","shell.execute_reply.started":"2025-01-03T10:42:38.128319Z","shell.execute_reply":"2025-01-03T10:43:02.208825Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 745ms/step\nРозподіл міток:\nНетоксичні (1): 970\nТоксичні (0): 626\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"# Оцінка моделі\nprint(\"\\nКласифікаційний звіт для бінарної моделі:\\n\")\nprint(classification_report(v_binary_labels, binary_predictions, target_names=[\n    \"non_toxic\", \"toxic\"\n]))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T10:43:12.815265Z","iopub.execute_input":"2025-01-03T10:43:12.815706Z","iopub.status.idle":"2025-01-03T10:43:12.829876Z","shell.execute_reply.started":"2025-01-03T10:43:12.815661Z","shell.execute_reply":"2025-01-03T10:43:12.828557Z"}},"outputs":[{"name":"stdout","text":"\nКласифікаційний звіт для бінарної моделі:\n\n              precision    recall  f1-score   support\n\n   non_toxic       0.11      0.42      0.17       165\n       toxic       0.90      0.61      0.73      1431\n\n    accuracy                           0.59      1596\n   macro avg       0.51      0.51      0.45      1596\nweighted avg       0.82      0.59      0.67      1596\n\n","output_type":"stream"}],"execution_count":20},{"cell_type":"markdown","source":"Фінтюнінг не показав суттєвого покращення. Проте можна припустити, що проблема саме в недостатньості тренувальних даних. Модель БЕРТ краще працює із великими масивами даних, тому при передачі на навчання 159 тис. прикладів очікується покращення результатів. \n\nПриймаємо поточну архітектури бінарної моделі у відповідності до останніх змін. ","metadata":{}},{"cell_type":"markdown","source":"**Багатоміткова модель**","metadata":{}},{"cell_type":"markdown","source":"Багатоміткова модель продемонструвала схильність присвоювати мітки класів для найбільш поширених класів та інгорувати рідкі класи. \n\nПотенційні проблеми:\n* надмала тренувальна вибірка. Ми передаємо моделі лише токсичні приклади, а це всього близько 800 прикладів. Цього недостатньо щоб модель змогла виділити характеристики класів.\n* кастомна функція втрат із застосуванням ваг може не працювати як очікуюється і необхідно виконати балансування даних замість використання ваг класів.\n* більш глибокі проблеми із архітектурою моделі (необхідна більш складна архітектура).\n\nТому плануємо спробувати:\n* передати у поточну архітектуру моделі повну вибірку токсичних коментарів\n* якщо перший підхід не дасть результатів, спробуємо збалансувати вибірку та розробити архітектуру моделі без кастомної функції","metadata":{}},{"cell_type":"code","source":"# Розділення на тренувальну та тестову вибірки (повний набір даних)\n\nt_input_ids, v_input_ids, t_attention_mask, v_attention_mask, t_labels, v_labels = train_test_split(\n    input_ids, attention_mask, labels, test_size=0.2, random_state=42\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T13:47:27.180113Z","iopub.execute_input":"2025-01-03T13:47:27.180449Z","iopub.status.idle":"2025-01-03T13:47:27.327918Z","shell.execute_reply.started":"2025-01-03T13:47:27.180422Z","shell.execute_reply":"2025-01-03T13:47:27.326634Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"# Підготовка даних для мультиміткової моделі (лише токсичні коментарі)\n\n# Видбірка токсичних коментарів\nt_toxic_indices = np.any(t_labels == 1, axis=1)\nv_toxic_indices = np.any(v_labels == 1, axis=1)\n\n# Вхідні дані лише для токсичних прикладів\nt_toxic_input_ids = t_input_ids[t_toxic_indices]\nt_toxic_attention_mask = t_attention_mask[t_toxic_indices]\nt_toxic_labels = t_labels[t_toxic_indices]\n\nv_toxic_input_ids = v_input_ids[v_toxic_indices]\nv_toxic_attention_mask = v_attention_mask[v_toxic_indices]\nv_toxic_labels = v_labels[v_toxic_indices]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T13:47:59.762432Z","iopub.execute_input":"2025-01-03T13:47:59.762740Z","iopub.status.idle":"2025-01-03T13:47:59.782423Z","shell.execute_reply.started":"2025-01-03T13:47:59.762713Z","shell.execute_reply":"2025-01-03T13:47:59.781589Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"print(len(t_toxic_labels))\nprint(len(v_toxic_labels))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T13:48:44.373741Z","iopub.execute_input":"2025-01-03T13:48:44.374066Z","iopub.status.idle":"2025-01-03T13:48:44.378755Z","shell.execute_reply.started":"2025-01-03T13:48:44.374036Z","shell.execute_reply":"2025-01-03T13:48:44.377982Z"}},"outputs":[{"name":"stdout","text":"12981\n3244\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"# Модель для мультиміткової класифікації, навчена на токсичних коментарях \n\n# Вхідні дані\ninput_ids = Input(shape=(128,), dtype=tf.int32, name=\"input_ids\")\nattention_mask = Input(shape=(128,), dtype=tf.int32, name=\"attention_mask\")\n\n# BERT шар\nbert_outputs = BertLayer(trainable=False)([input_ids, attention_mask])\n\n# Пулінг\npooled_output = GlobalAveragePooling1D()(bert_outputs)\n\n# багатоміткова класифікація токсичних коментарів\nmultilabel_dense = Dense(128, activation=\"swish\")(pooled_output)\nmultilabel_dropout = Dropout(0.3)(multilabel_dense)\nmultilabel_output = Dense(6, activation=\"sigmoid\", name=\"multilabel_output\")(multilabel_dropout)\n\n# Модель\nmodel_3_2 = Model(\n    inputs=[input_ids, attention_mask],\n    outputs=[multilabel_output]\n)\n\nclass_weights_tensor = tf.constant(class_weights, dtype=tf.float32)\n\n# Компіляція моделі\nmodel_3_2.compile(\n    optimizer=Adam(learning_rate=1e-4),\n    loss=weighted_binary_crossentropy(class_weights_tensor),\n    metrics=[\"accuracy\", Precision(name=\"precision\"), Recall(name=\"recall\"), f1_metric]\n)\n\nmodel_3_2.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T13:50:16.215801Z","iopub.execute_input":"2025-01-03T13:50:16.216082Z","iopub.status.idle":"2025-01-03T13:50:19.120984Z","shell.execute_reply.started":"2025-01-03T13:50:16.216061Z","shell.execute_reply":"2025-01-03T13:50:19.120282Z"}},"outputs":[{"name":"stderr","text":"Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias']\n- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\nAll the weights of TFBertModel were initialized from the PyTorch model.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional_1\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ input_ids (\u001b[38;5;33mInputLayer\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ -                      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ attention_mask            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ -                      │\n│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ bert_layer_1 (\u001b[38;5;33mBertLayer\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m768\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ input_ids[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],       │\n│                           │                        │                │ attention_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ global_average_pooling1d… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ bert_layer_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)  │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_1 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m98,432\u001b[0m │ global_average_poolin… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ multilabel_output (\u001b[38;5;33mDense\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)              │            \u001b[38;5;34m774\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ input_ids (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ attention_mask            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ bert_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BertLayer</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_ids[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       │\n│                           │                        │                │ attention_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ global_average_pooling1d… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ bert_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)  │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">98,432</span> │ global_average_poolin… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ multilabel_output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">774</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m99,206\u001b[0m (387.52 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">99,206</span> (387.52 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m99,206\u001b[0m (387.52 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">99,206</span> (387.52 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}}],"execution_count":28},{"cell_type":"code","source":"# Навчання моделі\nhistory_3_2 = model_3_2.fit(\n    {\n        'input_ids': t_toxic_input_ids,\n        'attention_mask': t_toxic_attention_mask\n    },\n    t_toxic_labels,\n    validation_data=(\n        {\n            'input_ids': v_toxic_input_ids,\n            'attention_mask': v_toxic_attention_mask\n        },\n        v_toxic_labels),\n    epochs=3, # лише три епохи для економії ресурсів у тестовому запуску моделі\n    batch_size=32\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T13:51:20.162866Z","iopub.execute_input":"2025-01-03T13:51:20.163170Z","iopub.status.idle":"2025-01-03T13:57:55.809274Z","shell.execute_reply.started":"2025-01-03T13:51:20.163145Z","shell.execute_reply":"2025-01-03T13:57:55.808585Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/3\n\u001b[1m406/406\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 326ms/step - accuracy: 0.7765 - f1_metric: 0.7017 - loss: 3.0252 - precision: 0.5997 - recall: 0.8546 - val_accuracy: 0.9420 - val_f1_metric: 0.7589 - val_loss: 2.7242 - val_precision: 0.6561 - val_recall: 0.9026\nEpoch 2/3\n\u001b[1m406/406\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 301ms/step - accuracy: 0.9400 - f1_metric: 0.7480 - loss: 2.9089 - precision: 0.6399 - recall: 0.9033 - val_accuracy: 0.9420 - val_f1_metric: 0.7589 - val_loss: 2.7107 - val_precision: 0.6561 - val_recall: 0.9026\nEpoch 3/3\n\u001b[1m406/406\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 303ms/step - accuracy: 0.9400 - f1_metric: 0.7478 - loss: 2.9619 - precision: 0.6407 - recall: 0.9006 - val_accuracy: 0.9420 - val_f1_metric: 0.7589 - val_loss: 2.6916 - val_precision: 0.6561 - val_recall: 0.9026\n","output_type":"stream"}],"execution_count":29},{"cell_type":"code","source":"# Прогнози мультиміткової моделі на валідаціних даних\nmultilabel_predictions = model_3_2.predict(\n    {'input_ids': v_toxic_input_ids, 'attention_mask': v_toxic_attention_mask},\n    batch_size=64\n)\n\n# Перетворюємо прогнози на бінарні мітки\nmultilabel_predictions = (multilabel_predictions > 0.5).astype(int)\n# Сумуємо значення для кожної мітки\ntoxic_label_counts = multilabel_predictions.sum(axis=0)\n\n# Мітки токсичності\nlabels = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n\nprint(\"\\nРозподіл міток багатоміткової моделі:\")\nfor i, label in enumerate(labels):\n    print(f\"{label}: {toxic_label_counts[i]}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T13:58:03.880878Z","iopub.execute_input":"2025-01-03T13:58:03.881285Z","iopub.status.idle":"2025-01-03T13:58:39.421825Z","shell.execute_reply.started":"2025-01-03T13:58:03.881255Z","shell.execute_reply":"2025-01-03T13:58:39.421026Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 603ms/step\n\nРозподіл міток багатоміткової моделі:\ntoxic: 3244\nsevere_toxic: 0\nobscene: 3244\nthreat: 0\ninsult: 3244\nidentity_hate: 0\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"# Істиний розподіл міток\ntrue_label_counts = v_toxic_labels.sum(axis=0)\n\nprint(\"\\nРозподіл істиних міток:\")\nfor i, label in enumerate(labels):\n    print(f\"{label}: {true_label_counts[i]}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T13:59:04.805168Z","iopub.execute_input":"2025-01-03T13:59:04.805529Z","iopub.status.idle":"2025-01-03T13:59:04.811904Z","shell.execute_reply.started":"2025-01-03T13:59:04.805502Z","shell.execute_reply":"2025-01-03T13:59:04.811020Z"}},"outputs":[{"name":"stdout","text":"\nРозподіл істиних міток:\ntoxic: 3056.0\nsevere_toxic: 321.0\nobscene: 1715.0\nthreat: 74.0\ninsult: 1614.0\nidentity_hate: 294.0\n","output_type":"stream"}],"execution_count":31},{"cell_type":"markdown","source":"Модель все ще не розрізняє рідкі класи та надлишково прогнозує часті класи. Тобто проблема не з обсягом даних, а з архітектурою. \n\nСпробуємо виконати балансування даних та відмовитись від кастомної функції втрат. ","metadata":{}},{"cell_type":"code","source":"# Розподіл класів у тренувальній вибірці\nclass_distribution = t_toxic_labels.sum(axis=0)\nprint(\"Розподіл класів у тренувальній вибірці:\", class_distribution)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T14:07:32.672009Z","iopub.execute_input":"2025-01-03T14:07:32.672361Z","iopub.status.idle":"2025-01-03T14:07:32.678083Z","shell.execute_reply.started":"2025-01-03T14:07:32.672329Z","shell.execute_reply":"2025-01-03T14:07:32.677426Z"}},"outputs":[{"name":"stdout","text":"Розподіл класів у тренувальній вибірці: [12238.  1274.  6734.   404.  6263.  1111.]\n","output_type":"stream"}],"execution_count":35},{"cell_type":"code","source":"# Балансування даних \n\nfrom sklearn.utils import resample\n\ndef balance_data(input_ids, attention_mask, labels):\n    # Створюємо датафрейм для зручної обробки\n    data = pd.DataFrame({\n        'input_ids': list(input_ids),\n        'attention_mask': list(attention_mask),\n        'labels': list(labels)\n    })\n    \n    # Розділяємо дані по класам\n    classes = [data[data['labels'].apply(lambda x: x[i] == 1)] for i in range(labels.shape[1])]\n\n    # Находимо середню кількість даних в класі\n    avg_class_size = int(np.mean([len(cls) for cls in classes]))\n\n    # Oversampling для кожного класу\n    balanced_classes = []\n    for cls in classes:\n        balanced_classes.append(resample(cls, replace=True, n_samples=avg_class_size, random_state=42))\n    \n    # Об'єднуємо збалансовані дані\n    balanced_data = pd.concat(balanced_classes)\n    return (\n        np.stack(balanced_data['input_ids'].values),\n        np.stack(balanced_data['attention_mask'].values),\n        np.array(balanced_data['labels'].tolist())\n    )\n\n# Балансування тренувальної вибірки\nt_balanced_input_ids, t_balanced_attention_mask, t_balanced_labels = balance_data(\n    t_toxic_input_ids, t_toxic_attention_mask, t_toxic_labels\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T14:08:22.304328Z","iopub.execute_input":"2025-01-03T14:08:22.304662Z","iopub.status.idle":"2025-01-03T14:08:22.566051Z","shell.execute_reply.started":"2025-01-03T14:08:22.304634Z","shell.execute_reply":"2025-01-03T14:08:22.565040Z"}},"outputs":[],"execution_count":36},{"cell_type":"code","source":"# Перевірка розподілу класів\nbalanced_class_distribution = t_balanced_labels.sum(axis=0)\nprint(\"Розподіл класів у збалансованій вибірці:\", balanced_class_distribution)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T14:08:25.649682Z","iopub.execute_input":"2025-01-03T14:08:25.650006Z","iopub.status.idle":"2025-01-03T14:08:25.654970Z","shell.execute_reply.started":"2025-01-03T14:08:25.649977Z","shell.execute_reply":"2025-01-03T14:08:25.654066Z"}},"outputs":[{"name":"stdout","text":"Розподіл класів у збалансованій вибірці: [26773.  9178. 21603.  5938. 21243.  8351.]\n","output_type":"stream"}],"execution_count":37},{"cell_type":"code","source":"# Модель для мультиміткової класифікації, навчена на токсичних коментарях \n\n# Вхідні дані\ninput_ids = Input(shape=(128,), dtype=tf.int32, name=\"input_ids\")\nattention_mask = Input(shape=(128,), dtype=tf.int32, name=\"attention_mask\")\n\n# BERT шар\nbert_outputs = BertLayer(trainable=False)([input_ids, attention_mask])\n\n# Пулінг\npooled_output = GlobalAveragePooling1D()(bert_outputs)\n\n# багатоміткова класифікація токсичних коментарів\nmultilabel_dense = Dense(128, activation=\"swish\")(pooled_output)\nmultilabel_dropout = Dropout(0.3)(multilabel_dense)\nmultilabel_output = Dense(6, activation=\"sigmoid\", name=\"multilabel_output\")(multilabel_dropout)\n\n# Модель\nmodel_3_2 = Model(\n    inputs=[input_ids, attention_mask],\n    outputs=[multilabel_output]\n)\n\n# Компіляція моделі без кастомної функції втрат\nmodel_3_2.compile(\n    optimizer=Adam(learning_rate=1e-4),  \n    loss=\"binary_crossentropy\",  \n    metrics=[\"accuracy\", Precision(name=\"precision\"), Recall(name=\"recall\"), f1_metric]\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T14:09:17.291957Z","iopub.execute_input":"2025-01-03T14:09:17.292415Z","iopub.status.idle":"2025-01-03T14:09:20.175337Z","shell.execute_reply.started":"2025-01-03T14:09:17.292364Z","shell.execute_reply":"2025-01-03T14:09:20.174639Z"}},"outputs":[{"name":"stderr","text":"Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias']\n- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\nAll the weights of TFBertModel were initialized from the PyTorch model.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n","output_type":"stream"}],"execution_count":38},{"cell_type":"code","source":"# Навчання моделі\nhistory_3_2 = model_3_2.fit(\n    {\n        'input_ids': t_balanced_input_ids,\n        'attention_mask': t_balanced_attention_mask\n    },\n    t_balanced_labels,\n    validation_data=(\n        {\n            'input_ids': v_toxic_input_ids,\n            'attention_mask': v_toxic_attention_mask\n        },\n        v_toxic_labels),\n    epochs=3,  \n    batch_size=32\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T14:09:53.664057Z","iopub.execute_input":"2025-01-03T14:09:53.664393Z","iopub.status.idle":"2025-01-03T14:21:29.627753Z","shell.execute_reply.started":"2025-01-03T14:09:53.664365Z","shell.execute_reply":"2025-01-03T14:21:29.627056Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/3\n\u001b[1m876/876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m251s\u001b[0m 266ms/step - accuracy: 0.8784 - f1_metric: 0.7782 - loss: 0.5231 - precision: 0.8155 - recall: 0.7452 - val_accuracy: 0.9420 - val_f1_metric: 0.7589 - val_loss: 0.5197 - val_precision: 0.6561 - val_recall: 0.9026\nEpoch 2/3\n\u001b[1m876/876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m221s\u001b[0m 252ms/step - accuracy: 0.9542 - f1_metric: 0.7859 - loss: 0.5085 - precision: 0.8282 - recall: 0.7483 - val_accuracy: 0.9420 - val_f1_metric: 0.7595 - val_loss: 0.5270 - val_precision: 0.6562 - val_recall: 0.9042\nEpoch 3/3\n\u001b[1m876/876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m224s\u001b[0m 256ms/step - accuracy: 0.9547 - f1_metric: 0.7876 - loss: 0.5050 - precision: 0.8275 - recall: 0.7519 - val_accuracy: 0.9420 - val_f1_metric: 0.7592 - val_loss: 0.4974 - val_precision: 0.6552 - val_recall: 0.9051\n","output_type":"stream"}],"execution_count":39},{"cell_type":"code","source":"# Прогнози мультиміткової моделі на валідаціних даних\nmultilabel_predictions = model_3_2.predict(\n    {'input_ids': v_toxic_input_ids, 'attention_mask': v_toxic_attention_mask},\n    batch_size=64\n)\n\n# Перетворюємо на бінарні мітки\nmultilabel_predictions = (multilabel_predictions > 0.5).astype(int)\n\n# Сумуємо значення для кожної мітки\ntoxic_label_counts = multilabel_predictions.sum(axis=0)\n\n# Мітки токсичності\nlabels = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n\nprint(\"\\nРозподіл міток багатоміткової моделі:\")\nfor i, label in enumerate(labels):\n    print(f\"{label}: {toxic_label_counts[i]}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T14:21:35.086542Z","iopub.execute_input":"2025-01-03T14:21:35.086857Z","iopub.status.idle":"2025-01-03T14:22:09.534987Z","shell.execute_reply.started":"2025-01-03T14:21:35.086832Z","shell.execute_reply":"2025-01-03T14:22:09.534259Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 561ms/step\n\nРозподіл міток багатоміткової моделі:\ntoxic: 3244\nsevere_toxic: 40\nobscene: 3244\nthreat: 0\ninsult: 3244\nidentity_hate: 0\n","output_type":"stream"}],"execution_count":40},{"cell_type":"code","source":"# Оцінка моделі\nprint(\"\\nКласифікаційний звіт для другого підходу моделі:\\n\")\nprint(classification_report(v_toxic_labels, multilabel_predictions, target_names=[\n    \"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"\n]))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T13:14:11.374656Z","iopub.execute_input":"2025-01-03T13:14:11.374942Z","iopub.status.idle":"2025-01-03T13:14:11.415722Z","shell.execute_reply.started":"2025-01-03T13:14:11.374921Z","shell.execute_reply":"2025-01-03T13:14:11.414860Z"}},"outputs":[{"name":"stdout","text":"\nКласифікаційний звіт для другого підходу моделі:\n\n               precision    recall  f1-score   support\n\n        toxic       0.94      1.00      0.97       931\n severe_toxic       0.00      0.00      0.00       105\n      obscene       0.53      1.00      0.70       528\n       threat       0.00      0.00      0.00        20\n       insult       0.51      1.00      0.67       502\nidentity_hate       0.00      0.00      0.00        95\n\n    micro avg       0.66      0.90      0.76      2181\n    macro avg       0.33      0.50      0.39      2181\n weighted avg       0.65      0.90      0.74      2181\n  samples avg       0.66      0.94      0.73      2181\n\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"}],"execution_count":17},{"cell_type":"markdown","source":"Результати моделі все ще низькі, проте певний прогрес є - модель визначила принаймні декілька прикладів рідкого класу severe_toxic. \n\nМожна очікувати, що при навчані моделі більшу кількість епох із раньої зупинкою та із фінтюнінгом, модель навчиться краще розпізнавати рідкі коментарі. \n\nТому у якості архітектури використаємо останні пропозиції - відмова від кастомної функції втрат з вагами класів і балансування даних для навчання. ","metadata":{}}]}